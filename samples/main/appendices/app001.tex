% #############################################################################
% This is Appendix Questionnaires
% !TEX root = main.tex
% #############################################################################
\chapter{Accessory Information}
\label{chap:app001}

In this appendix, we provide additional details on the use of AI models in our UI, as well as the severity classification during patient diagnosis, our patient selection, and information about participants.
We also discuss the existing system, evaluating performance recognition, thresholds, and strategies for curating patients, the next steps for explanations and tone, and the repositories.
As follows, we will provide further information to better understand the details of our work.

\section{Severity Classification}
\label{sec:app001001}

BIRADS stands for ``{\it Breast Imaging Reporting and Data System}'' and is a system used to standardize the way in which radiologists report the findings of mammograms and other imaging exams of the breast~\cite{SPAK2017179, mckinney2020international}.
The BIRADS provides a standardized method for reporting the results of breast imaging exams, which can help to ensure that the information is accurate and consistent.
This information is useful as an input for AI models that are designed to assist with the diagnosis of breast cancer, as it provides a standardized way of representing the findings of imaging exams~\cite{MAICAS2019101562}.

By using the BIRADS system as an input for AI models, it may be possible to improve the accuracy and reliability of the model's predictions, and to help prevent bias in the results.
The BIRADS system uses a scale from {\bf 0} to {\bf 6} for categorizing the findings of breast imaging exams.
However, in our study we just considered the scale from {\bf 1} to {\bf 5}, as the {\bf 0} means that the case is inconclusive, where we need to acquire more images, and {\bf 6} means we already have biopsy confirmation by previously known lesion.

\vspace{1.5mm}

\noindent
Here is a brief overview of each category on the BIRADS scale:

\vspace{0.5mm}

\begin{enumerate}
\item {\bf Negative:} The exam did not show any abnormalities and the patient's breast tissue appears normal.
\item {\bf Benign Finding:} The exam showed a benign (non-cancerous) abnormality in the breast tissue.
\item {\bf Probably Benign:} The exam showed an abnormality that is likely to be benign, but further testing may be needed to confirm this.
\item {\bf Suspicious Abnormality:} The exam showed an abnormality that is suspicious for cancer and further testing, such as a biopsy, is needed to determine if it is cancerous.
\item {\bf Highly Suggestive of Cancer:} The exam showed an abnormality that is highly suggestive of cancer, and a biopsy is recommended to confirm the diagnosis.
\end{enumerate}

\vspace{0.5mm}

It is important to note that the BIRADS system is only a tool for reporting the results of breast imaging exams and does not provide a definitive diagnosis of cancer. A biopsy is usually needed to confirm a cancer diagnosis.

\section{Patient Selection}
\label{sec:app001002}

In this paper, we used a total of 338 cases and acquired in the HFF clinical institution.
From this set of 338 cases, 289 were classified by the head of radiology.
Each patient has several images concerning four X-ray MG modalities (two in CC and two MLO views), one or two US images, and roughly 5 volumes in MRI.
In the MRI volumes, we take numerous image slices per patient, where the lesion is present.

From the 289 classified cases, we selected a total of 35 patients to be classified by our AI models.
Because we aim to test the three trials ({\it i.e.}, conventional {\it vs.} non-assertive {\it vs.} assertive), plus the two groups of medical professional experience ({\it i.e.}, novice {\it vs.} expert) we computed at least $2^5=32$ the number of patients.
Hence, the 35 patients were selected to cover that magnitude of patients.
This classification corresponds to assigning a BIRADS value for each modality image of the exam.

\section{Participants Information}
\label{sec:app001003}

In this study, we collected information about the participants through an initial survey, and this included details about their gender, age, geographic location, and professional experience (Table~\ref{tab:tab015}).
Additionally, we also ask participants about their professional background, in reading medical imaging data.
Regarding the professional background, 11.54\% of participants are doing their medical internships, 3.85\% were breast medical surgeons, but with knowledge of reading medical images, and 84.61\% were medical radiologists, reading and diagnosing patients every day.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{tables/tab015}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Existing System}
\label{sec:app001004}

Our new approach allows for a more flexible and dynamic system.
Furthermore, the new system addresses some limitations of the traditional system~\cite{CALISTO2022102285}, providing a more robust and scalable solution.
Ultimately, offering a new and innovative approach for solving the diagnostic task.

The AI models in this study are not fusing the predictions from different imaging modalities ({\it e.g.}, MG, US, or MRI).
Instead, each modality had its own ground-truth score, which refers to the correct or known diagnosis for a given patient.
This is because the different modalities may provide different information about a patient's breast tissue, and may, therefore; result in different diagnoses and BIRADS scores for a given patient.
Hence, the AI models in this study generated individual final predictions for each modality.

Specifically, the DenseNet model~\cite{8721151} was used to estimate the lesion score for 2D imaging data, such as MG and US images.
The 3D ResNet model~\cite{Aldoj2020} was used to estimate the lesion score for 3D data, such as MRI volumes.
Lesion score refers to the likelihood that a specific area of the breast tissue is cancerous, and is typically used as part of the BIRADS score for reporting the results of exams.

\section{Evaluating Performance Recognition}
\label{sec:app001005}

We have used the false-positive and false-negative metrics for evaluating the performance of recognition of clinicians, since these metrics are straightforwardly obtained from a classification process.
We chose to use these metrics because they are widely recognized as important indicators of performance in medical imaging classification tasks.
Particularly, in the context of breast cancer diagnosis, where false-positives and false-negatives can have significant consequences for patient care.
Furthermore, we believe that these metrics provide a more balanced and comprehensive evaluation of performance than classification accuracy, which can be misleading in imbalanced datasets.
For instance, if a clinician provides a BIRADS of 3 but the real BIRADS is a 5, we consider it as a false-negative result.
On the other hand, if the real BIRADS is a 2, but the clinician provides a BIRADS of 4, we consider it as a false-positive.
Where the ``real'' score is the ground-truth provided by the expert %from the HFF clinical institution.

Overall, our goal was to evaluate the performance of our system in terms of its ability to reduce false-positives and false-negatives.
We found that our classifiers achieved an average decrease of about 26\% for the false-positive rate and about 2\% for the false-negative rate, outperforming previous approaches that have been proposed for this task~\cite{CALISTO2022102285}.
Moreover, we believe that the false-positive and false-negative metrics we used are appropriate for this purpose.
By using these metrics, we were able to demonstrate the potential of our AI-assisted approach for reducing false-positives and false-negatives, and we believe that our findings could help to% inspire future research.

\section{Thresholds \& Strategies for Curating Patients}
\label{sec:app001006}

Similar to what was already described (Section~\ref{sec:app001001}), the rationale is the following.
The BIRADS score ranges from 0-to-6 scale, with the following meaning:
0 -- inconclusive,
1 -- no findings,
2 -- benign findings,
3 -- probably benign,
4 -- suspicious findings,
5 -- high suspicious malignancy,
6 -- previously known lesion.
BIRADS of 0 and 6 are ignored in our study, because they are meaningless for prediction purposes.

\vspace{1.15mm}

\noindent
We have clustered the values above into three classes as follows:

\vspace{0.05mm}

\begin{itemize}
\item ``No Findings'' with BIRADS = 1
\item ``Benign, probably benign findings'' with BIRADS = \{2, 3\}
\item ``Probably, highly suspicious malignancy findings'' with BIRADS = \{4, 5\}
\end{itemize}

Thus, the  DenseNet (for 2D MG and US) and the ResNet (for 3D MRI), three classes for the classification.
We take the values from 1-to-5, since the other two values do not count for the diagnosis.
Notice that both networks are trained with the BIRADS ground truth provided by a radiologist from the HFF clinical institution.

\section{Next Steps for Explanations and Tone}
\label{sec:app001007}

In this paper, we resort to two main classes of tones:
(1) assertive, by having a more authoritative tone, while imposing the AI recommendations; and
(2) non-assertive, while being a more suggestive agent.
However, and considering the clinical context, this should be expanded not only to test more trials in a near future, but also to a larger extent of the communication tones.
Concretely, the explanations should be attached to the concept of the lexicon for each breast modalities~\cite{SPAK2017179}.
For instance, having the explanation: ``scattered areas'' (\texttt{lex\_1}), ``fibrogandular density'' (\texttt{lex\_2})  or ``scattered fibroglandular tissue'' (\texttt{lex\_3}), and ``ring enhancement mass'' (\texttt{lex\_4}).
However, we recognize that there may be other communication tones that could be useful in the clinical context, and we plan to explore these in future research.

\vspace{1.5mm}

\noindent
To study the full effects of the style of tone, we will need the following trials:

\vspace{0.05mm}

\begin{enumerate}
\item Conventional Agent;
\item Agent with Explanations in Neutral Tone;
\item Agent with Explanations in Non-Assertive Tone; and
\item Agent with Explanations in Assertive Tone.
\end{enumerate}

\vspace{0.5mm}

This is an interesting point that presently we are pursuing our research in this direction.
By providing more detailed and accurate explanations, we believe that our AI-assisted system can improve the diagnostic performance of medical imaging classification in the clinical domain of breast cancer.

TODO: change the following text to the app002.tex file.

\section{Repositories}
\label{sec:app001sec010}

Our repositories are accessible to the public and can be easily located online.
Please follow the \texttt{\href{https://github.com/MIMBCD-UI/prototype-assertive-reactive}{prototype-assertive-reactive}} repository (\href{https://github.com/MIMBCD-UI/prototype-assertive-reactive}{github.com/MIMBCD-UI/prototype-assertive-reactive}) for more details about the source code of the prototypes.
In terms of results and statistical analysis, all information is available in the \texttt{\href{https://github.com/MIMBCD-UI/sa-uta11-results}{sa-uta11-results}} repository (\href{https://github.com/MIMBCD-UI/sa-uta11-results}{github.com/MIMBCD-UI/sa-uta11-results}).
The repositories have the linking pointers for the other related repositories, such as the datasets, source code of the AI models, prototypes, documentation, between others.
These links were accessed on 25th of January 2023.

\section{Intellectual Property}
\label{sec:app001sec011}

The work described in this paper is covered by pending patent applications~\cite{WO2022071818A1}, filed by Instituto Superior T\'{e}cnico.
The contents of this paper are intended to be informative to the scientific and technical community.
They are not intended to be used to limit the scope of the pending patent application.
The patent rights will be enforced to the extent necessary to protect the proprietary interests of the patent holders.
For more information, further details are available in the \texttt{\href{https://github.com/MIMBCD-UI/sa-uta11-results/blob/main/LICENSE.md}{LICENSE.md}} file of the \texttt{\href{https://github.com/MIMBCD-UI/sa-uta11-results}{sa-uta11-results}} repository (\href{https://github.com/MIMBCD-UI/sa-uta11-results}{github.com/MIMBCD-UI/sa-uta11-results}).
Accessed on 25th of January 2023.