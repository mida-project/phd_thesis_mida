% #############################################################################
% This is Appendix Assertiveness-based Details (CHI 2023)
% !TEX root = main.tex
% #############################################################################
\chapter{Assertiveness-based Details}
\label{chap:app005}

In this appendix, we provide additional details from Chapter~\ref{chap:chap006} on the use of \ac{AI} models in our \ac{UI}, as well as the severity classification during patient diagnosis, our patient selection, and information about participants.
We also discuss the existing system, evaluating performance recognition, thresholds, and strategies for curating patients, the following steps for explanations and tone, and the repositories.
As follows, we will provide further information to understand the details of our work better.

\section{Extended Motivation}
\label{sec:app005001}

\ac{AI} systems are showing increasing promise for numerous healthcare applications.
Recently, the advantages of \ac{DL} are spawning \ac{AI} systems with human-like performance in several clinical domains~\cite{CALISTO2022102285, Hannun2019, Ruamviboonsuk2019}.
However, these applications are not designed to capture the variability of personal or subpopulation level of clinicians~\cite{Uddin2019}.
Recent works highlight how \ac{AI} and the advancement of technologies together are empowering the aim of personalized and precision medicine~\cite{HO2020497, Wetzstein2020}.
Given the need to personalize and customize the \ac{AI} recommendations, an essential question in the design of \ac{AI} systems is how they should communicate, considering the professional experience of the clinician.

To achieve a more persuasive and reliable intelligent agent, we must analyze and collect data regarding the clinician's behavior~\cite{PELAU2021106855}.
Communication is essential to increase the reliability of an intelligent agent~\cite{10.1145/3311350.3347162} providing a diagnosis to a clinician.
One way to achieve that is by aligning the levels of assertiveness~\cite{pacheco2019alignment} of the agent with the years of experience of the clinician.
Besides that, explaining `how' and `why' the \ac{AI} assistant achieved a particular output increases trust in the system, solving a problem known as the ``black-box'' problem~\cite{10.1145/3491102.3502104, CALISTO2021102607}.

In this appendix, we present further details of our study for applying {\it BreastScreening-AI} prototype (Section~\ref{sec:chap005004} of Chapter~\ref{chap:chap005}) in two conditions, where clinicians will interact with conventional and assertiveness-based intelligent agents~\cite{pacheco2019alignment, 10.1145/3311350.3347162}.
The assistant will act as a second reader, resulting in improvements in diagnostic performance, by reducing \acp{FP} and \acp{FN} ({\it i.e.}, Over-Diagnosis {\it vs} Under-Diagnosis), as well as inefficiency and efficacy in the clinical workflow (Section~\ref{sec:chap006006001}).
While considerable work has focused on improving the accuracy of \ac{AI} algorithms, comparatively less work focused on improving the adoption and usability of interactive assistance techniques.
This paper broadly examines what clinicians need when using \ac{AI}-powered assistance, the practices they adopt while using diagnostic tools, and how these tools affect end-user attitudes toward the underlying \ac{AI} algorithms.

Here, we detail a within-subject study with 52 clinicians who interacted with both conventional and assertiveness-based agents, diagnosing a total of 35 patients from a dataset of 289 patients, out of which 34\% have benign abnormalities, 31\% have malignant abnormalities, and the other 35\% are healthy patients (Section~\ref{sec:app005010}).
Two different tones were used to communicate the \ac{AI} recommendations in our assertiveness-based agent, from a more suggestive to a more imposing tone.
Moreover, the assertiveness-based agent explained `{\it how}' and `{\it why}' the \ac{AI} algorithms achieved a particular diagnostic by providing human-interpretable clinical arguments for the achieved outputs.

While we used actual \ac{AI} outputs and clinical arguments curated from human clinicians, the \ac{AI} models were trained for classification and segmentation purposes through different architectures.
Specifically, through a DenseNet model~\cite{8721151} for a multimodal diagnosis of \ac{MG} and \ac{US} images.
Similarly, a 3D ResNet model~\cite{Aldoj2020} was trained to diagnose the \ac{MRI} volumes.
Our findings suggest that explaining the \ac{AI} outputs and clinical arguments by exploring how to adapt the communication through an assertiveness-based agent can benefit \ac{AI} assistance of medical reasoning.

The novelty of this work lies in applying communication theories through \ac{DL} systems to investigate the impact of assertiveness-based \ac{AI} mediation on different expertise levels in critical medical decision-making.
To achieve this, we updated the design of the {\it BreastScreening-AI} framework~\cite{CALISTO2022102285} to examine how assertiveness-based communication influences different expertise levels in clinical scenarios.
Our contributions encompass knowledge in computational interaction approaches, specifically assertiveness-based \ac{AI} mediation in the \ac{HCI} field, as well as insights into designing interactive systems guided by computational principles for the \ac{CHI} community.

\section{Further Contributions}
\label{sec:app005002}

So far, we have provided an extended motivation (Section~\ref{sec:app005001}) with more information to sustain the work under Section~\ref{sec:chap006001} of Chapter~\ref{chap:chap006}.
In this section, we provide further details on the contributions of this work.
The work was published~\cite{10.1145/3544548.3580682} and {\it peer-reviewed} at the \acs{CHI} 2023 conference.

\vspace{0.50mm}

\noindent
In sum, the main contributions of this work are as follows:

\vspace{0.05mm}

\begin{enumerate}
\item We present a novel approach for personalizing and customizing \ac{AI}-assisted medical reasoning, providing evidence that assertiveness-based agents can alter clinical workflows by effectively adapting the communication depending on the categories of medical professional experience.
\item We demonstrate that while explaining the \ac{AI} outputs can enhance medical efficiency, its impact heavily depends on the communication tone ({\it i.e.}, more suggestive or imposing the \ac{AI} recommendations) of the provided clinical arguments.
\item We report our results demonstrating that these assertiveness-based agents can increase the utility of clinical information found and increase user trust in the \ac{AI} recommendations, without a loss in diagnostic performance.
\item We provide design considerations for adapting the communication in \ac{AI}-assisted medical reasoning, laying a foundation for future implementations of intelligent agents better capable of personalizing and customizing explanations.
\end{enumerate}

\vspace{0.05mm}

Across the following sections, we outline related works on the issues of guiding the \ac{HAII} topic, assisting decision-making, going through some examples of \acp{CDSSe} present in the literature~\cite{NAISEH2023102941, 10.1145/3531146.3533193}, and ending on the effects of \ac{AI} communication.
We then introduce the design of our {\it Assertiveness-based BreastScreening-AI} assistant, followed by our research questions, hypotheses, and methods.
Last, we report our quantitative and qualitative findings, as well as conclude with a discussion of design considerations.

\section{Additional Literature}
\label{sec:app005003}

This section covers additional literature from Section~\ref{sec:chap006002} of Chapter~\ref{chap:chap006} on medical imaging system integration, challenges in clinical decision-making, \acp{CDSSe}, and the effects of \ac{AI} communication. The intersection of cognitive psychology, learnability, and context awareness in \ac{HCI} is examined. Personalized and customized algorithmic suggestions based on medical expertise levels are highlighted, along with the impact of \ac{AI} communication on trust and decision-making. The focus is on studying how assertiveness-based \ac{AI} mediation affects clinicians with different levels of expertise.

Medical imaging systems play a crucial role in diagnosing various modalities, such as \ac{MG}, \ac{US}, and \ac{MRI}, by enabling seamless data retrieval.
Integrating these modalities offers opportunities for quantitative imaging and diagnoses, necessitating specialized data handling, post-processing, and visualization methods~\cite{Igarashi:2016:IVS:2984511.2984537}.
In the clinical domain, medical imaging tools assist experts in making more informed decisions, including identifying cancer prognostics using multi-modal data.

In this section, we provide additional literature from Section~\ref{sec:chap006002} that expands on integrating \ac{CDSSe} into the radiology workflow.
The selected works aim to explore different aspects and expectations, focusing on enhancing medical imaging diagnosis through assertiveness-based interaction.
These studies shed light on the potential benefits and challenges of incorporating assertiveness-based \ac{AI} systems in the clinical setting.

\subsection{Human-AI Interaction Details}
\label{sec:app005003001}

Intelligent agents need to provide users with, not only results, but also accounting for their behaviors during decision-making~\cite{10.1145/3313831.3376807}.
In the field of \ac{HCI}, the topic of \ac{XAI} contains subjects that intersect cognitive psychology, learnability, and context awareness~\cite{doi:10.1073/pnas.1618211113}.
Cognitive psychology is a subject focusing more on explanation theory.
For cognitive psychology, we know that cognitive explanations are strongly connected with causality reasoning~\cite{10.1145/3544548.3580682}.
Learnability is an important part of usability~\cite{CALISTO2021102607}.
Here, the literature summarized topics of learnability related to designing a \ac{XAI} system, such as hints, guidance, and visualizations~\cite{CALISTO2022102285}.
These aspects contribute to the understanding of how intelligent agents can effectively communicate and provide meaningful explanations in decision-making processes.

Explainable context awareness is a simplistic representation of the context to inform users what is obtained and which action will be done by the system~\cite{10.1145/3313831.3376545}.
Other authors~\cite{Kocielnik:2019:YAI:3290605.3300641} designed a tailored interface, providing visual and textual explanations following several context-aware rules.
However, research in both \ac{HCI} and \ac{AI} communities is often disconnected between the two fields~\cite{10.1145/3173574.3174156, 10.1145/3313831.3376807}.
There is a research gap that is not crossing nor combine both fields to the interdisciplinary approach of accounting user's different behavioral characteristics (Section~\ref{sec:chap003001} of Chapter~\ref{chap:chap003}) during decision-making~\cite{10.1145/3173574.3174156}.
Therefore, both \ac{HCI} and \ac{AI} communities need to bridge this gap with further collaboration and investigation for an understanding enhancement of \acp{HAII} in decision-making processes.

\ac{HAII} incorporates human feedback in the model training process to create better \ac{ML} models.
In this thesis, we refer to the topic as \ac{HAII}, which somehow is addressed by Amershi et al.~\cite{10.1145/3290605.3300233} providing a set of design guidelines~\cite{10.1145/3132272.3134111}.
The work of Kocielnik et al.~\cite{Kocielnik:2019:YAI:3290605.3300641} is also addressing the study on the impact of several methods of expectation setting, and others studied the design for specific \ac{HAII} scenarios~\cite{aha2017ai}.
\textcolor{revised}{While prior work relies on handcrafted features~\cite{10.1145/3290605.3300233, Kocielnik:2019:YAI:3290605.3300641}, our approach leverages rich image data features automatically learned from \ac{DL} algorithms adapted to the {\it end-user}.
Specifically, we focus on personalized and customized \ac{AI} suggestions tailored to varying levels of medical expertise.}

Many researchers have argued that \ac{HAII} would be improved if the \ac{AI} systems could {\it explain their reasoning}~\cite{10.1145/3411764.3445717, Rudin2022, Kawamleh2022}.
In medicine, explaining predictions from \ac{AI} models is particularly salient, where the uncovered patterns of the model can be more important than prediction performance~\cite{Lundberg2020}.
The literature demonstrates how to retain interpretability by developing a method to provide explanations of model predictions~\cite{10.1145/3544548.3580682}.
Although these works explore how clinicians interact with \ac{AI} recommendations and their perceptions of \ac{AI} outcomes, they are not taking into account cognitive bias in decision-making.
One of the most notorious cognitive differences is seen between people with different levels of expertise and knowledge~\cite{https://doi.org/10.1111/nuf.12430, Seidel2021}.
We are studying how assertiveness-based agents are designed to adapt their communication tone based on expertise levels to reduce cognitive bias.

\subsection{Assisting Clinical Decision-Making}
\label{sec:app005003002}

Although the research in interaction with intelligent agents is recent, still this topic has seen new advances, {\it e.g.}, chat-bots and other agents~\cite{miller2019intrinsically}.
Recent advances in medical technologies that promote data generation have continued to drive interaction research in the clinical domain~\cite{azuaje2019artificial, Lopes:2017:UHC:3143820.3144118}.
Moreover, the new interest of the medical community to support \ac{AI} research projects and the available public {\it datasets}, are encouraging researchers to work in both fields~\cite{lau2018dataset}.
Therefore, we bring together both \ac{HCI} and \ac{AI} communities to leverage the high-stakes of clinical decision-making.

The introduction of technology for assisting clinical decision-making is fraught with challenges and unintended consequences, such as critical decisions dealing with patient safety, clinician fatigue, and increased medical errors~\cite{10.1093/jamia/ocab291, 10.1117/12.2613082, doi:10.1148/radiol.212631}.
Moreover, clinicians find \ac{AI} systems challenging to use because they may have limited technical skills for adopting these novel technologies, where these technologies are not customized to the behavioral aspects of clinicians~\cite{CALISTO2022102922}.
The \ac{AI} outcomes are challenging to understand and communicate to clinicians, as these systems often have poorly designed interfaces~\cite{10.1145/3555157}, without considering differences in clinician's characteristics during decision-making.
For instance, the reasoning of a novice clinician varies from an expert~\cite{Edgar2022}.

There is a lack of large-scale deployment of these systems in healthcare~\cite{10.1145/3411764.3445432, SU202328, ZAPPATORE20231}, making it difficult to understand how these systems are perceived and used by their intended users in real-world settings.
\ac{HCI} has proposed and conceptualized several approaches to human-AI relationships, such as \ac{iML}~\cite{10.1145/3544548.3580682}, \ac{HITL}~\cite{10.1145/3397481.3450668}, human-\ac{AI} symbiosis~\cite{JARRAHI2018577}, and human-\ac{AI} collaboration~\cite{10.1145/3411764.3445432}.
However, these approaches mainly use human input to improve the prediction accuracy, model efficiency, and interpretability of \ac{AI} to the unwanted added burdens on healthcare professionals~\cite{10.1145/3555157, 10.1145/3397481.3450668}.
Wang et al.~\cite{10.1145/3411764.3445432} studied the perception and usage of \ac{AI} systems for assisting clinical decision-making, but the work is not accounting the potential differences between behavioral reasoning.
Similarly, the work of Panigutti et al.~\cite{10.1145/3491102.3502104} is only considering accurate algorithmic suggestions without considering the clinician's professional medical experience.

In conclusion, integrating \ac{AI} systems into clinical decision-making requires a holistic approach that considers not only the technical challenges but also the unique behavioral characteristics and professional expertise of clinicians.
The collaboration between \ac{HCI} and \ac{AI} communities is crucial in developing intelligent systems that are user-friendly, personalized, and effective in real-world healthcare settings.
By bridging the gaps between these disciplines and understanding the complex interactions between humans and \ac{AI}, we can ensure that \ac{AI} technologies in healthcare are designed to meet the specific needs of clinicians, ultimately leading to improved patient outcomes.
In our work, we contribute to addressing these literature gaps by focusing on the personalization and customization of algorithmic suggestions based on different levels of professional medical experience.

\subsection{Clinical Decision Support Systems}
\label{sec:app005003003}

In medical applications, \ac{DL} systems have also been the major contributor to the success of several \ac{CDSSe} applications~\cite{esteva2019guide}.
Such \ac{CDSSe} applications can detect and learn patterns or make predictions to assist clinicians, such as pathologists, or radiologists, among others, in high-stakes clinical decision-making~\cite{10.1145/3555157}.
For instance, on the diagnosis of skin cancer~\cite{Esteva2017}, the segmentation of cardiac \ac{MRI}~\cite{medley2019segmenting}, or breast cancer detection~\cite{MAICAS2019101562}, there are a variety of works where \ac{DL} systems were introduced for clinical purposes.
Their outstanding performance in identifying meaningful patterns within the available data was recently used to help humans learn new biomarkers of specific diseases.
Because of that, several works are arguing that these models can see beyond what a trained radiologist sees in medical images~\cite{McKinney2020, Rajpurkar2022}.
Although some works are already contemplating the idea of a \ac{CDSSe} that predicts and explains some \ac{AI} outcomes~\cite{MAICAS2019101562, CALISTO2022102285}, they ignore the need to adapt the communication tone for personalized and customized medicine.

Most of the best-performing \acp{CDSSe} rely on \ac{ML} algorithms that learn specific tasks from training data~\cite{10.1001/jama.2018.17163, 10.1145/3399715.3399744}.
The field recently gained enormous interest, primarily due to the practical successes of \ac{DL}~\cite{10.1007/978-3-030-22871-2_67}.
The rapid and widespread development of \ac{DL} methods supports a wide range of image analysis tasks in breast cancer diagnosis, including classification, detection, and segmentation \cite{lecun2015deep, DIN2022106073}.
These methods rely on large annotated datasets to learn essential and discriminative image features for each specific task, with performances matching and even surpassing humans \cite{Esteva2017}.
However, past works highlight several obstacles in going from research and development environments to the hospital or real clinical settings for these set of applications~\cite{https://doi.org/10.3322/caac.21552, 10.1145/3313831.3376718}.

The lack of utility to clinicians and logistical hurdles that slow or block deployment are frequent obstacles in real clinical settings.
Even systems with widespread adoption, such as systems to aid radiologists during breast cancer diagnosis, require them to do more work~\cite{KOHLI2018535}.
Instead of reducing the radiologist's workload or easing the clinical workflow, these systems are generally not improving the radiologist's diagnostic accuracy~\cite{KOHLI2018535}.

The work of Beede et al.~\cite{10.1145/3313831.3376718} studies the introduction of \ac{CDSSe} set of tools, primarily focusing on \ac{AI} systems that use clinical data.
However, they are not examining the use of real patient \ac{AI} predictions.
Our work covers this gap by, not only, incorporating real granular patient information from the \ac{AI} outputs, but also studying how to personalize and customize a \ac{CDSSe} for the clinical setting.

Across the \ac{HCI} literature~\cite{10.1145/3311957.3359433, 10.1145/3359206, 10.1145/3538882.3542790}, or more precisely, from the \acs{CHI} community~\cite{10.1145/3313831.3376718, 10.1145/3290605.3300234}, human-centered evaluation of interactive, \ac{DL} systems, is an open area of research within clinical environments.
Cai et al.~\cite{10.1145/3290605.3300234} created interactive techniques, leading to an increased diagnostic utility and user trust in the predictions from a \ac{DL} system, used by clinicians in a lab setting.
Correspondingly, Cai et al.~\cite{10.1145/3359206} examined in the lab setting what information clinicians found to be important when being introduced to \ac{AI} assistants, before integrating these assistants into routine prostate cancer screening practice.
While these works bring us closer to understanding the clinician's needs as they interact with \ac{DL}-based systems, they do not account for the heterogeneous behavioral nature of decision-making.

\subsection{Detailed Effects of AI Communication}
\label{sec:app005003004}

Trust is critical in communication (Section~\ref{chap:app002001} of Appendix~\ref{chap:app002}), especially, in clinical environments, where clinicians are exposed to critical scenarios that affect life decisions.
From the \ac{HCI} literature~\cite{10.1145/3479587, 10.1145/3334480.3375147, 10.1145/3334480.3382842}, we know that the development of trust is influenced by the positive motivational attribution between the communication entity and the user.
The work of Hohenstein et al.~\cite{HOHENSTEIN2020106190} is showing that a successful collaboration between humans and \ac{AI} occurs when ambiguity and uncertainty in terms of perceptions are reduced through trust~\cite{HOHENSTEIN2020106190}.
While communicating \ac{AI} predictions and explanations is shaping the design of recent works~\cite{Lundberg2020}, we do not know how assertiveness-based \ac{AI} mediation is affecting novice or expert clinicians.

To avoid unexpected clinical consequences, we need to understand the effects of \ac{AI} communication on human interactions.
In fact, the direct effects of communication are suggesting that clinicians' level of trust in an \ac{AI} system directly affects their perception of the outcomes~\cite{HOHENSTEIN2020106190}.
Panigutti et al.~\cite{10.1145/3491102.3502104} are arguing that higher levels of trust will cause the clinician to have a positive attitude, resulting in high satisfaction and positive perceptions of performance with respect to the interaction outcome.
Moderation via adapting the communication suggests that trust will influence how a clinician interprets and evaluates information relevant to attitude and behavior.
Attribution theory tells us that when behavior is consistent with explanations, humans will attribute causality to self characteristics and needs.
On the other hand, when behavior is inconsistent with prior expectations, where there is missing information or ambiguity, external cues will determine behavior~\cite{HOHENSTEIN2020106190}.
As an example, a novice clinician asking for help and receiving a suggestive, {\it i.e.}, non-assertive communication.
During a human-human interaction, a novice clinician would receive an assertive recommendation from an expert advisor.
The novelty of our work lies in applying assertive communication theories in an \ac{AI} system and clinical scenario.

\section{Assertiveness-based System Details}
\label{sec:app005004}

In this section, we provide further details of the system that were summarized in Section~\ref{sec:chap006003} of Chapter~\ref{chap:chap006}.
Clinicians can open the patient by selecting the ID in a list of patients.
When the patient is open (attribute 1 of Figure~\ref{fig:fig112}), clinicians can select each respective image of the breast, by dragging-drop each image to the view-ports.
From here, clinicians can manipulate the image through the toolbox (attribute 3 of Figure~\ref{fig:fig112}).
In the end, the idea is to {\it accept} or {\it reject} the final recommendation of the AI agent (attribute 5 of Figure~\ref{fig:fig112}), while clinicians can also ask for an {\it explanation} to support their final decision-making.
The key difference between the two AI agents was in how they show communication with clinicians.
A typical output from an AI model includes not only the predicted classification of the BIRADS, but also a likelihood distribution over all possible classification choices.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htpb]
\centering
\includegraphics[width=1.000\textwidth]{fig112}
\caption[]{Interface for conventional and assertiveness-based AI agents for medical imaging analysis. Attributes are associated with numbers in each testing condition. When a clinician hovers the mouse over each variable ({\it e.g.}, accuracy, BIRADS, or any other clinical argument of attribute 6), the AI agent will pop up a window to inform the severity of each finding. The colors are ranging from benign (green) to malign (red). The number of findings is displayed in a neutral blue color, reflecting the importance of individual severity rather than quantity. Clinicians use purple to indicate family and personal history variables.}
\label{fig:fig112}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In our study, both AI agents were designed to communicate this type of {\it quantitative} confidence in two ways (Figure~\ref{fig:fig098}):
(1) for the conventional condition, clinicians could simply see the suggested numeric representation of the BIRADS and the respective accuracy of the model;
(2) for the assertiveness-based condition, the agent was communicating the clinical arguments along with the communication of the BIRADS and accuracy, but this time by descriptive information.
While our conventional agent employed this baseline numeric representation of confidence, our assertiveness-based agent is communicating the {\it quantitative} confidence based on a descriptive sentence of the clinical arguments.
Specifically, the image view-port was augmented with an additional bounding box or circle ellipse {\bf highlighting the lesion characteristics} that were likely to explain the final BIRADS classification.
Note that these suggestions did not dictate the order in which imaging modalities are presented to clinicians.
Indeed, clinicians can remain to decide freely what modalities and clinical arguments are reviewed first.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htpb]
\begin{center}
\centering
\includegraphics[width=0.625\textwidth]{fig098}
\end{center}
\caption[]{Example of representative use cases for the different testing trials. From top to the bottom, the first agent is representing a conventional example (pink), while the other two are representing assertiveness-based examples (brown), from assertive to non-assertive communication.}
\label{fig:fig098}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

The patient's detailed augmentation for medical imaging on breast cancer diagnosis was extended with an {\bf assertiveness-based explanation}.
With our system, we are listing human-interpretable clinical arguments for classification and segmentation recommendations that would adapt their communication depending on the personalized and customized demographic characteristics of the clinician.
These clinical arguments corresponded to the classification outputs of an AI model and were trained on data (Section~\ref{sec:chap006005002}) from real-world clinical cases, as described next.

\section{Research Objectives}
\label{sec:app005005}

In this section, we provide a comprehensive overview of our research objectives, which are guided by the research questions and hypotheses outlined earlier (Section~\ref{sec:chap006004} of Chapter~\ref{chap:chap006}).
These research questions and hypotheses serve as a roadmap for our study across the influence of assertiveness-based agents on medical assessments and clinicians' perceptions.
Here, we delve deeper into the specific research questions and hypotheses listed in Section~\ref{sec:chap006004} of Chapter~\ref{chap:chap006}, offering a more detailed perspective on our investigation.
Through this in-depth description, we establish a solid foundation for our investigation, highlighting the key aspects and driving factors that shape our research direction.

Through our research, we aim to contribute to developing effective \ac{AI} systems that align with clinicians' needs and expectations, ultimately enhancing clinical decision-making processes.
While investigating the impact of assertiveness-based agents on medical assessments, we can identify ways to optimize efficiency and accuracy in clinicians' assessments.
Addressing the following research questions and hypotheses with subsequent analysis (Section~\ref{sec:chap006005005} of Chapter~\ref{chap:chap006}) will provide valuable insights that inform the design and implementation of \ac{AI} systems.
Ultimately, these insights will contribute to improving the quality and speed of medical decision-making, benefiting both clinicians and patients.

For {\bf RQ6.1}, we assume that personalized and customized explanations can inform clinical decision-making.
Therefore, it will increase clinicians' classification accuracy without reducing their time performance over diagnosis.
Primarily, we envision that adapting the communication of personalized explanations is crucial for successfully informing clinicians' decision-making.
For that, we propose three hypotheses about efficiency, accuracy, and the impact on different levels of clinicians' expertise.
Hypothesis {\bf H6.1.1} suggests that clinicians' efficiency, measured by the time performance per diagnosed patient, will be higher with an assertiveness-based agent.
Hypothesis {\bf H6.1.2} states that the classification accuracy of clinicians will not be compromised when using an assertiveness-based agent.
Hypothesis {\bf H6.1.3} suggests that the accuracy differences between novice and expert clinicians will depend on the tone of the personalized explanations provided by the assertiveness-based agent.
By investigating these hypotheses, we aim to shed light on the effectiveness of assertiveness-based agents in informing and supporting clinicians' decision-making processes.

The \ac{HCI} research community has settled that poor user perception can be a barrier to the adoption of technology regardless of performance~\cite{10.1145/3313831.3376506, 10.1145/3479549}.
The user perceptions of preference and trust are essential in predicting technology adoption.
Hence, it is crucial to investigate clinicians' perceptions, as we do in {\bf RQ6.2}.
Beyond the primary outcome regarding reliability in \ac{AI}-assisted clinical assessments, our goal is also to understand how clinicians perceive assertiveness-based agents.
Because of that, we propose four hypotheses related to clinicians' preference, trust, workload, and perception based on different levels of expertise.
Hypothesis {\bf H6.2.1} suggests clinicians prefer an assertiveness-based agent.
Hypothesis {\bf H6.2.2} states that clinicians will consider an assertiveness-based agent more trustworthy.
Hypothesis {\bf H6.2.3} suggests that personalized highlights and explanations provided by the agent will not increase clinicians' workload or decrease usability.
Finally, Hypothesis {\bf H6.2.4} proposes that novice and expert clinicians will perceive the reliability and capability of the agent differently, depending on the levels of assertiveness.
By examining these hypotheses, we aim to gain insights into how clinicians perceive and interact with assertiveness-based agents, contributing to the development of effective and user-centered \ac{AI} technologies in healthcare.

Addressing these research questions and hypotheses (Section~\ref{sec:chap006004} of Chapter~\ref{chap:chap006}) will provide valuable insights into the impact of assertiveness-based agents on medical assessments and clinicians' perceptions.
Our goal is to understand the efficiency and accuracy benefits that these agents can offer without compromising clinicians' valuable time in real-world clinical settings.
Moreover, we recognize the significance of clinicians' perceptions in the successful adoption and integration of intelligent agents into clinical practice.
Thus, developing \ac{AI} systems more effectively to support clinicians in their decision-making process and leading to improved clinical outcomes.

\section{Research Methods and Experimental Design}
\label{sec:app005006}

This section provides a comprehensive detail of the research methods and experimental design employed in our study, building upon the summarized methods outlined in Section~\ref{sec:chap006005} of Chapter~\ref{chap:chap006}.
As a way to improve clinical decision-making, the goal of our study is to attain a deeper understanding of personalized and customized mechanisms, exploring how to adapt the communication of agents depending on the medical experience of clinicians.
Our study draws from 52 semi-structured interviews and user testing with clinicians for breast cancer detection via medical imaging diagnosis.
To accomplish this goal, we designed and implemented a rigorous experimental approach.
Our study employed a two-condition study design, using a within-subjects and counterbalanced experiment.
By employing a within-subjects design, we ensured that each participant in our study experienced both conditions under investigation.
Each participating subject was involved in three distinct trials (Figure~\ref{fig:fig098}), allowing us to collect a wealth of diverse and comprehensive data to analyze.

\textcolor{revised}{Interviews were conducted between March 2022 and June 2022 as part of a comprehensive study that included 18 clinicians, each with unique expertise.
In addition to the interviews, we organized 12 focus group sessions over four months.
Each of these sessions, which lasted approximately 40 minutes, included 4 to 8 participants.
We carefully planned the duration and frequency of these sessions to ensure a thorough exploration of the clinicians' perspectives while accommodating their varying schedules.
This approach allowed us to gather diverse and in-depth insights into their experiences and opinions regarding the use of \ac{AI} in medical imaging.}

\textcolor{revised}{Each focus group session was carefully designed to foster an open and candid discussion environment while ensuring a comprehensive exploration of the critical topics.
The primary focus of these discussions revolved around three critical aspects: the usability of \ac{AI} agents in clinical settings, the interpretability of \ac{AI}-driven decisions and outputs, and the overall perceived effectiveness of these agents in enhancing clinical decision-making processes.
This setup enabled a detailed exploration of the clinicians' perspectives and allowed participants to progressively contemplate their experiences and insights.}

\textcolor{revised}{The focus group sessions, marked by their iterative nature and the diverse backgrounds of the participants, provided a wealth of insights into the practical application and implications of \ac{AI} in medical diagnostics.
These sessions led to the formulation of \acp{RQ}, as detailed in Section~\ref{sec:chap006004} of Chapter~\ref{chap:chap006}.
We utilized a user-centered approach that involved various activities.
These activities included workshops, focus groups, affinity diagramming, data clustering, and prototype co-design.
The goal was to identify and address specific problems reported during these sessions.}

\textcolor{revised}{Our participants came from various backgrounds, including clinicians from different healthcare institutions, \ac{ML} researchers, and \ac{HCI} experts.
Before the commencement of the study, we obtained ethical approval from the ethics committees of each clinical institution involved.
The following sections provide detailed information about our controlled experiment, including the task, dataset, participant demographics, study procedures, and the statistical analysis conducted to evaluate our hypotheses.}

\subsection{Task Details}
\label{sec:app005006001}


\textcolor{revised}{In Section~\ref{sec:chap006005001} of Chapter~\ref{chap:chap006}, we summarized participation tasks.
In this section, we offer more in-depth details about these participation tasks. Our study was conducted in the field of imaging classification for breast cancer diagnosis, a clinical area known for its high \ac{FP} rates, often resulting in over-diagnosis~\cite{KIM2020e138}.
Specifically, we compared the performance of our conventional \ac{AI} agent with that of an assertiveness-based agent in assisting trained medical personnel with breast cancer diagnosis.
For the conventional condition (\href{https://mida-project.github.io/prototype-multi-modality-assistant/}{git.io/JMjDi}), we utilized the publicly available {\it BreastScreening-AI} framework~\cite{CALISTO2022102285}, designed to develop medical assistants.
In addition to the existing functionalities of this framework, we developed two experimental conditions to test our hypothesis, which arose from a post-hoc analysis focused on personalizing and customizing \ac{AI} recommendations for clinicians.}

We raised several trials, from a more suggestive (non-assertive) to a more assertive tone of the \ac{AI} recommendations, where clinicians with different levels of expertise interacted with both trials and the conventional.
In the end, all clinicians interacted with one conventional, one non-assertive, and one assertive agent.
Each clinician diagnosed three patients with different severities, where the task was to {\it accept} or {\it reject} the \ac{AI} recommendations.
This experimental setup allowed us to examine how clinicians responded to different assertiveness levels and evaluate their decision-making processes.

There are two groups of clinicians with different medical professional experiences:
(a) novice; and
(b) expert.
Patients are divided into three groups of breast severities:
(i) low severity, representing the \ac{BI-RADS} of 1, meaning there are no findings for that patient and both breasts are healthy;
(ii) medium severity, representing the \ac{BI-RADS} of 2 and 3, meaning there are some findings with a higher probability of benign suspicious; and
(iii) high severity, representing the \ac{BI-RADS} of 4 and 5, meaning there are findings with a higher probability of malign suspicion.
Usually, each patient has available three types of modalities ({\it i.e.}, \ac{MG}, \ac{US}, and \ac{MRI}).
For this task, clinicians need to read six imaging views approximately per each patient:
(1) one \acs{CC} left breast;
(2) one \acs{CC} right;
(3) one \acs{MLO} left;
(4) one \acs{MLO} right;
(5) one \acs{US}; and
(6) one \acs{DCE-MRI} volume with between 100 and 200 frames.
Shortly, clinicians participated as readers while assessing each patient regarding the likelihood and location of the malignancy.

During the task of responding to the lesion localization, the reader clinician provides the severity classification of the clinical argument for that suspicious attribute on the image.
For each image, the clinician classifies the patient's final severity assessment via \ac{BI-RADS} classification by default.
Meaning that, although the patient has some clinical arguments ({\it e.g.}, group microcalcifications with diffuse distribution in Figure~\ref{fig:fig098}) pointing to a \ac{BI-RADS} of 2, if there is a suspicious irregular shape mass with spiculated margin, by default the clinician will consider the final \ac{BI-RADS} as a 5.

The task of diagnosing breast cancer involves reading heterogeneous appearances, ranging from obvious masses with spiculated margins to subtle asymmetric or faint microcalcifications~\cite{Sturesdotter2020}.
This leads to difficulties for clinicians in achieving an accurate diagnosis and consistent interpretation of the patient.
Because of that, clinicians apply rules from radiological guidelines to classify breast images based on visually inspecting the patterns on the image~\cite{doi:10.1148/radiol.2020192534}.

The classification of breast cancer via the \ac{BI-RADS} scale lends itself to a task for our study on AI agents in medical imaging assessments.
Not only, is the task a time-consuming and tedious procedure for clinicians, but it also relies on non-trivial classification tasks.
Indeed, the prior medical literature has established that the medical error of clinicians has between 50\% and 30\% chance of being a false-positive and about 10\% chance of being a \ac{FN}.

\subsection{Dataset Details}
\label{sec:app005006002}

\textcolor{revised}{In Section~\ref{sec:chap006005002} of Chapter~\ref{chap:chap006}, we provided an overview of the dataset used in our study.
In this section, we will delve into the specifics of this dataset, which consists of a total of 338 cases obtained from \acl{HFF} (Section~\ref{sec:app005006003}).
Among these cases (Section~\ref{sec:app001002}), 289 were meticulously classified by the head of radiology.}

\textcolor{revised}{Each patient's dataset includes several images, encompassing four X-ray \ac{MG} images (two in \ac{CC} and two in \ac{MLO} views), one \ac{US} image used for training the DenseNet model, and approximately \acs{DCE-MRI} images obtained through \ac{MRI} to train the ResNet model.
In the context of \ac{MRI}, multiple image slices were acquired for each patient, specifically in the presence of a lesion.
This results in a dataset of approximately 2890 images ({\it i.e.}, 289~\texttimes~(4 + 1 + 5)), calculated as 289 patients multiplied by the sum of images from different modalities (4 from \ac{MG}, 1 from \ac{US}, and 5 from \ac{MRI}).
These images serve as the basis for training and testing our \ac{AI} models.}

\textcolor{revised}{Both traditional image processing and \ac{DL} techniques demand comprehensive pre-processing procedures.
It is well-established that preparing a clean dataset is essential when training deep neural networks, as noted in prior research~\cite{RIASATIAN2021102032}.
In our study, the pre-processing stage holds paramount significance due to the diverse characteristics of the \ac{MG}, \ac{US}, and \ac{MRI} images, which exhibit variations in intensity and size.
We undertake thorough data pre-processing to address these differences and ensure compatibility with the DenseNet and ResNet models, as outlined in Section~\ref{sec:app001006}.
Specifically, this pre-processing includes data normalization procedures aimed at standardizing the intensity levels of the images across all modalities.
This step ensures consistent intensity levels across images from different modalities, making them suitable for analysis and model training.}

\textcolor{revised}{In our pre-processing pipeline, all images are resized to a consistent 224x224 pixel dimension, promoting uniformity and compatibility with the models used.
Following resizing, images undergo normalization, a crucial step for \ac{DL} model data preparation, involving mean subtraction and standard deviation division.
This process standardizes intensity levels across images, regardless of modality or source.
The 224x224 pixel size aligns with the DenseNet model format employed in our research, ensuring seamless integration for effective training and analysis.}

\subsection{Participation Details}
\label{sec:app005006003}

In Section~\ref{sec:chap006005003} of Chapter~\ref{chap:chap006}, we summarized the demographic characteristics of our study participants and the clinical institutions involved.
Now, we will provide a more detailed description of the participants and clinical institutions that collaborated with us in this work.
We recruited 52 clinicians who volunteered to participate in our study from a diverse range of clinical environments (Table~\ref{tab:tab015} on Section~\ref{sec:app005011}), including public hospitals, cancer institutes, and private clinics.

% \vspace{0.50mm}

\noindent
Our clinicians were recruited through the already established protocols under this study from 11 different clinical institutions:

\vspace{0.05mm}

\begin{enumerate}
\item \href{https://hff.min-saude.pt}{\acf{HFF}};
\item \href{https://www.ipolisboa.min-saude.pt}{\acf{IPOL}};
\item \href{https://www.chln.min-saude.pt}{\acf{HSM}};
\item \href{http://www.ipocoimbra.min-saude.pt}{\acf{IPOC}};
\item \href{http://www.madeiramedicalcenter.pt}{\acf{MMC}};
\item \href{https://www.sams.pt}{\acf{SAMS}};
\item \href{http://www.chbm.min-saude.pt}{\acf{HB}};
\item \href{https://www.chporto.pt}{\acf{HSA}};
\item \href{https://www.fchampalimaud.org/}{\acf{CF}};
\item \href{https://www.chtmad.min-saude.pt/}{\acf{CHTMAD}}; and
\item \href{https://www.chlo.min-saude.pt/}{\acf{CHLO}};
\end{enumerate}

\vspace{0.05mm}

All clinicians and clinical institutions gave prior permission to use their data for research purposes under this study.
From the demographic questionnaires (Appendix~\ref{chap:app006}), 55.77\% of participants are expert clinicians, whereas 34.62\% are seniors having more than 10 years of practical experience, and 21.15\% are middle clinicians having more than 5 years but less than 10 years.
Similarly, 44.23\% of participants are novice clinicians, whereas 32.69\% are juniors after taking the exam, having up to 5 years of clinical experience, and 11.54\% are interns before the medical specialty exam.
Each clinician was exposed to the three trials ({\it i.e.}, conventional, assertive, and non-assertive) in a counter-balanced manner.

\subsection{Procedure Details}
\label{sec:app005006004}

In Section~\ref{sec:chap006005004} of Chapter~\ref{chap:chap006}, we provided a summarized description of the procedure followed in the study.
Across this section, we further detail some procedures.
After providing an informed consent form for participation in the study, each clinician reported information concerning several self-characteristics (Section~\ref{sec:chap006005003} of Chapter~\ref{chap:chap006}).
First, they reported their demographic characteristics.
Second, they reported their professional backgrounds, such as clinical education ({\it i.e.}, radiology, surgery, nurse, technician, etc.), areas of expertise, work sector, and medical experience.
Finally, information about their experience while reading medical imaging data.
Next, clinicians familiarized themselves for about 3 minutes with our user interface and basic functionalities common to both \ac{AI} agents.

At this stage, each participant interacted with the assistant, {\it accepting} or {\it rejecting} the system suggestion in the two different conditions: (a) conventional; and (b) assertiveness-based.
The set of patients provided participants with 289 patients, while all patients must have at least one of the three available modalities.
Each participant open the set of three patients ({\it e.g.}, {\bf P1}, {\bf P2} or {\bf P3}), chosen randomly, and examined it.
As participants interacted with the system, they could utilize a range of functionalities and tools designed to support their diagnostic tasks.
These functionalities enabled clinicians to access relevant information, perform detailed analysis, and make informed decisions.

Clinicians performed the same task of diagnosing three patients twice, once with the conventional agent and another time with the assertiveness-based agent.
For each task, clinicians were asked to read the suggested \ac{AI} recommendations, where the task ends when clinicians {\it accept} or {\it reject} the proposed \ac{BI-RADS}.
Additionally, clinicians could ask for a visual {\it explanation} inside the image during the task.
The \ac{AI} models fully classified the list of patients, and clinicians could revise the explanations (bounding boxes 2 and 4 of Figure~\ref{fig:fig096}) for the crucial regions to consider.

After each task, clinicians completed a brief feedback questionnaire exploring their perception of each \ac{AI} agent.
The questionnaire included scales to measure three dimensions of trust represented by perceived understanding, competence, and thoughtfulness, cognitive workload using \ac{NASA-TLX}, and usability using \ac{SUS}.
With these measures, we aimed to understand the perceived diagnostic utility and decision-making support provided by the \ac{AI} agents, and whether clinicians thought they would use the agents in practice.
Upon completing all the tasks, we measure the preferences using conventional or assertiveness-based agents, and the different levels of assertiveness.

\textcolor{revised}{Clinicians played a pivotal role in our study, offering assessments on the reliability, capability, and overall preference for both \ac{AI} agents.
To further explore the impact of assertiveness, we compared ratings by novice and expert clinicians.
Our assessment focused on the effectiveness of the communication tones employed by the assertiveness-based agent, ranging from suggestive to imposing \ac{AI} recommendations.
To gather these insights, clinicians used a 7-point Likert scale, enabling a comprehensive evaluation of their perspectives on assertiveness levels and communication styles.}

\subsection{Specified Analysis}
\label{sec:app005006005}

\textcolor{revised}{In Section~\ref{sec:chap006005005} of Chapter~\ref{chap:chap006}, we presented a summary of the analysis carried out in our study.
This section will provide a more comprehensive explanation of the specific analysis procedures conducted.
We will delve into the details of our investigation, focusing on research questions, hypotheses, and the statistical tests employed.
Our analysis is designed to explore the impact of the assertiveness-based agent on clinicians' efficiency and efficacy in diagnosing patients and their perceptions of both conventional and assertiveness-based agents.
Additionally, we will discuss the qualitative methods used to extract valuable insights from clinicians' feedback and comments.}

For {\bf RQ6.1}, we investigated the impact of our assertiveness-based agent on clinicians' efficiency and efficacy in terms of time performance and accuracy in diagnosing patients with the support of the AI-suggested recommendations.
Similar to the literature, we used the one-way \ac{ANOVA} test~\cite{SADEGHI2022105554, 10.1145/3491102.3517791} to compare both AI agents with respect to the following outcome measures per clinician:
(i) the time (in seconds) for diagnosing each patient ({\bf H6.1.1.}); and
(ii) accuracy rates via false-positives and false-negatives of clinician-provided classifications ({\bf H6.1.2.}).
For the efficacy differences between novice and expert clinicians during decision-making ({\bf H6.1.3.}), we used the chi-squared test of independence~\cite{10.1145/3411764.3445464} to assess the relationship between the expertise of clinicians and the assertiveness levels of the agents.
Regarding human-AI accuracy, our dataset has post-biopsy verification, meaning that we could measure the real \ac{GT} of the patient.

For {\bf RQ6.2}, we compared clinicians' perceptions of both conventional and assertiveness-based agents.
A possible observed pattern in perceived preference ({\bf H6.2.1.}) and trustworthiness ({\bf H6.2.2.}) was examined using the \ac{ANOVA} test and statistical significance (p $<$ 0.05) for testing our hypothesis.
Reported scores for cognitive workload and usability ({\bf H6.2.3.}) were compared between the two AI agents using statistical significance (p $<$ 0.05) for computing the likelihood of confidence.
\textcolor{revised}{Lastly, we used the one-way \ac{ANOVA} test to assess assertiveness levels in the clinical arguments provided by the two groups, novice and expert clinicians, based on their medical professional experience.}
Specifically, we used this test to measure clinicians' perceived preferences regarding reliability and capability ({\bf H6.2.4.}).
From ``Totally Non-Assertive'' ({\it i.e.}, more suggestive) to ``Totally Assertive'' ({\it i.e.}, imposing \ac{AI} recommendations), we test the overall tendency between novice and expert clinicians of the communication tone.

\textcolor{revised}{In our extensive analysis, we integrated open coding comments and feedback from various focus group sessions, workshops, and interviews.
These sessions were specifically structured to promote thorough discussions about the usability, interpretability, and effectiveness of \ac{AI} agents in clinical decision-making.
The primary aim of these sessions was to identify and extract emerging themes from the open-ended discussions, thereby enriching the context of our findings, as referenced in~\cite{SHIBUYA2022107131, BIEG2022107249}.}

\textcolor{revised}{To effectively organize and analyze the clinicians' responses, we employed affinity diagrams, concentrating on their insights regarding workflow practices and the core functional concepts of the intelligent agents.
This approach, supported by literature~\cite{DEUTSCH2019122, 10.1145/3491101.3519863}, enabled us to meticulously categorize the data, uncovering underlying patterns and preferences in a detailed manner.
Affinity diagramming also played a crucial role in revealing clinicians' preferences and concerns, utilizing thematic coding techniques like card sorting for efficient data interpretation.
The insights from these sessions informed our approach to personalizing \ac{AI} recommendations by tailoring the communication tone to meet clinicians' needs and expectations.
The in-depth feedback and thematic analysis conducted during these sessions deepened our understanding of clinicians' requirements from \ac{AI} systems in medical imaging, guiding the development of user-centric \ac{AI} medical imaging systems to ensure effectiveness and usability.}

\textcolor{revised}{Our findings enabled us to bridge the gap between technological capabilities and clinical usability, ensuring that the \ac{AI} systems meet technical standards and resonate with the practical realities of medical professionals.
As a result of this analysis, the enhanced alignment between \ac{AI} functionalities and clinicians' workflows promises to improve the efficiency and accuracy of clinical decision-making processes.}
Clinicians were asked to reflect on their decisions, what information they need to be explained by the \ac{AI} models, and why they need that.
\textcolor{revised}{These qualitative analysis methodologies identify emerging themes in the data, revealing design considerations.}
In Section~\ref{sec:chap006006003} of Chapter~\ref{chap:chap006}, recurring themes are reported as we detail them, with provided feedback and comments from these sessions with clinicians.

\section{Detailed Outcomes Investigation}
\label{sec:app005007}

This section expands upon the summarized results presented in Section~\ref{sec:chap006006} of Chapter~\ref{chap:chap006}, offering a more comprehensive data analysis.
To test our hypotheses, we used the \texttt{scipy} library from \texttt{python} to conduct a one-way \ac{ANOVA} test, with the level of medical professional experience as the main factor on the dependent variables~\cite{CASALE2022107302}.
\textcolor{revised}{The alpha level ($\alpha$ = 0.05) was set for statistics, and effect size quantitatively measured the magnitude of the experimental comparison between variables~\cite{Yigit_Mendes_2018, 10.1145/3180155.3182556}.
Briefly, we focus on statistically significant results and selectively report them to address our hypotheses, following literature recommendations~\cite{10.1145/3301275.3302289, 10.1145/3290605.3300234, 10.1145/3491102.3517791}.}
Next, we investigate the time performance (Figure~\ref{fig:fig099}, Section~\ref{sec:chap006006001} of Chapter~\ref{chap:chap006}), accuracy (Figure~\ref{fig:fig084}, Section~\ref{sec:chap006006001} of Chapter~\ref{chap:chap006}), and decision (Table~\ref{tab:tab014}) rates of clinicians, while addressing their preference choices (Figure~\ref{fig:fig085}), agreement comparisons (Table~\ref{tab:tab013}, Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}), reliability and capability (Figure~\ref{fig:fig091}, Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}).

\subsection{RQ6.1: Assertiveness-Based Agent Impact on Medical Assessments}
\label{sec:app005007001}

In Section~\ref{sec:chap006006001} of Chapter~\ref{chap:chap006}, we summarized some of our obtained results to answer question {\bf RQ6.1}.
In this section, we provide detailed results to answer our {\bf RQ6.1}.
These findings offer insights into how incorporating intelligent agents with assertive communication capabilities can optimize the diagnostic process, potentially leading to improved patient care and outcomes.

We hypothesized that using the assertiveness-based communication between clinicians and an intelligent agent, would alter clinicians' workflow and increase the time performance of clinicians ({\bf H6.1.1.}) during patient diagnosis.
On average, the time performance of clinicians was significantly improved with the assertiveness-based agent (M = 124.02 seconds, SD = 44.60 seconds) than with the conventional agent (M = 166.12 seconds, SD = 60.42 seconds), confirming our hypothesis (Figure~\ref{fig:fig099}, Section~\ref{sec:chap006006001} of Chapter~\ref{chap:chap006}).
This difference was significant (F = 11.32, p = 0.005 $<$ 0.05), indicating a large effect size (r = 0.49).
These findings highlight the positive influence of assertiveness-based communication on clinicians' efficiency and suggest its potential as a valuable tool in the context of patient diagnosis.

In addition to our investigation, we hypothesized ({\bf H6.1.2}) that using an assertiveness-based agent would not harm clinicians' accuracy.
Our analysis of the results (Figure~\ref{fig:fig084}, Section~\ref{sec:chap006006001} of Chapter~\ref{chap:chap006}) revealed no significant difference in accuracy (F = 1.85, p = 0.37 $>$ 0.05).
These findings support our hypothesis, indicating that the assertiveness-based explanations did not negatively affect clinicians' ability to classify patients.
Consequently, the integration of the assertiveness-based agent into clinical settings can proceed without compromising the accuracy of patient diagnoses.
Moreover, Table~\ref{tab:tab014} presents additional insights into clinicians' acceptance and rejection rates of \ac{AI} recommendations, further reinforcing our conclusions and demonstrating the robustness of the assertiveness-based approach.
Overall, our study contributes valuable evidence to support the adoption of assertiveness-based agents in medical settings, offering improved workflow and decision-making without compromising diagnostic accuracy.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{tables/tab014}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We further examined the potential impact of personalized explanations by customizing the agent communication differently between the two groups of professional medical experience, {\it i.e.}, novice and expert clinicians ({\bf H6.1.3.}).
We observed a significant association between the levels of assertiveness ({\it e.g.}, from non-assertive to assertive communication tone of the clinical arguments) and the medical professional experience while revising \ac{AI} recommendations ($\chi^2$ = 3.84, p = 0.001 $<$ 0.05).
In other words, the chance of a patient getting classified correctly by a novice was significantly higher (Accuracy\textsubscript{novice} = 91\%) with the assertive agent ({\it i.e.}, imposing \ac{AI} recommendations) than with the non-assertive ({\it i.e.}, more suggestive \ac{AI} recommendations).
On the contrary, the chance of correctly classifying the patient by an expert clinician was slightly higher (Accuracy\textsubscript{expert} = 78\%) with the non-assertive agent.
\textcolor{revised}{Novices had a 17.4\% higher chance of correct classification with the assertive agent, whereas expert clinicians had a 4.4\% higher chance with the non-assertive agent.}

Finally, Table~\ref{tab:tab014} shows how often clinicians accept or reject the \ac{AI} recommendations, as well as how often they switch to a different conclusion.
The highest overall correct rate was 81.59\% in the assertive trial for novice clinicians and 66.41\% in the non-assertive trial for expert clinicians.
Moreover, experts are switching to fewer wrong decisions with the non-assertive agent (Total = 33.59\%).
On the other hand, novices are switching to less wrong decisions with the assertive agent (Total = 18.41\%).

Overall, clinicians made better decisions with assertiveness-based assistance while exploring how to adapt the communication tone.
The results suggest that the assertiveness-based condition may have been more favorable to novice and expert clinicians, with higher correct acceptance and correct reject rates than the conventional condition.
The results highlight the importance of scenario design in evaluating clinicians' performance, as the trials significantly impacted the performance of both novice and expert clinicians.

\subsection{RQ6.2: Assertiveness-Based Agent Perceptions of Clinicians}
\label{sec:app005007002}

In Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}, we presented a summary of our findings on question {\bf RQ6.2}.
In this section, we delve deeper into the detailed results obtained to address our research question. Our focus for {\bf RQ6.2} was to investigate clinicians' perceptions of both \ac{AI} agents.
By examining clinicians' feedback and perspectives, we gained valuable insights into their experiences and attitudes toward assertiveness-based and conventional agents.
These insights provide a comprehensive understanding of how clinicians perceive and interact with the \ac{AI} technology in the context of medical assessments.

The results for our hypothesis ({\bf H6.2.1}) that clinicians would have a preference (Figure~\ref{fig:fig085} on Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}) for an assertiveness-based agent were statistically significant (F = 8.35, p = 0.001 $<$ 0.05) between the groups of interns, juniors, middles, and seniors with a large effect size (r = 0.41).
Out of the 52 participants who expressed a preference, 66\% preferred the assertiveness-based agent, and another 24\% preferred the conventional agent, while 10\% did not have a preference.
These findings highlight the importance of considering clinicians' preferences and the potential benefits of incorporating assertiveness-based communication in medical decision-making processes.

We also examined the perceived trust and understanding of clinicians towards both the conventional and assertiveness-based agents (Table~\ref{tab:tab013}, Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}).
The results showed slight differences (F = 19.47, p = 0.06 $>$ 0.05) in overall perceived trust between the two agents, indicating a comparable level of trustworthiness.
There were no significant differences (p = 0.14 $>$ 0.05) in understanding between the agents.
\textcolor{revised}{The assertiveness-based agent was perceived to have greater competence (p = 0.04 $<$ 0.05), suggesting it was seen as more capable.}
Additionally, clinicians demonstrated higher levels of thoughtfulness with the assertiveness-based agent than with the conventional agent (p = 0.001 $<$ 0.05), indicating a more engaged and attentive response.
These findings partially support our hypothesis ({\bf H6.2.2.}) regarding trust, understanding, competence, and thoughtfulness.

We also evaluated if there were no significant differences in workload and usability between conventional and assertiveness-based agents.
Specifically, there were no significant differences between the workload scores of the two \ac{AI} agents on \ac{NASA-TLX} (p = 0.38 $>$ 0.05).
Furthermore, we observed no significant differences between the usability scores on \ac{SUS} (p = 0.38 $>$ 0.05).
\textcolor{revised}{Hence, this supports our {\bf H6.2.3.} hypothesis that personalized recommendations do not harm clinicians' workload or usability.}

Finally, to assess how clinicians perceive the levels of assertiveness differently (Figure~\ref{fig:fig091}, Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}), we compared the preferences in terms of reliability and capability from non-assertive (suggestive) to assertive (authoritative) communication of the clinical arguments.
Here, we can denote that there are significant differences in reliability (F = 31.36, p = 0.0001 $<$ 0.05) and capability (F = 18.17, p = 0.0003 $<$ 0.05) between groups of novice and expert clinicians.
Novice clinicians perceived assertive communication as more reliable (61\%), although not mainly feeling the same for capability (48\%).
On the other hand, expert clinicians perceived non-assertive communication as more reliable (69\%) and capable (66\%).
Therefore, we can observe that the {\bf H6.2.4.} hypothesis is supported by showing that novice and expert clinicians will perceive differently the provided clinical arguments depending on if the agent is imposing the \ac{AI} recommendations or being more suggestive.

\subsection{Qualitative Insights}
\label{sec:app005007003}

\textcolor{revised}{Following a similar approach described in Section~\ref{sec:chap005005004002} of Chapter~\ref{chap:chap005}, we adopted a participatory approach to qualitatively analyze our study results.
This analysis was based on data collected from focus group sessions, including participant opinions and transcripts.
Over four months, we engaged 18 participants with diverse expertise in 12 sessions, each lasting approximately 40 minutes.
These sessions were structured to encourage open discussions, focusing on how clinicians interpret and utilize \ac{AI} recommendations in their workflow.
We used emergent affinity diagrams to identify and categorize common themes regarding participants' preferences for receiving clinical arguments and visualizing \ac{AI} recommendations.
This method helped systematically analyze the data, uncovering insights into clinicians' preferences and concerns, influencing their decision-making processes in clinical settings.}

\textcolor{revised}{Our qualitative analysis extended beyond participant responses to open-ended survey questions.
It provided a deeper understanding of how assertiveness-based agents could impact clinicians' workflows and mental models.
This detailed analysis, which builds upon the summary provided in Section~\ref{sec:chap006006003} of Chapter~\ref{chap:chap006}, highlights the nuances of clinicians' interactions with \ac{AI} systems.
It underscores the importance of designing \ac{AI} tools that are technically proficient and tailored to medical professionals' specific needs and cognitive processes.}

\subsubsection{Altering Clinical Workflows}
\label{sec:app005007003001}

To validate the proposed design, we discussed with clinicians how could they use these set of personalized agent communications to perform diagnosis on a real clinical environment.
The goal is to understand whether an assertiveness-based agent can (a) be compatible integrated into clinicians' workflow, and (b) provide added values to clinicians' diagnosis process.
Next, we summarize the main opinions of clinicians between conventional and assertiveness-based assistance, as well as between suggestive (non-assertive) and more imposing (assertive) AI recommendations.

One major criticism to the traditional approach of representing the AI recommendations with numeric BIRADS classification, accuracy of the output and heatmap values is that it is not sufficient for clinicians to make sense of the decision-making reasoning behind the output classifications.
In particular, when the output accuracy is lower than 80\% confidence.
Our qualitative findings suggest that in choosing between numeric representations of the AI output classifications and human-interpretable arguments while exploring how to adapt the communication, clinicians found the latter to be more effective during decision-making.
This highlights the necessity for AI systems to be designed with a user-centered approach~\cite{10.1145/3491102.3517789}, taking into account the preferences and needs of the end-users (in this case, clinicians) to ensure that they are usable and effective in real-world scenarios.

\vspace{2.5mm}

\noindent
Specifically, a middle clinician ({\it i.e.}, expert clinician) reported:

\vspace{2.5mm}

\noindent
``{\it When I was interacting with the AI agents, the first thing I did was to find classification conflicts between the final BIRADS of the patient, the BIRADS of each image, output accuracy, and clinical arguments. Something that I couldn't do so well in the first [conventional] agent, but could do better for the second [assertiveness-based] one.}'' (C51)

\vspace{2.5mm}

In domains where clinicians' availability is rare, it can be exceedingly hard to obtain an immediate second reader every time a clinician needs the opinion of another human expert.
Clinicians shared a positive attitude towards the use of an assertiveness-based agent to aid their decision-making, since we are exploring how these set of agents are adapting the communication depending on the level of professional medical experience.
Something that is common when a senior (assertively) talks to an intern, while our agent is mimicking the same communication conditions.
Such mimicking behavior must be designed to help diagnosis without incurring in learning misinformation that interrupts the main clinical workflow.

\noindent
Here, a senior clinician ({\it i.e.}, expert clinician) is sustaining the above argument by reporting that:

\vspace{2.5mm}

\noindent
``{\it Adapting the communication between more suggestive [non-assertive] or assertive tone of the clinical arguments can help the diagnosis workflow. I may prefer a suggestive agent, but an assertive agent will be more helpful for my interns concerning an educational purpose.}'' (C15)

\vspace{2.5mm}

Categorically, clinicians were mostly stating that they could understand how such personalized communication could be beneficial to customize the interaction between humans and AI.
In particular, clinicians valued the opportunity to choose the communication tone to explore the clinical arguments in a more detailed fashion.
Our qualitative findings suggest that most clinicians (48/52) found the assertiveness-based agent to be more helpful and reliable.
These findings also support our claim that customization could have a positive impact on the decision-making process and improve the overall effectiveness of AI-assisted systems.

% \vspace{2.5mm}

\noindent
As another example, a junior clinician ({\it i.e.}, novice clinician) reported that:

\vspace{2.5mm}

\noindent
``{\it When the agent is talking to me in a more assertive way, I can feel more safe of my decision... and feeling more assurance of the right answer.}'' (C17)

\vspace{2.5mm}

This analysis further highlights the effectiveness of the assertiveness-based agent in personalizing and customizing the communication of the agent, taking into account differences of medical professional experience.
That is, 37 out of 52 clinicians in our study explicitly mentioned that their workflow differed between the two agents.
Particularly, clinicians showed different confidence and trusting opinions depending on the levels of assertiveness.

\vspace{2.5mm}

\noindent
For instance, an intern clinician ({\it i.e.}, novice clinician) reported that:

\vspace{2.5mm}

\noindent
``{\it It seems like, when I was interacting with the more suggestive [non-assertive] assistant, it has the same doubts on the communication tone as I am. The more assertive assistant gave me higher confidence in the decision.}'' (C10)

\vspace{2.5mm}

\noindent
On the other hand, a senior clinician ({\it i.e.}, expert clinician) reported the following:

\vspace{2.5mm}

\noindent
``{\it In my opinion, I don't like the communication tone and the way assertive agents are reporting the clinical arguments. Imposing the AI recommendations feels like I need to follow the orders they give to me. I prefer a more suggestive agent, asking me if the clinical arguments are well classified or not.}'' (C49)

\vspace{2.5mm}

To conclude, these levels of personalizing and customizing the agent communication ({\it e.g.}, from less assertive to more assertive) are important to take into account when designing systems for critical domains.
Especially, for decision-making under these clinical workflows.
We found that assertiveness-based not only enhanced decision-making, but also helped clinicians to develop a mental model of the AI agents, or probe for the likelihood of the diagnosis.
Next, we describe in what manner our work is leveraging these insights.

\subsubsection{Agent Mental Models}
\label{sec:app005007003002}

This section examines how clinicians develop mental models of assertiveness-based agents, with expert clinicians using communication tones to anticipate \ac{AI} mistakes and novice clinicians focusing on the learning process.
Effective communication and personalized approaches are crucial for designing intelligent agents that cater to the perspectives of both groups.
Additionally, clinicians form comparative mental models when comparing conventional and assertiveness-based agents, highlighting the importance of effective communication.
These insights inform the design of intelligent agents that offer personalized communication, catering to the perspectives of both novice and expert clinicians while adjusting the levels of assertiveness.

\textcolor{revised}{Both novice and expert clinicians have preconceived mental models about assertiveness levels.
Expert clinicians used the output results to disambiguate \ac{AI} errors from their errors, depending on the communication tone.}
It is, therefore, possible that this reasoning behavior is projected onto the \ac{AI} agent to anticipate where the agent would likely make mistakes:
``{\it It could be also important to adapt the communication tone of the clinical arguments depending on the \acs{AI} confidence.}''
\textcolor{revised}{From here, we understand that expert clinicians expect the assertiveness of a clinical argument to adapt depending on the accuracy of the \ac{AI} output results for that variable.}
On the contrary, novice clinicians were more focused on the learning process and patient comparisons for educational purposes:
``{\it For me, the most important thing was to look at the provided arguments and understand if they are right from what I learn or from similar cases.
A junior like me must know how the machine is thinking to follow the same reasoning process from my side mentally.}''
Hence, it is vital to provide a more `{\it storytelling-like}' view of the patient for novice clinicians, even in a more assertive fashion.

Apart from preconceptions, we further observed that clinicians developed comparative mental models between conventional and assertiveness-based agents:
``{\it The first \acs{AI} [assertiveness-based] was outstanding… but in the second \acs{AI} [conventional] I was frustrated with the lack of communication in comparison to the first one.}''
Moreover, the interaction experience of clinicians with the different \ac{AI} agents can also shape their reasoning while looking for \ac{AI} recommendation mistakes:
``{\it In the second assistant [assertiveness-based], I look for classification conflicts between the final BIRADS and the clinical arguments, while I couldn't do the same for the first assistant [conventional], taking me more time to see if there are some mistakes.}''

\textcolor{revised}{Our intelligent agents can leverage these insights by providing personalized communication with different perspectives between novice and expert clinicians, while adjusting internal representations of assertiveness levels.}
Yet, without hurting the time performance of the diagnostic (Section~\ref{sec:chap006006001} of Chapter~\ref{chap:chap006}), nor increasing the workload (Section~\ref{sec:chap006006002} of Chapter~\ref{chap:chap006}).
In sum, these observations support growing evidence that considering the communication of the \ac{AI} outputs ({\it e.g.}, structure, order, and tone of the arguments) can alter the clinicians' perceptions of the mental models of assisting agents.

\section{Insights and Recommendations}
\label{sec:app005008}

\textcolor{revised}{In Section~\ref{sec:chap006007} of Chapter~\ref{chap:chap006}, we discussed the impact of personalized communication from assertiveness-based agents on clinicians' decision-making in medical imaging diagnosis.
This section explored the influence of such communication strategies on clinicians' decision-making, examining the nuanced relationship between assertiveness and clinical expertise.
In the upcoming sections, we will analyze insights and provide recommendations for designing intelligent agents in medical imaging, aiming to enhance their usability and effectiveness for novice and expert clinicians.}

Overall, the classification accuracy remained unaffected by the incorporation of assertiveness-based communication.
However, our study revealed a significant impact of the explanation tone on the decision-making behavior of novice and expert clinicians.
This finding underscores the importance of developing compliant agents that can offer personalized and tailored explanations to better cater to the specific needs of clinicians.
These future directions in agent development and validation aim to enhance the provision of relevant and customized explanations \textcolor{revised}{(Section~\ref{sec:app005019})}, further improving the effectiveness of intelligent agents in medical imaging diagnosis.

Participants were keener on following \ac{AI} recommendations that adapt their communication tone than the ones that did not.
Although this effect may occur because of adding more explanations, it is reflected in differences in behavioral decisions between novice and expert clinicians.
We gain even more insight into the effect of tone from the feedback provided by the clinicians across our qualitative analysis.
Our qualitative results show that participants appreciate the idea of adapting tone to probe the likelihood of the diagnosis.
This finding might be in line with the previous research in psychology and decision support science~\cite{Seidel2021}, bringing new directions for the theoretical application of assertiveness-based communication in \ac{AI} systems and clinical domains.

\textcolor{revised}{In our study, we focused on personalizing and customizing \ac{AI} recommendations based on clinicians' varying professional experience, with the primary goal of assessing whether tailoring these recommendations could reduce medical errors and increase overall satisfaction among clinicians.
Our analysis revealed significant differences in accuracy, perceived reliability, and perceived capability when comparing novice clinicians with their expert counterparts, and these disparities were notably influenced by the tone and style of personalized explanations provided by the \ac{AI} agents.
These findings have important implications for designing and implementing \ac{AI} agents in healthcare.
They emphasize the significance of customization and personalization in enhancing user experiences and outcomes in clinical settings.}

Clinicians' overall preferences and perceived trust were also increased for the assertiveness-based agent compared to the conventional.
Results suggest a significantly higher perceived understanding of the assertiveness-based agent than the conventional variant.
At the same time, the assertiveness-based agent showed to be perceived by clinicians as more competent and thoughtful.
However, our results indicate the existence of other latent variables.
For instance, the demographic characteristics of clinicians with different levels of clinical experience could shape the implementation of intelligent agents to consider the differences in clinicians' perception of \ac{AI} systems generally.

\textcolor{revised}{In the context of the \ac{HCI} community, our research holds particular significance due to its emphasis on the utilization of intelligent agents in the field of medical imaging.
Given its potential impact on healthcare and clinical practices, this domain is increasingly recognized as a crucial area of study within \ac{HCI}.
Our research's main goal is to enhance human clinicians' decision-making by creating tailored explanations that align with \ac{HCI} principles.}

\textcolor{revised}{In the context of the \ac{HCI} community, our contribution involves designing a novel interactive approach for personalized and customized explanations of intelligent agents, underpinned by computational principles.
This approach combines \ac{ML} with image processing techniques to generate explanations tailored to the individual clinician's expertise.
To our knowledge, this is the first time that such an approach has been proposed and evaluated in the context of medical imaging.}

Concerning the broader implications of our work, we believe it has relevance for both decision-support research and \ac{AI} communication research.
Our approach to personalized and customized explanations has the potential to improve the accuracy and effectiveness of decision-making by humans in critical domains, which is an essential goal in decision-support research.
At the same time, our work contributes to the growing body of research on improving the communication between \ac{AI} systems and human users, a key concern in \ac{AI} communication research.
\textcolor{revised}{Next, we discuss the design implications, generalizability, limitations, and future work.}

\subsection{Design Considerations}
\label{sec:app005008001}

This section provides more detailed insights and recommendations based on the design implications summarized in Section~\ref{sec:chap006007001} of Chapter~\ref{chap:chap006}.
Our findings have different stages of design implications for the development of novel \ac{AI}-assisted systems in this clinical domain.
\textcolor{revised}{Presented findings range from combining different knowledge classifiers of the clinical arguments, training these models with enriched information, to designing user interfaces for embedded intelligent agents.
In addition, further research is essential to explore the potential benefits and limitations of different knowledge representation methods and evaluate the effectiveness of various design features in enhancing \ac{AI} systems' performance.}
Ultimately, our findings aim to inform the development of more human-centered medical \ac{AI} systems that effectively support clinical decision-making and enhance patient outcomes.
\textcolor{revised}{As follows, we will provide recommendations for future work on human-centered medical \ac{AI} systems.}

\subsubsection{Different Knowledge Combination}
\label{sec:app005008001001}

\textcolor{revised}{Expanding upon the design considerations discussed in Section~\ref{sec:chap006007001} of Chapter~\ref{chap:chap006}, this section explores the integration of detailed patient information obtained from \ac{DL} method classifiers.
In an actual clinical workflow, additional patient-specific data becomes crucial for accurate breast cancer diagnoses.
Providing comprehensive lesion information and emphasizing the significance of classification results are essential features that enhance decision-making.
Moreover, furnishing clinicians with granular details about identified lesions, such as size, location, and potential malignancy, facilitates their assessment and contributes to more informed decisions.
Incorporating these details effectively into the \ac{UI} of medical intelligent agents ensures that clinicians have access to comprehensive patient information, ultimately improving the diagnostic process.}

\textcolor{revised}{Collective intelligence in groups, irrespective of culture or context, can enhance integrated medical approaches worldwide~\cite{10.1093/jamia/ocab291, Sollini2020}.
Moreover, understanding risk and uncertainty in decision-making can refine intelligent agents, offering insights that align with clinicians' cognitive frameworks and cultural expectations.
This goes beyond presenting data, involving its interpretation that aligns with clinicians' intuitive grasp of risk and uncertainty in clinical diagnoses~\cite{10.1145/3544548.3581075, 10.1145/3313831.3376506}.
Embedding these principles into medical intelligent agents' design can create \acp{UI} that present data and offer interpretative layers, aiding clinicians in decisions informed by a blend of \acs{AI}-driven insights and human judgment.
This method acknowledges clinical decision-making's complexity and the intricate interplay between human and machine intelligence within the healthcare socio-cultural context.
Thus, integrating detailed patient information from \ac{DL} classifiers with collective intelligence and an understanding of human risk and uncertainty aspects can significantly improve clinical workflow decision-making.
This fosters a more informed, context-aware, and clinician-centric healthcare approach.}

\textcolor{revised}{Our interviews emphasize the importance of detailed information in improving both the speed and accuracy of diagnoses, aiding clinicians in accurately identifying and assessing lesions.
To ensure that the \ac{AI} aligns with clinicians' cognitive frameworks and provides intricate guidance and clarifications, it is essential to incorporate detailed patient data from \ac{DL} method classifiers~\cite{doi:10.1148/ryai.210299}.
For instance, the \ac{AI} system might utilize specialized classifiers to clarify the contours of lesions, while employing different classifiers focused on precisely defining the lesion margins.
This targeted approach ensures clinicians receive comprehensive and specific insights, enhancing their diagnostic capabilities.}

\vspace{2.50mm}

\noindent
\textcolor{revised}{This contemplation leads us to a pivotal inquiry:}

\vspace{1.00mm}

\noindent
{\it How should we train the \ac{DL} methods with such mixed information, for proper integration into clinical workflows?}

\vspace{2.50mm}

\textcolor{revised}{Drawing insights from the literature~\cite{10.1145/3313831.3376506}, the integration of such detailed information aligns with the broader understanding of risk and uncertainty in clinical decision-making.
Presenting data in a contextually relevant manner allows the \ac{AI} system to align with clinicians' intuitive grasp of risk, thereby assisting them in managing the inherent uncertainties associated with diagnosis.
This approach enhances the precision of diagnoses and enriches the clinicians' interpretative capabilities, fostering a more informed and confident decision-making process.
Moreover, this integration of granular data and \ac{AI} insights can be seen as a step towards cultivating collective intelligence within the clinical team.
The system fosters a collaborative atmosphere by merging the varied expertise of clinicians with the sophisticated capabilities of \ac{DL} classifiers, ensuring that knowledge and insights are shared and enhanced.
This collective intelligence, emerging from the interaction between human expertise and \acs{AI}-driven analytics, can lead to a more holistic and nuanced understanding of patient cases, ultimately enhancing the quality of care and patient outcomes.}

Insights and recommendations in this section guide the design and implementation of intelligent agents in medical imaging by incorporating granular patient information from classifiers.
This enhances clinicians' decision-making and emphasizes the need to align the \ac{AI} system with their mental model for personalized guidance.
Future research should explore training \ac{DL} methods with mixed information to integrate them effectively into clinical workflows.
These considerations foster human-centered and efficient medical \ac{AI} systems, improving clinical outcomes and patient care.

\subsubsection{Training Mixed Models}
\label{sec:app005008001002}

Expanding on the design implications presented in Section~\ref{sec:chap006007001} of Chapter~\ref{chap:chap006}, this section delves into the training of mixed \ac{DL} methods.
Our study suggests that clinical workflows and trust can be positively affected by endowing personalization of agent communication.
In fact, with the ability to, not only incorporate granular patient information from the mixed \ac{DL} method classifiers~\cite{doi:10.1148/radiol.2018181371}, but also adapt the tone depending on the medical experience of the clinician.
Implementing such intelligent agents would require that \ac{DL} methods are equipped with the additional prediction of mixed clinical arguments ({\it e.g.}, lesion contours, margin, or cancer type of the patient) beyond diagnosis alone.
This additional granular information about the patient could include its importance to the diagnostic, while also customizing the communication tone depending on the various demographic characteristics of clinicians.
Such an idea could be integrated either into one fused training, or by developing multi-separated \ac{DL} methods~\cite{RIASATIAN2021102032}, one for each clinical variable.

\textcolor{revised}{The integration of multiple \ac{CNN} classifiers~\cite{10230686}, customized for specific clinical variables, significantly enhances the precision and adaptability of medical diagnostics~\cite{doi:10.1148/radiol.2018181371}.
Renowned for their capacity to seamlessly amalgamate various architectural components and efficiently extract pertinent features, \ac{DL} methods offer a robust framework that consolidates a wide array of clinical data, providing detailed and contextually relevant insights.
Moreover, the adaptability of mixed \ac{DL} methods in processing spatial, temporal, and spatial-temporal data renders them exceptionally suitable for complex medical imaging tasks~\cite{9730804}.
Mastering these tasks requires a profound understanding of disease progression and precise localization of pathological changes.
This multifaceted strategy ensures clinicians possess the most accurate and actionable information, enhancing diagnosis and treatment.}

\textcolor{revised}{The significance of algorithm development and breast segmentation methods highlights the critical role of precision and adaptability within \ac{DL} methods.
Training these methods on datasets encompassing more granular information, such as various pathologies and imaging attributes, can bolster their capacity to generalize effectively and deliver accurate results across clinical situations.
Utilizing sophisticated architectures like  DensNet for classification~\cite{CALISTO2022102285}, and MobileNet for segmentation~\cite{10230448} demonstrates the promising capabilities of \ac{DL} techniques.
These architectures, tailored for 2D and 3D operations, showcase their potential to provide comprehensive insights into patients' health.}

Personalizing agent communication and incorporating granular patient information from mixed classifiers enhances intelligent agents' effectiveness in medical imaging.
To achieve this, \ac{DL} methods must predict mixed clinical arguments, such as lesion contours, margins, or cancer type, and adapt communication based on clinicians' experience and demographics.
Fused training or separate \ac{DL} methods for each variable may be necessary.
These recommendations advance context-aware medical \ac{AI} systems, improving decision-making and benefiting patient outcomes.

\subsubsection{Adapting Communication}
\label{sec:app005008001003}

This section examines personalized communication between agents and clinicians, expanding on the insights summarized in Section~\ref{sec:chap006007001} of Chapter~\ref{chap:chap006}.
In this work, we evaluate one specific way of personalizing and customizing the communication between agents and clinicians with different levels of medical experience.
We did that by exploring how to adapt the communication tone depending on if the agent was communicating with a novice or an expert clinician.
While our results suggest that this communication technique may be effective, we recommend that future work may explore different demographic characteristics of clinicians.
For example, from different medical institutions ({\it e.g.}, public hospitals, private clinics, cancer centers, etc), or different medical fields ({\it e.g.}, family physicians, breast surgeons, etc.), where some behavioral decision-making of clinicians should differ.
\textcolor{revised}{In doing so, we aim to provide a comprehensive understanding of how tailored communication can enhance the interaction between intelligent agents and clinicians.}

\textcolor{revised}{To unlock a more comprehensive understanding of the intricacies at play, future investigations should consider an array of factors, such as clinicians' diverse backgrounds and affiliations~\cite{LI2021106929}.
This could encompass variances stemming from different medical institutions, ranging from public hospitals to private clinics and specialized cancer centers.
We must also acknowledge the unique nuances present within various medical fields, encompassing diverse specialties such as family medicine and breast surgery.
We hold the firm belief that these distinctions are of paramount significance, as they have the potential to shed light on the intricate evolution of clinicians' behavioral decision-making processes.
This evolution, we posit, is in direct response to the multifaceted contextual parameters that inherently define and characterize their specific domains of practice.}

\textcolor{revised}{Our qualitative findings, as discussed in Section~\ref{sec:chap006006003} of Chapter~\ref{chap:chap006}, demonstrate that clinicians exhibit a willingness to adjust the communication tone of clinical arguments based on the level of confidence in the \ac{AI} system.
To illustrate, when the confidence exceeds 80\%, the system is advised to present an Assertive recommendation (as depicted in Figure~\ref{fig:fig098}, middle).
Conversely, if the confidence falls below this threshold, a non-assertive recommendation should be displayed (as shown in Figure~\ref{fig:fig098}, bottom).
As a research direction, it is worth considering how various performance actions by intelligent agents may influence the behavioral decision-making processes of clinicians.}

\textcolor{revised}{In conclusion, this section delves into the realm of personalized communication between agents and clinicians, building upon the insights introduced in Section~\ref{sec:chap006007001} of Chapter~\ref{chap:chap006}.
The adaptation of communication tones based on clinicians' experience presents a promising avenue.
Future research endeavors should delve into exploring various demographic characteristics to further enhance medical decision-making.
Our qualitative findings strongly indicate that clinicians are willing to adjust their communication tone based on the \ac{AI}'s confidence level.
This prompts a critical need for an investigation into how these adjustments may impact overall performance.
These research directions contribute significantly to the advancement of personalized and context-aware communication within the realm of medical \ac{AI}, ultimately leading to improved patient care outcomes.}

\subsubsection{Generalizability}
\label{sec:app005008001004}

\textcolor{revised}{Building upon insights from Section~\ref{sec:chap006007001} in Chapter~\ref{chap:chap006}, this section explores the generalizability of intelligent agents in breast cancer diagnosis through medical imaging, emphasizing assertiveness-based agents.
Future research should prioritize intelligent agents leveraging \ac{DL} methods while integrating diverse data types for clinical workflow enhancement~\cite{RASMY201811}.
These agents, especially those employing assertiveness-based communication, should adapt their tone to align with the confidence level of their explanations, accommodating variable data representations in medical imaging.}

\textcolor{revised}{In situations marked by data variability, the communication tone of these agents should align with the \ac{DL} method's generalizability.
The communication tone should be more suggestive in cases with limited data availability or variability.
Conversely, the communication tone can be more assertive in well-represented and robust data scenarios.
This adaptability enhances the agent's effectiveness in providing data-aligned recommendations, aiding clinicians in decision-making.}

\textcolor{revised}{Imbalanced datasets are crucial to address as they can hinder the generalizability of the \ac{DL} method, especially when dealing with less-represented cases.
For example, our dataset might exhibit an imbalance, with most cases having lesions characterized by circumscribed margins, which are typically less severe and benign, and fewer cases with spiculated margins, which are generally more severe and malignant.
This imbalance can affect the generalizability of the \ac{DL} method, making training more challenging and increasing the risk of critical errors, notably higher \ac{FN} rates, a significant concern.}

\textcolor{revised}{Despite the \ac{DL} method's high confidence levels in specific classifications, underperformance may occur due to limited data availability for certain patient cases.
In such cases, the \ac{AI} agent's communication tone should be more suggestive, considering the \ac{DL} method's generalizability limitations.
This nuanced communication approach ensures the \ac{AI} system remains dependable and supportive for clinicians, particularly when data constraints might impact the \ac{DL} method's performance, thereby advancing medical \ac{AI} systems and promoting human-centered design.
It underscores the importance of creating adaptable \ac{AI} systems that can assist healthcare professionals effectively in various clinical scenarios.}

\textcolor{revised}{While it's important to exercise caution when applying these findings to other medical domains, personalized and customized communication principles hold promise across various medical specialties.
These principles effectively address common challenges in clinical data integration and decision-making processes, ensuring that \ac{AI} systems remain relevant and practical for clinicians with diverse demographic characteristics.
Ultimately, this approach can enhance decision-making and improve patient outcomes in breast cancer diagnosis and various medical fields.}

\textcolor{revised}{Considerations related to demographic characteristics in the context of medical diagnosis extend well beyond breast cancer~\cite{STAHNKE2021103243, LANDRO2020102897, doi:10.1080/21642850.2020.1741372}.
Research in various domains supports the idea that tailoring communication and decision-support systems to individual healthcare professionals can enhance diagnostic accuracy and ultimately benefit patient outcomes.
For example, the principles explored in our study can be applied to lung cancer diagnosis, where specialized radiologists visually analyze chest imaging data~\cite{10.1145/3313831.3376807}.
Personalizing agent communication based on clinicians' backgrounds and expertise can improve diagnostic precision and patient care.
This approach emphasizes considering clinician-centric design principles across medical domains to optimize diagnostic processes and healthcare delivery.}

\textcolor{revised}{Personalized communication extends to various clinical domains.
In skin cancer diagnosis, for instance, clinicians often follow established medical procedures and draw upon their experiences with similar cases to arrive at a final diagnosis~\cite{10.1007/978-3-030-87199-4_52, Tschandl2020, Esteva2017}.
In such scenarios, the effectiveness of the communication and decision-support provided by an \ac{AI} agent should adapt to the clinician's experience level, incorporating customizable techniques.
These insights underline the broader applicability of our research beyond assertiveness-based agents.
They suggest that personalized approaches can be beneficial in diverse areas of medical imaging diagnosis.
This emphasizes the potential for enhancing diagnostic processes across the medical field through tailored communication strategies.}

\textcolor{revised}{The notion of \acs{AI}-based systems supporting personalized medicine is gaining traction in healthcare.
Studies advocate for using \ac{AI} to aid diagnosis and treatment guidance~\cite{Sollini2020, Aerts2016}, emphasizing the potential for tailored approaches to improve patient care.
Our findings highlight the advantages of personalizing agent communication in medical imaging diagnosis, aligning with the broader trend of leveraging \ac{AI} for personalized medicine and underscoring our research's relevance and potential impact on healthcare.}

\subsection{Study Constraints}
\label{sec:app005008002}

This section provides a more detailed analysis of the study constraints summarized in Section~\ref{sec:chap006007002} of Chapter~\ref{chap:chap006}.
In this work, we conducted a within-subject experiment to investigate the use of assertiveness-based agents by clinicians in the particular medical domain of breast cancer diagnosis.
We investigate this question through the design and study of Assertiveness-based BreastScreening-AI~\cite{10.1145/3544548.3580682}.
More specifically, this tool was used to explore how an intelligent agent should adapt its communication tone depending on the professional experience ({\it i.e.}, novice vs expert) of the clinician.

Due to the short availability of clinicians and the remote nature of our study, it was challenging to control the tasks of each step in the experiment precisely.
For example, participants varied how long they completed the task for the first patient, in comparison to the second and third patients.
This lack of experimental control may have impacted the degree to which exposure to the first patient, while interacting for the first time with the assertiveness-based agent, affected how clinicians interacted with the latter.
These challenges highlight the importance of future studies with more controlled experimental conditions to validate further and generalize the findings.

Another limitation is related to the implications of liability when using \ac{AI} in medical settings~\cite{10.1145/3555157}, where the legal framework for addressing these issues is still evolving.
The use of \ac{AI} in medical settings raises complex questions that are not yet fully understood or addressed by existing laws and regulations~\cite{10.1145/3411764.3445432}.
This can make it difficult to determine who might be liable in the event of an error or harm caused by an \ac{AI} system.
\ac{AI} systems often operate in complex and dynamic environments, making it challenging to identify the specific factors that led to a particular outcome.

Overall, the limitations concerning the implications of liability when using \ac{AI} in medical settings highlight the need for further research and legal developments in this area.
Policymakers and other stakeholders need to continue to explore these issues and work to address them in a way that ensures the safe and effective use of \ac{AI} in medical settings~\cite{10.1145/3544549.3573827}.
Future efforts should focus on developing robust frameworks and guidelines to mitigate potential risks and establish accountability in deploying \ac{AI} systems in healthcare~\cite{10.1145/3544548.3581393}.

\textcolor{revised}{In our study, the assertiveness-based agent made use of specific \ac{AI} outputs meticulously curated and selected by us, mirroring typical clinical scenarios encountered in real-world practice.
While prior research has demonstrated the potential of predicting clinicians' trust in \ac{AI} recommendations using raw medical data~\cite{pmlr-v97-raghu19a}, the next step should prioritize the training of \ac{DL} models to generate personalized and customized explanations.
These explanations would serve as human-interpretable arguments, enhancing transparency and aiding clinicians in understanding and accepting the \ac{AI}'s recommendations.}

\textcolor{revised}{Another promising avenue for future research involves dissecting the effects of the two primary features of the assertiveness-based agent, namely explanations and tone, in distinct conditions (Section~\ref{sec:app001007}).
However, extracting valuable insights to adapt \ac{DL} methods presents new technical challenges for the \ac{AI} community.
For the \ac{HCI} community, the challenge lies in ensuring these inferences are transparent, accounting for various behavioral characteristics exhibited by clinicians.
This multidisciplinary effort holds the potential to further improve personalized communication between agents and clinicians in medical contexts.}

\section{Severity Classification}
\label{sec:app005009}

The \ac{BI-RADS} provides a standardized method for reporting the results of breast imaging exams, which can help to ensure that the information is accurate and consistent.
As a quantitative approach, it serves for representing the severity assessment of patients with breast imaging exams.
This information is helpful as an input for \ac{AI} models that are designed to assist with diagnosing breast cancer, as it provides a standardized way of representing the findings of imaging exams~\cite{MAICAS2019101562}.

\textcolor{revised}{Utilizing the \ac{BI-RADS} system as an input for \ac{AI} models may potentially enhance the accuracy and reliability of the model's predictions while aiding in the prevention of bias in the results.}
Additionally, it enables a seamless communication and understanding between the \ac{AI} system and healthcare professionals, fostering trust and facilitating collaboration in the diagnostic process.
The \ac{BI-RADS} system uses a scale from {\bf 0} to {\bf 6} for categorizing the findings of breast imaging exams.
However, in our study we just considered the scale from {\bf 1} to {\bf 5}, as the {\bf 0} means that the case is inconclusive, where we need to acquire more images, and {\bf 6} means we already have biopsy confirmation by previously known lesion.

\vspace{2.50mm}

\noindent
Here is a brief overview of each category on the \ac{BI-RADS} scale:

\vspace{1.50mm}

\begin{enumerate}
\item {\bf Negative:} The exam did not show any abnormalities and the patient's breast tissue appears normal.
\item {\bf Benign Finding:} The exam showed a benign (non-cancerous) abnormality in the breast tissue.
\item {\bf Probably Benign:} The exam showed an abnormality that is likely to be benign, but further testing may be needed to confirm this.
\item {\bf Suspicious Abnormality:} The exam showed an abnormality that is suspicious for cancer and further testing, such as a biopsy, is needed to determine if it is cancerous.
\item {\bf Highly Suggestive of Cancer:} The exam showed an abnormality that is highly suggestive of cancer, and a biopsy is recommended to confirm the diagnosis.
\end{enumerate}

\vspace{2.5mm}

\textcolor{revised}{One key advantage of incorporating the \ac{BI-RADS} system as input for \ac{AI} models like \acp{CNN}, such as DenseNet for 2D~\cite{CALISTO2022102285}, and MobileNet for 3D imaging~\cite{10230448}, is the potential enhancement of prediction accuracy and reliability.
This improvement is achieved by leveraging the well-defined categorization provided by \ac{BI-RADS}, standardizing findings' representation in breast imaging exams, and mitigating potential bias in results.
Moreover, this integration promotes seamless communication and understanding between the \ac{AI} system and healthcare professionals, particularly radiologists.
Aligning with the \ac{BI-RADS} system allows the \ac{AI} model to use familiar terminology and categorization, fostering trust and facilitating collaboration in the diagnostic process.}

It is important to note that the \ac{BI-RADS} score is only a tool for reporting the results of breast imaging exams and does not provide a definitive diagnosis of cancer.
A biopsy is usually needed to confirm a cancer diagnosis.
For more details, follow the \href{https://radiopaedia.org/articles/breast-imaging-reporting-and-data-system-bi-rads}{link} (\href{https://radiopaedia.org/articles/breast-imaging-reporting-and-data-system-bi-rads}{radiopaedia.org/articles/breast-imaging-reporting-and-data-system-bi-rads}).
It was accessed on the 11th of January 2023.

\section{Patient Selection}
\label{sec:app005010}

In Chapter~\ref{chap:chap006}, we used a total of 338 cases and acquired in the \ac{HFF} clinical institution.
From this set of 338 cases, 289 were classified by the head of radiology.
Each patient has several images concerning four X-ray \ac{MG} modalities (two in \ac{CC} and two \ac{MLO} views), one or two US images, and roughly 5 volumes in \ac{MRI}.
In the \ac{MRI} volumes, we take numerous image slices per patient, where the lesion is present.

From the 289 classified cases, we selected a total of 35 patients to be classified by our \ac{AI} models.
Because we aim to test the three trials ({\it i.e.}, conventional {\it vs.} non-assertive {\it vs.} assertive), plus the two groups of medical professional experience ({\it i.e.}, novice {\it vs.} expert) we computed at least $2^5=32$ the number of patients.
Hence, the 35 patients were selected to cover that magnitude of patients.
This classification corresponds to assigning a \ac{BI-RADS} value for each modality image of the exam.

\section{Participants Information}
\label{sec:app005011}

\textcolor{revised}{In this study, we meticulously gathered comprehensive information about the participants during this study by conducting an initial survey.
This survey served as a crucial data collection tool, encompassing a wide range of participant demographics, as summarized in Table~\ref{tab:tab015}.
It aimed to paint a detailed picture of our participant pool during the work developed under this dissertation, encompassing gender, age, geographic location, and professional experience.}

\textcolor{revised}{Our examination delved deeper into the participants' professional backgrounds, particularly in their ability to interpret and analyze medical imaging data.}
We also ask participants about their professional background in reading medical imaging data.
Regarding the professional background, 11.54\% of participants are doing their medical internships, 3.85\% were breast medical surgeons, but with knowledge of reading medical images, and 84.61\% were medical radiologists, reading and diagnosing patients every day.
\textcolor{revised}{This rich tapestry of participant backgrounds and experiences forms a foundational element of our study, contributing to the depth and diversity of insights gained during the research process.
It allows us to draw upon a spectrum of perspectives within the medical community, enhancing the robustness and applicability of our findings.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{tables/tab015}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Existing System}
\label{sec:app005012}

Our new approach allows for a more flexible and dynamic system.
Furthermore, the new system addresses some limitations of the traditional system~\cite{CALISTO2022102285}, providing a more robust and scalable solution.
Ultimately, offering a new and innovative approach for solving the diagnostic task.

The \ac{AI} models in this study are not fusing the predictions from different imaging modalities ({\it e.g.}, \ac{MG}, \ac{US}, or \ac{MRI}).
Instead, each modality had its own \ac{GT} score, which refers to the correct or known diagnosis for a given patient.
This is because the different modalities may provide different information about a patient's breast tissue, and may, therefore; result in different diagnoses and \ac{BI-RADS} scores for a given patient.
Hence, the \ac{AI} models generated individual final predictions for each modality.

Specifically, the DenseNet model~\cite{8721151} was used to estimate the lesion score for 2D imaging data, such as \ac{MG} and \ac{US} images.
The 3D ResNet model~\cite{Aldoj2020} was used to estimate the lesion score for 3D data, such as \ac{MRI} volumes.
Lesion score refers to the likelihood that a specific area of the breast tissue is cancerous, and is typically used as part of the \ac{BI-RADS} score for reporting the results of exams.

\section{Evaluating Performance Recognition}
\label{sec:app005013}

We have used the false-positive and false-negative metrics for evaluating the performance of recognition of clinicians, since these metrics are straightforwardly obtained from a classification process.
We chose to use these metrics because they are widely recognized as important indicators of performance in medical imaging classification tasks.
Particularly, in the context of breast cancer diagnosis, where false-positives and false-negatives can have significant consequences for patient care.
Furthermore, we believe that these metrics provide a more balanced and comprehensive evaluation of performance than classification accuracy, which can be misleading in imbalanced datasets.
For instance, if a clinician provides a \ac{BI-RADS} of 3 but the real \ac{BI-RADS} is a 5, we consider it as a false-negative result.
On the other hand, if the real \ac{BI-RADS} is a 2, but the clinician provides a \ac{BI-RADS} of 4, we consider it as a false-positive.
Where the ``real'' score is the \ac{GT} provided by the expert from \ac{HFF}.

Overall, our goal was to evaluate the performance of our system in terms of its ability to reduce false-positives and false-negatives.
We found that our classifiers achieved an average decrease of about 26\% for the false-positive rate and about 2\% for the false-negative rate, outperforming previous approaches that have been proposed for this task~\cite{CALISTO2022102285}.
Moreover, we believe that the false-positive and false-negative metrics we used are appropriate for this purpose.
By using these metrics, we were able to demonstrate the potential of our \ac{AI}-assisted approach for reducing false-positives and false-negatives, and we believe that our findings could help to inspire future research.

\section{Thresholds \& Strategies for Curating Patients}
\label{sec:app005014}

Similar to what was already described (Section~\ref{sec:chap002003} of Chapter~\ref{chap:chap002}), the rationale is the following.
The \ac{BI-RADS} score ranges from 0-to-6 scale, with the following meaning:
0 -- inconclusive,
1 -- no findings,
2 -- benign findings,
3 -- probably benign,
4 -- suspicious findings,
5 -- high suspicious malignancy,
6 -- previously known lesion.
\ac{BI-RADS} of 0 and 6 are ignored in our study because they are meaningless for prediction purposes.

\vspace{1.00mm}

\noindent
We have clustered the values above into three classes as follows:

\vspace{0.05mm}

\begin{itemize}
\item ``No Findings'' with \ac{BI-RADS} = 1
\item ``Benign, probably benign findings'' with \ac{BI-RADS} = \{2, 3\}
\item ``Probably, highly suspicious malignancy findings'' with \ac{BI-RADS} = \{4, 5\}
\end{itemize}

Thus, the  DenseNet (for 2D \ac{MG} and \ac{US}) and the ResNet (for 3D \ac{MRI}), three classes for the classification.
We take the values from 1-to-5, since the other two values do not count for the diagnosis.
Notice that both networks are trained with the \ac{GT} of the \ac{BI-RADS} provided by a radiologist from \ac{HFF}.

\section{Next Steps for Explanations and Tone}
\label{sec:app005015}

In Chapter~\ref{chap:chap006}, we resort to two main classes of tones:
(1) assertive, by having a more authoritative tone, while imposing the \ac{AI} recommendations; and
(2) non-assertive, while being a more suggestive agent.
However, considering the clinical context, this should be expanded not only to test more trials in the near future, but also to a larger extent of the communication tones.
Concretely, the explanations should be attached to the concept of the lexicon for each breast modalities~\cite{SPAK2017179}.
For instance, having the explanation: ``scattered areas'' (\texttt{lex\_1}), ``fibrogandular density'' (\texttt{lex\_2})  or ``scattered fibroglandular tissue'' (\texttt{lex\_3}), and ``ring enhancement mass'' (\texttt{lex\_4}).
Recognizing the potential usefulness of additional communication tones in the clinical context, we have plans to explore them in our future research.
This exploration will provide us with a deeper understanding of how these communication tones can be practically applied and valued in the clinical domain.

\vspace{2.00mm}

\noindent
To study the full effects of the style of tone, we will need the following trials:

\vspace{0.05mm}

\begin{enumerate}
\item Conventional Agent;
\item Agent with Explanations in Neutral Tone;
\item Agent with Explanations in Non-Assertive Tone; and
\item Agent with Explanations in Assertive Tone.
\end{enumerate}

% \vspace{0.50mm}

This is an intriguing area of investigation that currently drives our research in this direction.
We are actively pursuing this line of inquiry to explore the potential for more detailed and accurate explanations.
Our ultimate goal is to enhance the diagnostic performance of medical imaging classification in the clinical domain of breast cancer through the implementation of our \ac{AI}-assisted system.

\section{Repositories}
\label{sec:app005016}

Our repositories, which are publicly accessible online, provide a wealth of information and resources related to our research.
Kindly navigate to the designated \texttt{\href{https://github.com/MIMBCD-UI/prototype-assertive-reactive}{prototype-assertive-reactive}} repository (\href{https://github.com/MIMBCD-UI/prototype-assertive-reactive}{github.com/MIMBCD-UI/prototype-assertive-reactive}) for more details about the source code of the prototypes.
In terms of results and statistical analysis, all information is available in the \texttt{\href{https://github.com/MIMBCD-UI/sa-uta11-results}{sa-uta11-results}} repository (\href{https://github.com/MIMBCD-UI/sa-uta11-results}{github.com/MIMBCD-UI/sa-uta11-results}).
The repository has the linking pointers for the other related repositories, such as the datasets, source code of the \ac{AI} models, prototypes, and documentation, among others.
Please note that these repositories are periodically updated to ensure the availability of the most current information.
For instance, the updates can include more updated inferences and statistics on our results, providing deeper insights into our research findings.
Access to the repositories was last verified on the 3rd of July 2023.

\section{Intellectual Property}
\label{sec:app005017}

The work described in this paper is covered by pending patent applications, filed by \href{https://tecnico.ulisboa.pt}{\acl{IST}}.
The contents of this paper are intended to be informative to the scientific and technical community.
They are not intended to be used to limit the scope of the pending patent application.
The patent rights will be enforced to the extent necessary to protect the proprietary interests of the patent holders.
For more information, further details are available in the \texttt{\href{https://github.com/MIMBCD-UI/sa-uta11-results/blob/main/LICENSE.md}{LICENSE.md}} file of the \texttt{\href{https://github.com/MIMBCD-UI/sa-uta11-results}{sa-uta11-results}} repository (\href{https://github.com/MIMBCD-UI/sa-uta11-results}{github.com/MIMBCD-UI/sa-uta11-results}).
Accessed on the 11th of January 2023.

\section{Potential Clinical Impact}
\label{sec:app005018}

\textcolor{revised}{Integrating our intelligent agents into radiological diagnostics has shown significant potential to transform clinical practices, patient outcomes, and radiologist work environments.
This section elucidates the multifaceted clinical impact of our \ac{AI}-assisted approach.
It is characterized by a substantial reduction in medical errors (Section~\ref{sec:app005018001}), an enhancement in diagnostic speed (Section~\ref{sec:app005018002}), and a notable decrease in radiologist workload (Section~\ref{sec:app005018003}), as well the overall financial impact (Section~\ref{sec:app005018004}).
These factors contribute to the profound changes we are witnessing in healthcare.}

\subsection{Medical Error Impact}
\label{sec:app005018001}

\textcolor{revised}{Our intelligent agents' proficiency in reducing medical errors by 26\% significantly enhances patient care.
A notable aspect of this reduction is the 22\% decrease in \acp{FP}, which alleviates patient anxiety and curtails unnecessary medical interventions.
This reduction in \acp{FP} is particularly significant as it contributes to a potential saving of up to 15\% in diagnostic-related costs~\cite{10.1001/jamainternmed.2015.5231}.
Moreover, these savings extend beyond mere financial aspects (Section~\ref{sec:app005018004}), translating into optimized resource allocation and reduced patient burden within healthcare facilities.}

\textcolor{revised}{In addition to reducing \acp{FP}, there has been a 4\% decrease in \acp{FN}, ensuring the timely identification of critical conditions~\cite{doi:10.3322/caac.21492}.
This reduction in \acp{FN} is particularly crucial as it directly correlates with an increase in the chances of successful treatment by up to 20\% for time-sensitive conditions, emphasizing the importance of accurate and prompt diagnosis (Section~\ref{sec:app005018002}).
Furthermore, this improvement in diagnostic precision mitigates the risk of delayed or missed treatments, enhancing patient outcomes and easing the long-term burden on healthcare systems.
It also reinforces the role of intelligent agents in the continuum of care, bridging the gap between early detection and timely treatment.}

\subsection{Diagnostic Time Impact}
\label{sec:app005018002}

\textcolor{revised}{The proficiency of intelligent agents is further exemplified by their ability to quadruple the speed of diagnostics, translating to an average saving of about 2.25 weeks per patient~\cite{WAYMEL2019327}.
This acceleration in the diagnostic process is a paradigm shift from the traditional settings, where the typical wait time for a diagnosis could extend up to 6 weeks~\cite{https://doi.org/10.1002/cncr.32910}.
Such an enhancement in diagnostic speed is not just a metric of efficiency, but a critical factor in treatment outcomes, especially for conditions where early intervention is paramount.
The significance of prompt and accurate diagnosis is particularly evident in breast cancer, where early detection is closely linked with survival rates.
In such scenarios, intelligent agents and advanced diagnostic tools become indispensable, potentially raising the 5-year survival rate to 99\%~\cite{DIN2022106073}.
However, it's essential to approach the integration of such technologies with a critical understanding of their impact and cost-effectiveness, as highlighted by the studies mentioned above.}

\textcolor{revised}{According to recent studies, such an enhancement in diagnostic processing speed can lead to a 35\% increase in patient throughput, significantly reducing the time patients spend waiting for critical diagnostic results~\cite{doi:10.1148/radiol.212631}.
This marks a substantial breakthrough in sectors where the typical diagnosis wait time can extend beyond 6 weeks~\cite{https://doi.org/10.1002/cncr.32910}.
Drawing from pilot sessions conducted as part of our participatory design approach, we have observed that integrating our intelligent agents holds promise.
It has shown the potential to significantly reduce this duration by up to 75\%.
This transformation takes the concept of timely diagnosis, once considered a mere aspiration, and turns it into a tangible reality.}

\subsection{Burnout Impact}
\label{sec:app005018003}

\textcolor{revised}{Intelligent agents are reshaping radiological practices, driving improved workflow efficiency and resource management (Section~\ref{sec:app005018001}).
Deployment of these agents has led to a fourfold increase in diagnostic efficiency (Section~\ref{sec:app005018002}), particularly beneficial in high-demand healthcare settings.
This enhancement seamlessly addresses the urgent need for efficiency with precision.
Integrating intelligent agents tackles the industry's challenges~\cite{doi:10.1148/radiol.210948}, balancing the relentless growth in radiologists' workload with the need for accurate interpretation.
Without clear workload and speed limit guidelines~\cite{KOHLI2018535}, intelligent agents play a crucial role in maintaining accuracy and adapting to growing demands in radiology.}

\textcolor{revised}{Addressing the well-being of radiologists, our intelligent agents play a vital role in fostering a healthier work environment by reducing the workload by approximately 48\% (Section~\ref{sec:chap005006004}), as quantified by the \ac{NASA-TLX} scale.
Given that burnout among physicians, including radiologists, has a prevalence rate exceeding 40\%~\cite{doi:10.1148/radiol.212631}, this substantial workload reduction has the potential to bring burnout rates down to approximately 20\%, thereby significantly enhancing radiologists' overall mental well-being and job satisfaction.
Our results underscore the tangible impact intelligent agents can have on the quality of life and professional fulfillment of radiologists, benefiting both healthcare providers and patients.}

\subsection{Financial Impact}
\label{sec:app005018004}

\textcolor{revised}{Our intelligent agents make a profound impact on enhancing diagnostic precision, which, in turn, leads to substantial cost savings.
This is achieved through a notable reduction in both \acp{FP} by 22\% and \acp{FN} by 4\%.
This substantial improvement in diagnostic accuracy translates into significant financial benefits.
Consider a medical facility serving approximately 1,000 patients monthly to put this into perspective.
By harnessing our intelligent agents to reduce the occurrence of \acp{FP}, which often triggers unnecessary follow-up procedures, this facility could potentially save around \$11,000 per month~\cite{10.1001/jamainternmed.2015.5231}.
The real-world impact of these agents serves as a compelling testament to their tangible value.
It extends beyond clinical aid and enhances financial efficiency within the healthcare ecosystem.}

\textcolor{revised}{Intelligent agents demonstrate their crucial role in healthcare cost reduction by effectively reducing the incidence of \acp{FN}.
Effectively reducing the incidence of \acp{FN} through intelligent agents is vital in avoiding the substantial expenses of treating medical conditions at more advanced and severe stages~\cite{DIN2022106073}.
The potential for substantial cost reductions, possibly up to \$100,000 per patient~\cite{McKinney2020}, reflects direct cost savings.
In light of these advantages, developing \acs{AI}-assisted solutions that integrate intelligent agents and meet user needs is essential.
This development should be grounded in \ac{HCI} principles~\cite{PELAU2021106855, 10.1145/3290605.3300233}, utilizing \ac{UCD} methodologies and a participatory design approach to ensure effective solutions.
Advancing precision medicine and bringing financial benefits to healthcare, intelligent agents enable accurate early diagnoses, improving clinical outcomes while reducing costs.}

\textcolor{revised}{Lastly, intelligent agents can quadruple diagnostic speed, resulting in higher patient throughput and lower operational costs.
To illustrate, imagine a facility serving 1,000 patients each month, which could potentially save \$150,000 monthly thanks to enhanced efficiency and reduced time per diagnosis~\cite{doi:10.1148/radiol.212631}.
This increased efficiency, coupled with a $\sim$48\% reduction in radiologist workload, mitigates burnout and translates into significant cost savings.
This consideration is crucial when factoring in the substantial costs of staff turnover.
In our study, these savings emphasize the vital role of intelligent agents in optimizing healthcare through diagnostic accuracy and financial efficiency.}

\section{Future Directions}
\label{sec:app005019}

\textcolor{revised}{Our research paves the way for many fascinating future investigations.
The promising nature of our current findings underscores the necessity for ongoing refinement and adaptation.
Future endeavors will concentrate on honing the \ac{DL} algorithms, broadening the scope of the system to encompass additional medical imaging modalities, and incorporating patient feedback to tailor and elevate the diagnostic experience further.
The quest to unlock the full potential of \ac{AI} in healthcare is a continuous journey, and our dedication to innovation and excellence is unwavering.}

\textcolor{revised}{A particularly intriguing direction for subsequent research involves leveraging the insights gained from the assertiveness-based agent in other critical sectors where decisions significantly affect individuals' lives, such as airport security or supermarket surveillance.
Moreover, these agents hold promise in professions with a wide range of expertise.
For instance, an assertiveness-based agent could offer \acs{AI}-driven guidance to research scientists on selecting the most suitable publication venues, thereby enhancing the dissemination of their work.
Such explorations would determine the relevance of our findings to the medical field and their broader applicability across diverse professional landscapes.}

\textcolor{revised}{We propose exploring diverse communication tones and enhancing explanation relevance by incorporating a lexicon specific to breast modalities.
Unraveling the distinct characteristics of assertive and non-assertive tones, and integrating explanations with precise medical terminology, aims to cultivate a stronger rapport between humans and \ac{AI} systems.
Future work should focus on developing \ac{AI} tools that provide detailed, accurate, and tonally appropriate explanations.
We believe such improvements can enhance breast cancer diagnostic accuracy, leading to more confident and informed clinical decisions.}

\textcolor{revised}{There is another significant potential for training \ac{DL} models to offer personalized, interpretable arguments, which could strengthen clinicians' trust in \ac{AI} recommendations.
Moreover, studying the impacts of essential functionalities, namely, explanations and tone, under a wider array of conditions is critical (Section~\ref{sec:app005015} of Appendix~\ref{chap:app005}).
For the \ac{AI} community, this means technical adaptations to the \ac{DL} model, while for the \ac{HCI} community, the challenge lies in ensuring transparency and accommodating the behavioral characteristics of the clinicians.}

\textcolor{revised}{Potential future research directions include investigating clinicians' acceptance of \ac{AI}-based follow-up suggestions and assessing the influence of explanations within \acp{CDSSe}.
Furthermore, executing exploratory thematic analyses of intelligent agents and designing ambiguity-aware \ac{AI} assistants offers exciting research trajectories.
Advancements in these domains will augment our comprehension of the intersection between \ac{HCI} and \ac{AI} in healthcare, thereby facilitating the creation of enhanced, user-friendly tools for healthcare professionals and promoting improved patient outcomes.}

\section{Epilogue}
\label{sec:app005020}

In conclusion, this appendix is a comprehensive resource, providing additional details related to Chapter~\ref{chap:chap006} and key aspects of our work.
We explore \ac{AI} model used in our \ac{UI} design, patient selection approach, diagnosis classification, and crucial participant information.
Furthermore, we examine performance recognition, thresholds, and patient curation strategies in the current system, highlighting methods for robustness and accuracy.
Using \ac{HCI} principles, this research advances intelligent agent design, emphasizing usability, user satisfaction, and comprehensive evaluation.
Consequently, this improved effectiveness of the systems boosts user acceptance and adoption in clinical settings.

In subsequent \ac{HCI} research, guided by Prof. \href{https://www.hcii.cmu.edu/people/john-zimmerman}{John Zimmerman} of the \ac{HCII} at \ac{CMU}, we aim to investigate communication and explanation nuances in other high-stakes domains like airport security or supermarket surveillance.
We strive for a human-centric approach to iterative designs that integrate into critical workflows, enhancing users' understanding and trust in \ac{AI} systems.

The \ac{HCII} at \ac{CMU} significantly shaped our future academic directions.
Yet, clinical institution partnerships are essential for progress.
We plan to extend partnerships with \ac{CHBM}, \ac{CHULN}, \ac{CHUSA}, \ac{HVFX}, national \acp{IPO} centers, and start a collaboration with Portuguese Cancer League, thanks to Dr. João Maria Abrantes of \ac{JCCC} and \ac{CHTMAD}.
Not only are we extending collaboration through \ac{CHBM}, \ac{CHULN}, \ac{CHUSA}, \ac{HVFX}, \ac{JCCC}, and the \acp{IPO} centers, but also to all involved clinical institutions earlier to the work developed under this dissertation thesis.

Our publicly accessible source code and statistical analysis repositories enhance transparency and promote research collaboration (\href{https://github.com/MIMBCD-UI}{github.com/MIMBCD-UI}).
Remember, our work, protected by pending patents, contributes to \ac{AI}-assisted medical imaging diagnosis advancements.
This appendix serves as a valuable resource for researchers and practitioners, driving advancements in diagnosing and treating diverse medical conditions.
We look forward to expanding clinical \ac{AI} assistant boundaries, contributing to the field's evolution.