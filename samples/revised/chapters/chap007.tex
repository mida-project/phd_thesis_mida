% #############################################################################
% This is Chapter 7
% !TEX root = main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Discussion}
\clearpage
% The following line allows to ref this chapter
\label{chap:chap007}

In this dissertation, we carry out a thorough investigation of the role and design of intelligent agents in high-stakes domains, specifically for critical healthcare environments.
Our thesis spans three primary investigations.
Chapter~\ref{chap:chap004} examines the receptiveness of clinicians to intelligent agents, employing the \ac{UTAUT} model as a lens to scrutinize the various factors influencing technology adoption within the medical imaging field.
Through a human-centered approach, Chapter~\ref{chap:chap005} deepens this exploration by addressing clinicians' experiences and perceptions when using \ac{AI} assistance in radiology, shedding light on potential design interventions for more effective integration of \ac{AI} tools into their workflows.
Finally, in Chapter~\ref{chap:chap006}, we provide a novel perspective on personalizing and customizing the communication of intelligent agents adapted to the characteristics of human clinicians, illustrating its importance in facilitating decision-making processes.
Through these investigations, we bridge the gap between \ac{HCI} and \ac{AI} in healthcare, while making significant strides towards understanding, as well as enhancing the adoption and utility of \ac{AI} technologies in clinical settings.

This chapter presents a compendium of contributions (Section~\ref{sec:chap007001}) toward the overarching thesis statement (Section~\ref{sec:chap007002}) and provides pertinent design recommendations (Section~\ref{sec:chap007003}) to integrate intelligent agents into medical imaging workflows.
Our findings underscore the necessity of compliant agents providing tailored explanations, informing future enhancements in the field (Section~\ref{sec:chap007004}).
The insights derived from this dissertation significantly contribute to \ac{HCI}, decision support systems, and \ac{AI} communication research for healthcare, providing a robust foundation for subsequent investigations and developments in these areas.

\section{Contributions and Impact}
\label{sec:chap007001}

This dissertation serves as a substantial contribution to the interwoven realms of \ac{HCI} and \ac{AI}.
Specifically, within the context of decision-making in high-stakes domains such as healthcare.
It provides meaningful exploration of the intricate relationship between these fields, offering invaluable insights for researchers and practitioners navigating the dynamic landscape of healthcare technology.
The cornerstone of this thesis rests in the comprehensive exploration of integrating intelligent agents within healthcare settings, delving into the intricate dynamics affecting clinicians' adoption and usage of such advanced technologies.
It elucidates many factors that influence the acceptance of these systems, providing an in-depth understanding that bridges \ac{HCI} and \ac{AI} in the context of medical decision-making.
By harnessing the power of \ac{AI} and grounding it in the principles of \ac{HCI}, we present potential pathways for enhancing decision-making processes where decisions are critical.
This cross-disciplinary exploration not only enhances the theoretical underpinnings of the field, but also opens new avenues for practical applications in the design and development of user-centric \ac{AI} technologies for critical environments.
The investigation spans three distinct contexts, detailed next.

Our first contribution centers on elucidating the processes through which intelligent agents can be seamlessly integrated into medical imaging workflows.
Relying on the \ac{UTAUT} model as a guiding framework (Chapter~\ref{chap:chap004}), we unravel the roles played by critical determinants and various moderator variables in accepting \ac{AI} recommendations.
This rigorous exploration unveils nuanced insights into how these factors influence clinicians' readiness to incorporate \ac{AI} systems into their routine clinical workflow.
Our findings not only enrich the theoretical underpinnings regarding the incorporation of \ac{AI} systems in healthcare, but they also provide pragmatic recommendations for designing and implementing these technologies effectively.
A critical facet of our research underscores trust's role in clinicians' interaction with \ac{AI} systems, considering potential behavioral variations among clinicians of diverse demographics.
Consequently, our research asserts that fostering trust by considering these varied factors and characteristics is a crucial component in the successful design and deployment of \ac{AI} systems within healthcare settings.

The second significant contribution of this dissertation is the employment of a human-centered design approach that seamlessly weaves \ac{AI} systems into the intricate domain of medical imaging diagnosis (Chapter~\ref{chap:chap005}).
Our approach forms design interventions for a robust medical assistant tool, capturing user needs for control and comprehension of \ac{AI} methods, thereby enhancing clinicians' decision-making.
The research provides an in-depth analysis of these interventions, emphasizing the criticality of transparency, explainability, and usability in building trust.
From this exploration, we distill vital design recommendations endorsing task-specific evaluations, concrete evidence delivery, and precision and recall metrics calibration.
These findings underscore \ac{HCI} principles' pivotal role in developing efficient, user-centric \ac{AI} systems for healthcare, thus augmenting the synergy between clinicians and \ac{DL} predictions.

Our third essential contribution focuses on personalized and customized explanations from intelligent agents, enabling improved communication with clinicians in the complex realm of medical imaging diagnosis (Chapter~\ref{chap:chap006}).
We carried out a comprehensive experimental study comparing a conventional and an assertiveness-based agent.
The latter proved significantly more effective in offering detailed explanations and tailoring communication to clinicians' medical experiences.
Clinicians favored the assertiveness-based agent, perceiving it as more reliable and proficient due to its enhanced understandability and competence.
This preference led to significant reductions in diagnosis time, implying improved efficiency.
Moreover, accuracy rates in diagnoses rose for both novice and expert clinicians.
We extend these findings to infer implications for \ac{AI} system design in medical domains and other fields requiring personalized \acp{HAII}, highlighting the broad applicability of this human-centered approach.

To summarize, our work contributes to the intertwined fields of \ac{HCI} and \ac{AI}, particularly, within the healthcare sector.
Our investigations span clinician acceptance of \ac{AI} systems, the role of human-centered design, and the importance of personalized explanations from intelligent agents.
The findings provide insights for improving decision-making in healthcare and pave the way for practical applications in crafting user-centric \ac{AI} technologies across critical sectors, signifying a substantial stride in \ac{HAII}.

\section{Thesis Statement Support}
\label{sec:chap007002}

This section supports the claims made in this dissertation (Section~\ref{sec:chap001003} of Chapter~\ref{chap:chap001}), aiming to significantly improve the efficiency of the diagnostic process for cancer patients through a human-centered design approach.
The first claim aligns with the principles of \ac{HCI} that emphasize reducing waiting times and alleviating the workload of clinicians in medical systems.
In fact, \ac{HCI} principles serve as guiding paradigms that prioritize \ac{UCD} methodologies, ensuring that \ac{AI} systems in medical imaging are seamlessly integrated and intuitive for clinicians.
While considering the power of such methodologies to address clinicians' experiences and perceptions, this thesis strives to create intuitive and seamlessly integrated \ac{AI} systems that enhance the diagnostic process.
The second claim aligns with the \ac{HCI} principles of personalizing and customizing \ac{AI} outcomes, emphasizing the importance of explainability and interpretability to foster trust and support informed decision-making.
\ac{HCI} research has highlighted the importance of designing \ac{AI} systems that provide clear explanations and insights, empowering clinicians to understand and trust the \ac{AI}-generated outcomes.
These \ac{HCI} principles reinforce the transformative potential of a \ac{UCD} approach, supporting the claims to enhance the efficiency of the diagnostic process and improve the overall healthcare experience.
Next, we provide a detailed description for each claim, offering fundamental evidence that supports these claims within the context of this thesis.

\vspace{1.00mm}

\begin{displayquote}
{\bf Claim:}
{\it
Through a human-centered design, the outcome of this dissertation aims to significantly improve the efficiency of the diagnostic process for cancer patients by reducing the waiting time from weeks to days, which is critical given the time-sensitivity of cancer treatments.
Additionally, it can reduce the workload of radiologists by decreasing the number of exams to be analyzed by half.
}
\end{displayquote}

\vspace{1.00mm}

Our meticulous human-centered design approach aims to significantly enhance the efficiency of the diagnostic process for cancer patients.
In Chapter~\ref{chap:chap004}, we investigate the integration of intelligent agents into medical imaging workflows, uncovering crucial factors that influence clinicians' acceptance and adoption of \ac{AI}-based systems in radiology.
Our findings enrich the theoretical foundations and provide practical recommendations for designing and implementing these technologies effectively, thereby improving the diagnostic process for cancer patients.
Chapter~\ref{chap:chap005} further advances our first claim by focusing on the human-centered design of \ac{AI} assistance in medical imaging diagnosis.
From our design interventions, we gain valuable insights that support clinicians' decision-making capabilities and satisfaction.
By prioritizing transparency, explainability, and usability, we strive to reduce waiting times and alleviate the workload of radiologists, enhancing the overall efficiency of the diagnostic process.
Collectively, these achievements underscore the potential of a human-centered design approach to significantly improve the diagnostic process for cancer patients and relieve the burden on radiologists.

\begin{displayquote}
{\bf Claim:}
{\it
Broader adaptation and customization of the \ac{AI} outcomes may augment individual clinicians to higher cancer detection rates, as well as a reduction of cost and risk for the patient.
As appealing concepts, personalizing and customizing the \ac{AI} outcomes for each clinician will promote a better understanding of \ac{AI} predictions and explain why \ac{AI} achieved some results.
}
\end{displayquote}

\vspace{1.00mm}

Chapter~\ref{chap:chap006} serves as a compelling support for our second claim, as it sheds light on the significance of personalizing and customizing intelligent agents' explanations within our human-centered design strategy.
The preference shown by clinicians towards the assertiveness-based agent, with its enhanced understandability and competence, further strengthens our claim for the importance of adapting and customizing \ac{AI} outputs to improve the comprehension of \ac{DL} predictions and explanations (Section~\ref{sec:app005008} of Appendix~\ref{chap:app005}).
These findings provide solid evidence that such an approach has the potential to enhance detection rates, reduce costs, and mitigate risks for patients.
Furthermore, our research implications transcend healthcare, demonstrating the versatility of personalized \ac{HAII} in diverse fields.
This confirms our thesis claim and underscores user personalization's transformative potential across contexts.

\section{Design Recommendations}
\label{sec:chap007003}

Our design recommendations are based on several thorough analyses.
The first analysis focused on accepting and adopting intelligent agents into the clinical workflow (Section~\ref{sec:chap004006002}).
Another vital study was optimizing workflow integration (Section~\ref{sec:chap005007003}).
Finally, we explored the power of adapting \ac{AI} systems to specific clinical characteristics (Section~\ref{sec:chap006007001}).
From these analyses, we derived recommendations for future \ac{AI} development, targeting enhanced clinical alignment and workflow efficiency.

\vspace{2.00mm}

\noindent
{\bf Guidance Control}:
To preserve clinicians' control, the system should offer precise explanations of the reasoning behind each \ac{DL} prediction and statistical confidence.
An \ac{AI} system should be designed with enough flexibility that allows clinicians to adjust or even override the final diagnostic when necessary.

\vspace{2.00mm}

In terms of decision-making control, \ac{AI} systems should be designed in a way that augments human decision-making rather than trying to replace it.
For better acceptance and adoption, clinicians should always have the final decision and be able to override the recommendations of \ac{DL} predictions if necessary.
This approach reinforces clinician agency, fosters trust, and ensures clinicians stay in charge of patient diagnosis.
In essence, the role of the \ac{AI} guidance should be viewed as a `decision-support' tool rather than a `decision-maker' tool, emphasizing the importance of human judgment in critical domains.

\vspace{2.00mm}

\noindent
{\bf Variability and Usability}:
Account for variability in behavioral characteristics of clinicians during decision-making and adapt \ac{AI} techniques accordingly.
Enhance understanding and usability of \ac{AI} systems to improve clinician trust.

In our human-centered design approach across several clinical institutions, we prioritize accounting for clinician variability during decision-making, impacting how they interact with \ac{AI} systems.
We recommend customizing \ac{AI} techniques to accommodate diverse clinician needs by aligning system functionalities and interfaces with their contexts, terminologies, and conventions.
This tailored approach enhances \ac{AI} usability, understanding, and clinician trust.
Not only it improves \ac{AI} effectiveness, and efficiency, but also supports collaborative decision-making among clinicians with different behavioral characteristics.

\vspace{2.00mm}

\noindent
{\bf Explainability and Transparency}:
Incorporate explainability functionalities, such as feature importance and granular visualization of the clinical arguments, to enhance clinicians' interpretation and belief in \ac{AI} recommendations, fostering interpretability and transparency.

\vspace{2.00mm}

To improve collaboration between clinicians and \ac{DL} models, prioritize explainability in system design.
Features like severity importance provide insights into the factors considered significant by the intelligent agent in making diagnostic decisions.
This enhances clinicians' understanding and confidence in \ac{AI} recommendations.
Additionally, visualizing detailed results can make complex \ac{AI} algorithms more interpretable, fostering transparency and deepening clinicians' comprehension of \ac{AI} suggestions.
Interactive functionalities should be integrated, allowing clinicians to explore variables and conditions and their impact on \ac{DL} predictions.

\vspace{2.00mm}

\noindent
{\bf Workflow Integration and Optimization}:
Integrate \ac{AI} systems seamlessly into the clinical workflow, optimizing the compatibility, performance, and efficiency of each institution.

\vspace{2.00mm}

\ac{AI} systems should be designed to comprehend and accommodate the unique procedures, guidelines, and standards inherent to each clinical setting.
This can be achieved by mapping the workflow and identifying clinicians' needs for specific tasks.
Additionally, \ac{AI} systems should be designed to adapt and evolve based on user feedback and changing clinical needs, incorporating mechanisms for continuous design improvement.
In this way, the \ac{AI} system can become a valuable tool in the clinical workflow, enhancing productivity and ultimately contributing to diagnostic performance.

\vspace{2.00mm}

\noindent
{\bf Longitudinal Studies and Continuous Evaluation}:
Conduct longitudinal studies and gather feedback to iterate on design-based evolving needs and challenges.

\vspace{2.00mm}

Adopt a longitudinal approach to monitor clinicians' evolving interactions with the \ac{AI} system and to pinpoint emerging challenges and enhancement opportunities.
Collect user feedback through multiple channels like surveys, interviews, and usage data, and iterate on the system's design and functionality based on the insights gathered.
Crucially, include clinical outcomes and efficiency measures in evaluations to ensure the system positively impacts medical workflows.
Be prepared to adapt the \ac{AI} system to significant changes in the clinical landscape, such as new guidelines or technologies.
This commitment to continuous evaluation and adaptation underpins the long-term success of \ac{AI} systems in healthcare.

\noindent
{\bf Combination of Classifiers and Enriched Training Models}:
Implement \ac{AI} systems that align with clinicians' mental models, providing personalized guidance and explanations.
Incorporate mixed information in training models to integrate \ac{AI} systems effectively into clinical workflows.

\vspace{2.00mm}

Design \ac{AI} systems that align with clinicians' mental models by incorporating classifiers that consider multiple factors like patient history, demographic data, and clinical observations.
The classifiers should be trained to consider these varied inputs, providing more holistic and accurate predictions.
To ensure effective integration into clinical workflows, the training of these models should also leverage mixed information.
This could include combining diverse data sources such as clinical notes, laboratory results, and imaging data, enhancing the system's ability to handle complex clinical scenarios.
The system should also explain its recommendations by linking them to relevant data or clinical guidelines, enhancing transparency and trust.
Ultimately, these design approaches can enhance the \ac{AI} system's utility in clinical decision-making and its acceptance by clinicians.

\vspace{2.00mm}

\noindent
{\bf Personalization of Communication}: Develop \ac{DL} models that predict mixed clinical arguments and adapt communication based on clinicians' experience and demographics.

\vspace{2.00mm}

To cater effectively to clinicians' needs, \ac{AI} system development should emphasize personalization.
This involves designing systems to predict mixed clinical arguments by incorporating data such as clinicians' experience level, medical specialty, and demographics.
Experienced clinicians may prefer concise, technical language, whereas less experienced ones might find more straightforward, explanatory language beneficial.
Moreover, tailoring communication to the clinician's specialty ensures the relevance of \ac{AI} recommendations.
This personalization enhances usability and fosters a sense of ownership and trust in the system.
By bridging the gap between technical complexity and clinical applicability, \ac{AI} provides personalized, meaningful insights to augment decision-making.
Additionally, the system should flexibly adjust its communication style based on feedback preferences.

\vspace{2.00mm}

\noindent
{\bf Adapting Communication Tone to Generalizability Concerns}: Adjust the communication tone based on \ac{DL} model confidence and case similarity to address the generalizability concerns effectively.

\vspace{2.00mm}

Ensuring effective communication between clinicians and \ac{AI} systems in the context of \ac{DL} models requires addressing the crucial concern of generalizability.
To achieve this, it is necessary to tailor the communication tone by considering two key factors:
(1) the {\it patients' dissimilarity problem} to the training set; leading to
(2) the {\it potential inaccuracies} in the model's confidence.
To adjust the tone based on confidence levels, it is recommended to incorporate case similarity by evaluating how closely the patient's characteristics align with the training data.
When the model encounters a case that significantly deviates from its training set, it should proactively alert the clinician about potential limitations and encourage further assessment.
Additionally, contextual explanations about the model's training data and its potential impact on predictions can greatly enhance clinicians' interpretability and decision-making abilities.

To conclude, these design recommendations call for \ac{AI} systems in healthcare to augment human decision-making, requiring flexibility and transparency.
Both \ac{HCI} and \ac{AI} communities should collaboratively strive to accommodate the diversity among clinicians and ensure seamless integration of their systems into clinical workflows.
Our recommendations stress continuous evaluation, alignment with clinicians' mental models, and personalization.
Emphasis is also placed on explainability, transparency, and tailored communication to address generalizability concerns.
The ultimate goal is to facilitate effective \ac{AI} integration into clinical institutions, thereby improving medical outcomes and patient care.

\section{Future Work Opportunities}
\label{sec:chap007004}

Our research carves a path for numerous intriguing future explorations.
A compelling next step could involve applying insights from the assertiveness-based agent to other high-stakes domains where pivotal decisions deeply impact individuals' lives, such as airport security or supermarket surveillance.
Additionally, these agents could prove valuable in fields marked by considerable variability in professional expertise.
For example, an assertiveness-based agent could provide \ac{AI} recommendations on optimal publication venues for research scientists.
This would help determine whether our findings hold specific relevance to the medical domain or possess broader applicability across varied professions.

We propose exploring diverse communication tones and enhancing explanation relevance by incorporating lexicon specific to breast modalities.
Unraveling the distinct characteristics of assertive and non-assertive tones, and integrating explanations with precise medical terminology, aims to cultivate a stronger rapport between humans and \ac{AI} systems.
Future work should focus on developing \ac{AI} tools that provide detailed, accurate, and tonally appropriate explanations.
We believe such improvements can enhance breast cancer diagnostic accuracy, leading to more confident and informed clinical decisions.

There is another significant potential for training \ac{DL} models to offer personalized, interpretable arguments, which could strengthen clinicians' trust in \ac{AI} recommendations.
Moreover, studying the impacts of essential functionalities, namely, explanations and tone, under a wider array of conditions is critical (Section~\ref{sec:app005015} of Appendix~\ref{chap:app005}).
For the \ac{AI} community, this means technical adaptations to the \ac{DL} model, while for the \ac{HCI} community, the challenge lies in ensuring transparency and accommodating the behavioral characteristics of the clinicians.

Potential future research directions include investigating clinicians' acceptance of \ac{AI}-based follow-up suggestions and assessing the influence of explanations within \acp{CDSSe}.
Furthermore, executing exploratory thematic analyses of intelligent agents, as well as designing ambiguity-aware \ac{AI} assistants, offers exciting research trajectories.
Advancements in these domains will augment our comprehension of the intersection between \ac{HCI} and \ac{AI} in healthcare, thereby facilitating the creation of enhanced, user-friendly tools for healthcare professionals and promoting improved patient outcomes.