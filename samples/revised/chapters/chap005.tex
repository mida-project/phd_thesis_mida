% #############################################################################
% This is Chapter 5
% !TEX root = main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Assessment \& Implications}
\clearpage
% The following line allows to ref this chapter
\label{chap:chap005}

\vspace{0.05mm}

\noindent
{\it Chapter~\ref{chap:chap005} was published in two journals, ranked Q1 in 2021 and 2022, respectively:}

\vspace{0.05mm}

\begin{itemize}
\item {\bf Francisco Maria Calisto}, Carlos Santiago, Nuno J. Nunes, Jacinto C. Nascimento, Introduction of Human-Centric AI Assistant to Aid Radiologists for Multimodal Breast Image Classification, International Journal of Human-Computer Studies, Volume 150, 2021, 102607, ISSN 1071-5819. DOI: \href{https://doi.org/10.1016/j.ijhcs.2021.102607}{doi.org/10.1016/j.ijhcs.2021.102607}
\item {\bf Francisco Maria Calisto}, Carlos Santiago, Nuno J. Nunes, Jacinto C. Nascimento, BreastScreening-AI: Evaluating Medical Intelligent Agents for Human-AI Interactions, Artificial Intelligence in Medicine, Volume 127, 2022, 102285, ISSN 0933-3657, DOI: \href{https://doi.org/10.1016/j.artmed.2022.102285}{doi.org/10.1016/j.artmed.2022.102285}
\end{itemize}

For this thesis, the main goal is to understand how the implemented \ac{DL} methods (Appendix~\ref{chap:app004}) can be integrated within an intelligent agent.
Moreover, it is essential to understand how the intelligent agent(s) can better communicate with clinicians as a second reader.
In this chapter, we take an \ac{HCI} perspective on the implications of \ac{AI} techniques~\cite{CALISTO2022102285} across the assessment of medical imaging~\cite{CALISTO2021102607}, focusing on workflow efficiency and quality, preventing medical errors and variability of diagnosis in breast cancer.

\section{Motivation}
\label{sec:chap005001}

The combination of \ac{AI} and medical imaging, known as ``radiomics''~\cite{Lambin2017}, has the potential to revolutionize radiology by automating the analysis of large amounts of data and extracting meaningful features to support diagnosis and clinical decision-making~\cite{Ruddle:2016:DEI:2872314.2834117}.
However, while modern assistant technologies such as \ac{DL} methods show promising accuracy (Section~\ref{sec:app003001}), the probabilistic nature of their algorithms can lead to mistrust and abandonment by clinicians who do not expect their clinical systems to behave inconsistently and imperfectly~\cite{Kocielnik:2019:YAI:3290605.3300641}.
Therefore, evaluating the acceptance and usability of \ac{AI}-based clinical systems was crucial to ensure successful adoption (Chapter~\ref{chap:chap004}) in real-world clinical setups.

Deficiencies in experimental and analytic designs have been identified in some studies~\cite{Sultanum:2018:MTP:3173574.3173996}.
However, these studies fail to include a more holistic understanding of the clinical context.
Another important consideration on using \ac{AI} in real-world clinical settings is the trust and usability of interactive assistance techniques~\cite{Cadario2021}.
While much work has focused on improving the accuracy of \ac{AI} algorithms, comparatively less work has been done to improve trust and usability~\cite{CALISTO2021102607}.
Thus, our research aims to answer high-level questions about how radiologists accept and interact with AI-assisted systems, how receptive they are to their introduction, and how they are affected by \ac{AI} assistance in different clinical contexts~\cite{CALISTO2022102285, CALISTO2021102607}.
For that, we propose an \ac{AI}-assisted approach, which integrates \ac{DL} techniques with a real clinical workflow for a multimodal medical imaging diagnosis~\cite{10.1145/3399715.3399744}.
Our proposed approach aims to improve diagnosis accuracy and reduce cognitive workload.
We also consider the importance of providing reasons for \ac{AI} recommendations to foster model transparency and user trust.

\subsection{Contributions}
\label{sec:chap005001001}

We created our proposed technique, based on the following contributions:
(1) exploring the power of explanations and the users' need for control on the introduction of \ac{AI} methods among medical imaging diagnosis; and
(2) studying the \ac{AI} impact on the radiologists' {\it behaviour} in professional practice.
We did that to achieve higher user expectations of the system capabilities, addressing potential gaps.
Although efforts have been dedicated to enhancing the precision of \ac{AI} algorithms, there has been relatively less emphasis on enhancing trust and usability of interactive assistance techniques.
Therefore, we ask several high-level questions, namely:
i) how they {\it accept} and {\it interact} with these systems;
ii) how {\it receptive} are the clinicians to the introduction of \ac{AI} assistance;
iii) how clinicians are {\it affected} by the \ac{AI} assistance in different clinical contexts.
This chapter contributes broadly to the literature in \ac{HCI} and \ac{AI} by examining what radiologists need when using \ac{AI}-powered image diagnostic, the practices they adopt while using these tools, and how they affect end-user attitudes towards the underlying \ac{AI} algorithms.

\subsection{Research Questions}
\label{sec:chap005001002}

A vital component of this dissertation thesis was to access many clinical settings and radiologists.
In this thesis, the work has established the foundations of its research via a human-centered design process and following the literature guidelines (Section~\ref{sec:app003002} of Appendix~\ref{chap:app003}) for \ac{HAII}~\cite{10.1145/3313831.3376718, 10.1145/3290605.3300233, 10.1145/3290605.3300234, Kocielnik:2019:YAI:3290605.3300641}, including:
i) findings from a user study in nine clinical institutions, encompassing {\it in-situ} observations and interviews, as well as grounded by related work; which informed
ii) a list of design recommendations for medical imaging systems, including temporal awareness, image processing, multimodality, trust, acceptance, and usage; leading to
iii) findings from an evaluation study of {\it BreastScreening-AI}, a proof-of-concept prototype that was developed to support the clinical translation of {\it radiomics}, validated by 45 physicians; and finally
iv) evidence from the impact of multimodality and \ac{AI}-assisted strategy in diagnosing breast cancer patients and severity classification of lesions.

\vspace{2.50mm}

\noindent
By focusing on the integration of multimodality and \ac{AI} techniques in {\it BreastScreening-AI} and clinical workflows, we formulated the following three research questions:

\vspace{0.05mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
\item {\bf RQ5.1.} What is the impact on clinicians' satisfaction and acceptance of \ac{AI} assistance with applied design interventions in radiology?
\item {\bf RQ5.2.} How can we improve clinicians' understanding and trust in \ac{AI} recommendations using design techniques to increase the explainability power of the system?
\item {\bf RQ5.3.} What is the impact of \ac{AI} assistance on the medical workflow, including accuracy, time performance, and variability in patient classification?
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Background}
\label{sec:chap005002}

In this section, two areas motivate our research work:
a) related works designing autonomous systems ({\it e.g.}, {\it radiomics}, \acp{CADe}, \acp{CADx}, \acp{CDSSe}) for the clinical workflow, while providing an assisted medical imaging analysis; and
b) the theories of \ac{HAII} collaboration while covering users' expectations and potential gaps.
The section begins by outlining the role of design for the clinical workflow and how it is currently handled in various steps of the \ac{DL} pipeline and {\it radiomics} stages (Figure~\ref{fig:fig027}, Section~\ref{sec:app004001} of Chapter~\ref{chap:app004}), including image segmentation, feature extraction, and image classification.
Then, the section introduces existing \ac{HAII} techniques for integrating intelligent agents into the framework.

\subsection{Clinical Workflow Design}
\label{sec:chap005002001}

In modern healthcare, medical images play a crucial role in supporting decision-making for diagnosis, predictions, and treatment planning~\cite{liang2019deep}.
Accurate lesion detection and segmentation are often mandatory for image analysis and {\it radiomics}, where numerous methods have been proposed to automatically perform these tasks~\cite{litjens2017survey}.
In the field of breast cancer, medical imaging systems allow clinicians to diagnose several modalities from the retrieval of medical imaging data~\cite{seifabadi2019correlation}.
To enhance clinical workflows, a wide range of \acp{CDSSe} are designed, including those that provide potential information for medical decision-making and those that make diagnostic decisions~\cite{10.1145/3290605.3300234, GU2020101858}.
However, experts may resist using a system if it does not capture the nuances of their mental models or provides relevant context~\cite{10.1145/2858036.2858373}.
Conversely, clinicians are known to resist changes and new tools~\cite{10.1145/3132272.3134111}, an issue that has an impact in their workflow.
In our research, we take a human-centered approach to understanding various design aspects and expectations of a medical imaging \ac{CDSSe} that is integrated into a real radiology workflow.
To accomplish this, we use methods such as bringing focus groups, workshops, observations, and interviews from the literature~\cite{Lim:2019:DDI:3319806.3301427} into our user research activities (Section~\ref{sec:chap005003001}).
By doing so, we aim to understand better how the system can be designed to meet the needs and expectations of its users (Section~\ref{sec:app003004007} of Appendix~\ref{chap:app003}), including radiologists and other medical professionals who work with the system on a regular basis.
In particular, our work demonstrates how an interactive \ac{AI} can directly address the above-mentioned challenges during medical imaging diagnosis.

The field of \ac{AI} is providing several \ac{DL} work models to assist clinical practitioners with appropriate knowledge~\cite{9540298, 9730804}.
However, the literature does not typically address the effectiveness of clinical \ac{AI} solutions from the perspective of human users~\cite{CALISTO2021102607}.
The work of Xie et al.~\cite{10.1145/3313831.3376807} has established the importance of providing reasons for the design of \ac{AI} recommendations to foster model transparency and user trust within these clinical workflows.
This work stressed that clinical systems should be designed based on the user needs of clinical practitioners, but the speculative evaluation of their system design does not provide much evidence of its integration into a real clinical workflow.

In another direction, Schaekermann et al.~\cite{10.1145/3313831.3376506} argue that explanations for clinical cases can be leveraged by \ac{AI} assistants to support medical reasoning.
Although similar to what we are doing in this work, these authors are not using real \ac{AI} outputs.
Instead, they are simulating hypothetical \ac{AI} scenarios and agent behaviors, manually generated by clinicians.
However, their work highlights the importance of explainability and interpretability of \ac{AI} models in the medical domain.
Concerning explainability and interpretability, two approaches are currently proposed: \ac{XAI} and Intelligibility~\cite{gunning2017explainable}.
\ac{XAI} and Intelligibility must take into account the fact that diverse data may contribute to a relevant result~\cite{10.1145/3411764.3445736, Bharadhwaj:2019:ERS:3308557.3308699}.
The work done by Holzinger et al.~\cite{holzinger2018current} addresses this need, namely {\it how} and {\it why} a machine has reached a given decision~\cite{shah2019artificial}.
Moreover, transparent algorithms could appropriately enhance the trust of clinicians in future \acp{HAII}~\cite{Dominguez:2019:EEA:3301275.3302274, Weisz:2019:BTS:3301275.3302290}.
Our work contributes novel perspectives on the system design and integration of a real \ac{DL} model for clinical assessments (Section~\ref{sec:app003003005} of Appendix~\ref{chap:app003}).

\subsection{Human-AI Interaction}
\label{sec:chap005002002}

Recent advances in medical technologies have driven research in \ac{HAII} across the clinical domain, where \ac{HAII} incorporates human feedback in the model training process to create better \ac{ML} models~\cite{10.1145/3411764.3445717, 10.1145/3411764.3445562}.
The \ac{iML} topic adds human expertise to \ac{AI}/\ac{ML} processes, allowing for re-enactment and retracing of results on demand, and requires new \ac{HITL} interfaces for \ac{XAI}~\cite{CALISTO2021102607}.
While much of the previous work in \ac{HAII} has employed handcrafted features, leveraging the rich image data features automatically learned from \ac{DL} algorithms can improve clinical recommendations and clinical decision-making~\cite{holzinger2019interactive}.
Guidelines for designing \ac{HAII} systems have been provided (Section~\ref{sec:app003002}), which can help to address issues of transparency, trust, and accountability.
More precisely, the work of Amershi et al.~\cite{10.1145/3290605.3300233} is providing a set of design guidelines to evaluate the quality of explanations.
Therefore, incorporating \ac{HAII} in medical imaging diagnosis can lead to the development of more accurate and reliable \ac{AI} systems that can enhance the workflow of medical professionals.

The use of \ac{AI} in diagnosis requires addressing two key issues:
(1) trust, transparency, and accountability of the agent~\cite{10.1145/3290605.3300233}; and
(2) the user's ability to understand and predict agent behavior through explainability and intelligibility~\cite{gunning2017explainable}.
In this context, expectation theories~\cite{Kocielnik:2019:YAI:3290605.3300641} suggest that user satisfaction and system adoption are tied to the gap between initial expectations and actual clinical experience.
Specifically, Quinn et al.~\cite{QUINN2022102158} are stating that expecting more than the system can deliver will decrease user satisfaction and lead to the rejection of the system.
Misaligned \ac{AI} recommendations can cause contention.
To mitigate the effects of misaligned \ac{AI} recommendations, strategies like giving users control over final diagnostic decisions can improve user expectations and satisfaction, especially when \ac{AI} falls short.
We aim to ensure that the abilities of our intelligent agent are correctly understood~\cite{CALISTO2021102607}, while studying its impact on radiologists' behavior.
These insights are helping us to address potential gaps and ensure that users have accurate expectations of what the intelligent agent is capable of.

\section{Design Keys}
\label{sec:chap005003}

The process that leads to the design of the {\it BreastScreening-AI} prototype~\cite{CALISTO2022102285} included a holistic understanding across the context of {\it radiomics} in breast cancer (Section~\ref{sec:chap002006}).
Herein, the developed study was specifically interested in using several modalities and intelligent agents to detect and classify lesions (Section~\ref{sec:chap002004}).
Quantitative and qualitative studies were conducted in nine health institutions to understand the medical procedures (Section~\ref{sec:chap002005}) surrounding {\it radiomics} in breast cancer (Section~\ref{sec:chap002002}), including the classifications of the lesion severity (Section~\ref{sec:chap002003}) using the \ac{BI-RADS} score.
At this point, impressions were taken regarding the efficiency of clinicians, and their recommendations based on their experience for improvements of the patient {\it examination} (Section~\ref{sec:app001005001} of Appendix~\ref{chap:app001}).
Several studies demonstrated that radiologist fatigue levels and performance are related to environmental factors such as the number of \acp{FP} and \acp{FN}~\cite{waite2017tired}.
That said, the study started by analyzing the potential enhancement that an \ac{AI}-assisted diagnosis could take in the \ac{RRR}.
To better understand the clinical procedures (Section~\ref{sec:app001005}) of the \ac{RRR} workflow (Section~\ref{sec:chap002005}), we implemented several design activities with users (Section~\ref{sec:chap005003001}) to acknowledge the insights and challenges of such workplace (Section~\ref{sec:chap005003002}), as well as to inform further the design of the {\it BreastScreening-AI} prototype (Section~\ref{sec:chap005003003}).

\subsection{Design Activities}
\label{sec:chap005003001}

In this thesis, all clinicians were actively involved in the design of this medical imaging solution.
To generate clinician's empathy and involvement, several design activities from participatory design were preliminarily used~\cite{10.1145/3308558.3314123}.
Under this thesis, the following design activities consist of three aspects: (a) {\it insight}; (b) {\it ideation}; and (c) {\it implementation}.
The proposed design activities are a practical, repeatable process along with clinicians by applying a human-centered approach to achieve an optimal solution for the first requirements of the intelligent agents (Section~\ref{sec:chap005003003005}).

Interviews and observations are helpful to obtain a synthesized {\it insight} in the clinical workflow (Section~\ref{sec:chap002005}).
As design activity according to this aspect, this work went through several observations and interviews at nine clinical institutions.
From those activities, information was extracted regarding, not only, workflow (Section~\ref{sec:chap002005}), but also, clinical characteristics of participants (Section~\ref{sec:chap005005001}).

For {\it ideation}, the goal is to find novel solutions around user needs and requirements.
In terms of design activities, this work promotes several brainstorming techniques.
Those techniques are such as workshops (Section \ref{sec:chap005003003001}), focus groups (Section~\ref{sec:chap005003003002}) and affinity diagrams (Section~\ref{sec:chap005003003003}).
Affinity diagramming~\cite{harrington2016affinity} has been used in this study to organize the acquired large sets of ideas into essential data needs for the workflow (Section~\ref{sec:chap005003003004}).
In this thesis, the methods are used to organize the findings and to sort design ideas into {\it ideation} of a focus group during several workshops.
These techniques will be further detailed and discussed (Section~\ref{sec:chap005003003}).

Finally, the {\it implementation} is promoted as a way of developing the first prototyping requirements (Section~\ref{sec:chap005003003005} of Appendix~\ref{chap:app003}).
The successful {\it implementation} was quickly recognized and would rely on a bare minimum number of requirements (Section~\ref{sec:app003003003}).
Short iterations enabled us to take advantage of these design activities for properly prototyping and testing the optimal solution with clinicians.

\subsection{Insights and Challenges}
\label{sec:chap005003002}

Interviews and observations are aligned with previous research on clinician-driven diagnostic {\it tasks}~\cite{Sultanum:2018:MTP:3173574.3173996}, informing our clinical procedures (Appendix~\ref{chap:app001}).
From the research {\it insights}, the following main challenges were identified:
i) how can we design for the heterogeneous visualization nature of large imaging numbers and file sizes; and
ii) how the introduction of intelligent agents can improve patient classification.
From the  observations and interviews, it was clear that clinicians observe only a fraction of the \ac{MRI} volumes (Section~\ref{sec:app001005002} of Appendix~\ref{chap:app001}).
Also, the imaging volumes inspected are different depending on the practices of each clinical institution \textcolor{revised}{(Figure~\ref{fig:fig018})}.
For instance, it was observed that in \acs{HFF} only the \acs{DCE-MRI} at the second time instant is considered, while in \acs{IPOL} only the third time instant of imaging volume is used for diagnosis.
Consequently, the \ac{UI} should reflect the specific institution, as it will be detailed in Section~\ref{sec:chap005004002}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht]
\centering
\includegraphics[width=\columnwidth]{images/fig018}
\caption{Workflow of the radiology reading room is commonly adopted in clinical institutions using several image acquisition strategies. Screening modalities ({\it e.g.}, US, MRI, etc.) constitute important complementary information for a reliable diagnosis.}
\label{fig:fig018}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Related to the requirements of {\it radiomics}, the second challenge involves the generation of \ac{GT} data.
This is twofold, namely,
(i) for visualization issues, when the radiologist can inspect the delineation provided, thus, facilitating an eventual second reading of the exam, also
(ii) it constitutes valuable information for training \acp{DNN} with (semi)supervised learning procedures, as mentioned above (Section~\ref{sec:chap002006}).
This comprises the localization/delineation of anatomical microcalcification and mass lesions.
In addition, it is easier to detect the lesion patterns (Section~\ref{sec:chap002004}) by comparing the breast region in different modalities.
This is particularly relevant in designing the {\it BreastScreening-AI} prototype, since the lesions in dense breasts are almost impossible to detect in \ac{MG} (in both \ac{CC} and \ac{MLO} views) -- a recognized problem leading to numerous non-diagnosed cancers -- which only manifest later in touch exams or after severe consequences on disease progression~\cite{mohamed2018deep}.

\subsection{Preliminary Design}
\label{sec:chap005003003}

\textcolor{revised}{This thesis, rooted in \ac{UCD}, integrates insights from participant interviews into our design approach.
It details the development of a medical assistant using an iterative methodology focused on clinicians' needs.
This approach aligns the solutions with healthcare professionals' requirements, leading to intuitive and effective designs for clinical use.
Our work connects \ac{AI} technology with practical application by centering on clinicians, ensuring relevance and utility in medical practice.}

\textcolor{revised}{Workshops (Section~\ref{sec:chap005003003001}) were pivotal in this process, with participants answering open-ended questions for broad insights.
Focus groups (Section~\ref{sec:chap005003003002}), involving the research team, further utilized affinity diagrams (Section~\ref{sec:chap005003003004}) for critical idea organization.
These diagrams, essential for clustering and categorizing ideas (Section~\ref{sec:chap005003003003}), aligned with \ac{UCD} principles to ensure design evolution through user feedback and collaboration.
The following sections detail this preliminary design, demonstrating adherence to \ac{UCD} methodologies, from data collection to iterative design refinement.}

\subsubsection{Clinical Workshops}
\label{sec:chap005003003001}

\textcolor{revised}{The first step of our design activities involved exploring the {\it workflow} practices and routines of clinicians.
This process began with sending out invitations to various medical institutions and organizing at least one workshop per institution.
Participants, detailed in Section~\ref{sec:chap005005001}, were volunteers who were grouped into different sessions.
The research team dedicated at least one day to each institution for these workshops.
Specifically, the \acs{HFF} institution required four workshop sessions due to its larger clinician population, posing scheduling challenges.
\acs{IPOL} and \acs{HB} institutions hosted two sessions.
For the remaining institutions, one workshop session was sufficient.
In total, 45 healthcare professionals, including Radiologists, Oncologists, and Surgeons, along with six members of the {\it BreastScreening} research team (specializing in \acs{HCI} and \acs{AI}), participated in these workshops.}

\textcolor{revised}{The decision to conduct workshops, rather than shadowing clinicians, was influenced by ethical and privacy considerations~\cite{10.1145/3449199}.
Our established protocol with \acs{HFF} was meticulously designed to encompass specific patients within our dataset, ensuring they are under ethical approval from the hospital.
However, this protocol did not encompass patients outside the protocol.
Consequently, shadowing clinicians in their routine practice would have risked inadvertent exposure of the non-anonymized patients inside this institution's \acs{RRR}, thereby contravening established ethical and privacy norms.
In light of this, workshops emerged as a more ethically sound alternative.
They enabled us to gather valuable insights while maintaining the privacy of all patients, particularly those who were not directly informed about or involved in our research activities.
This approach not only adhered to ethical standards but also ensured the integrity of our research process in the sensitive clinical environment.}

\textcolor{revised}{These workshops, integral to the {\it BreastScreening} research, involved group-based brainstorming sessions about clinical practices and routines.
The majority of these practices were meticulously recorded and subsequently transcribed digitally.
During these sessions, we employed the affinity diagramming\footnotemark[6] technique (Section~\ref{sec:chap005003003003}) to organize and analyze the data systematically.
This participatory approach was deliberately chosen to ensure that the design of our novel intelligent agent was informed by direct feedback and real-world needs, facilitating its seamless integration into clinical settings.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[6]{Affinity diagramming is a methodical approach for organizing and analyzing complex data sets. In our context, it was pivotal in understanding the role of technology within radiology workflows. By using affinity diagrams, we could categorize clinicians' information into coherent groups, aligning them with related ideas or topics, and enhancing our understanding of their workflow intricacies.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcolor{revised}{Each workshop session lasted approximately two hours and concluded with joint sessions where each clinician group highlighted critical aspects of the clinical {\it workflow} for their institutions.
Four distinct procedures for acquiring medical images were collated at the end of these sessions (Figure \ref{fig:fig018}).
Participants actively engaged in the design activities, providing valuable inputs regarding the intelligent agent.
Utilizing the insights gathered from the workshops, a prototype was developed and subsequently evaluated during multiple sessions across the nine clinical institutions (Section~\ref{sec:chap005005003}).}

\subsubsection{Focus Groups}
\label{sec:chap005003003002}

\textcolor{revised}{After the workshops with clinicians (Section~\ref{sec:chap005003003001}), a focus group of six Researchers (\acs{MSc}, \acs{PhD}, Post-Doc students, and faculty) and six Radiologists (2 seniors; 1 middle; 2 juniors; and 1 intern) from \acs{HFF} used affinity diagrams to organize {\it workflow} practices and functionality ideas~\cite{CALISTO2021102607}.
Using these affinity diagrams was an essential aspect of our \ac{UCD} methodology, enabling the systematic identification and prioritization of functionalities.
For instance, the affinity diagrams highlighted the critical need for clinicians to {\it accept} or {\it reject} the {\it assistant}'s results.
Notably, the affinity diagrams revealed a high-priority need for a feedback mechanism to retrain the DenseNet when clinicians {\it reject} the intelligent agent's recommendation (Section~\ref{sec:app004004} of Appendix~\ref{chap:app004}).
This approach refines functionalities based on clinician input, exemplifying \ac{UCD} and ensuring the design evolves with user needs and feedback.}

% \vspace{1.00mm}

\noindent
The technique is novel and, while applying these \ac{HCI} practices, it provides twofold contributions:

\vspace{0.50mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
\item Creating a new way of control on the introduction of \ac{AI} methods, via intelligent agents among medical imaging diagnosis; and
\item The inclusion of a \ac{DNN} in the \ac{UI} with the anthropomorphic characteristics of an intelligent agent, particularly, the introduction of a pre-trained DenseNet capable of providing a fast and reliable classification for humans to interpret.
To the best of our knowledge, this is the first attempt to include in the \ac{UI} feedback coming from a \ac{DNN} in breast cancer diagnosis with these characteristics.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.50mm}

Another important aspect coming from these focus groups is that the \ac{MG} image modality is always present on a first stage of medical image acquisition, mainly because of its low cost.
The \ac{US} is the second most preferred modality to cross information between \ac{MG} image modality views ({\it i.e.}, \ac{CC} or \ac{MLO}).
Finally, because of the high costs ({\it e.g.}, time of acquiring the images) associated with the \ac{MRI}, clinicians said (in nine institutions only one follows the {\bf Proc. 4}, see Figure \ref{fig:fig018}) it was typically recommended only for highly risk patients.

\subsubsection{Affinity Diagrams}
\label{sec:chap005003003003}

\textcolor{revised}{The use of affinity diagrams in our study was a dynamic and interactive process (Figure~\ref{fig:fig039}), characterized by the iterative addition and removal of items to achieve a final pattern configuration.
This approach, aligning with \ac{UCD} principles, was particularly effective given the diverse range of clinicians' ideas and functionalities.
Starting with a broad categorization, we established a strong foundation for a more detailed analysis, allowing us to capture a wide range of insights without prematurely restricting our focus.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\includegraphics[width=\columnwidth]{images/fig039}
\caption{Resulting affinity diagrams passed to a digital software tool. The overall ideas and functionalities for categorization. Each idea and functionality has a category ({\it e.g.}, ``Action Items'', ``Essential'', ``Went Well'', ``Need To Change'' or ``Questions and Discussion''), so that it can manage the final requirements and development priorities of the {\it Assistant}.}
\label{fig:fig039}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcolor{revised}{These ideas, functionalities, and priorities were then systematically translated into a digital format\footnotemark[7] using the collaborative tool.
Digital translation played a crucial role in streamlining data organization and enhancing collaboration among the research team.
It facilitated comprehensive insight capture and categorization, improving our data analysis's robustness.
Moreover, the flexibility of the digital format in modifying and reorganizing ideas was essential in adapting to evolving insights and feedback, a key aspect of the iterative \ac{UCD} process.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[7]{For that, the collaboration software \href{https://trello.com}{Trello} (\href{https://trello.com}{trello.com}) was used, which allowed this study to organize and manage the group ideas digitally. The links were accessed on the 5th of April, 2023.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{1.00mm}

\noindent
\textcolor{revised}{In this context, affinity diagrams~\cite{10.1145/3290605.3300628} played a crucial role by:}

\vspace{0.10mm}

\begin{enumerate}[(i)]
\item \textcolor{revised}{Categorizing items from the focus group, structuring the diverse inputs into coherent categories.}
\item \textcolor{revised}{Clustering chaotic and complex data, a common challenge in \ac{ML} projects~\cite{10.1145/2858036.2858373, 10.1145/3343413.3377983}, into manageable and interpretable groups.}
\end{enumerate}

\vspace{0.10mm}

\textcolor{revised}{Our methodology adeptly navigated the complexities of chaotic data analysis in medical imaging diagnosis.
By integrating affinity diagrams, we organized complex data and ensured continual alignment with clinician feedback.
This approach facilitated an iterative cycle where designs were consistently refined based on evolving insights, crucial for developing \ac{AI}-assisted diagnostic tools that are technically robust and clinically relevant, especially in breast cancer diagnosis.
The use of affinity diagrams thus became a pivotal element in our research, transcending data organization to reinforce a user-focused trajectory, ensuring that every stage of development resonated with the practical needs of clinicians.}

\textcolor{revised}{During the workshops (Section~\ref{sec:chap005003003001}), participants, encompassing both researchers and clinicians, were deeply engaged in the affinity diagramming process within the focus groups (Section~\ref{sec:chap005003003002}).
This collaborative effort involved critically reviewing and repositioning ideas and functionalities within various categories.
Initially grouped under the ``Action Items'' component, each concept or functionality was subject to a rigorous re-evaluation and re-categorization, facilitated by inclusive group discussions.
This methodical approach fostered a deeper understanding of the clinicians' perspectives and encouraged diverse viewpoints, enriching the design process with multifaceted insights.}

\textcolor{revised}{The iterative process was a conscious implementation of \ac{UCD} principles, aimed at ensuring the design's continuous alignment with clinicians' real-world needs and insights.
Embedding \ac{UCD} principles centrally within our methodology ensured that each element of the design was closely aligned with and shaped by the viewpoints of end-users.
This approach markedly improved the practicality and user-friendliness of our solutions in clinical settings.
Moreover, adopting these principles fostered a dynamic design environment, where feedback was actively sought and incorporated, resulting in a product that genuinely resonates with its intended users.}

% \vspace{2.5mm}

\noindent
For instance, several clinicians listed\footnotemark[8] their preferred components as the position (32/45) and simplicity (28/45) of the {\it Toolbar} (Section~\ref{sec:chap005004002}):

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[8]{The workshop answers and feedback were transcribed so that they can join with similar opinions in different items. A ``(32/45)'' means that 32 clinicians for a total of 45 clinicians appointed a similar sentence of the clinician number 30, {\it i.e.}, ``(C30)'' on that example.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{2.50mm}

\noindent
``{\it The {\bf Toolbar} position should be on the top in contrary to what we usually see}.'' (C30)

\vspace{2.50mm}

\textcolor{revised}{In this phase, we created a labeled ``Toolbar Position'' item, which underwent evaluation by the clinicians.
Most clinicians endorsed this item, leading to its placement in the ``Went Well'' category, indicative of positive reception.
This categorization reflected our \ac{UCD} principle of iterative design, where clinician feedback directly influenced the design process.
The minority who rejected or omitted the item offered insights for refinement, showcasing the dynamic, responsive nature of our \ac{UCD} approach.}

\vspace{1.00mm}

\noindent
Through the affinity diagrams, it was found that specific items, within each own categories, correspond to three needs of clinicians:

\vspace{0.10mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}[label=\alph*]
\item - new strategies among the medical imaging visualizations;
\item - to understand the intelligent agent ({\it Assistant}) result; and
\item - to control ({\it e.g.}, {\it accept} or {\it reject}) the final intelligent agent ({\it Assistant}) result.
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.10mm}

These threefold clinicians' needs were possible to achieve due to the correct application of affinity diagrams.
The technique was of chief importance to promote an understanding of this thesis background (Chapter~\ref{chap:chap002}).
Without such an approach, it would be impossible to follow the proper design of the developed intelligent agent.
Furthermore, the technique will follow all the steps and iterations that will be important for the future directions of this thesis (Section~\ref{sec:chap007004} of Chapter~\ref{chap:chap007}).

\textcolor{revised}{During the focus group sessions, clinicians emphasized the necessity to comprehensively map out all {\it workflow} processes and activities integral to the diagnostic pipeline.
This discussion underscored the significance of integrating \ac{AI} systems tuned to these specific {\it workflow} characteristics, thereby augmenting their clinical tasks.
This aspect of the research aligns with the \ac{UCD} approach, where understanding and incorporating user workflows is crucial in designing effective \ac{AI} tools.}

\vspace{1.50mm}

\noindent
One clinician even stated that an intelligent agent would make their job more straightforward:

\vspace{2.50mm}

\noindent
``{\it If we have an assistant like this in our workflow, it will be more simple and easy to do our job.}'' (C45)

\vspace{1.50mm}

\textcolor{revised}{This statement aligns with \acs{UCD}'s primary goal: simplifying and improving the user experience.
The identified needs to cover essential preconditions for prompt, accurate diagnosis, highlighting a user-centric approach in \ac{AI} system development.
Focusing on these needs ensured our research followed \ac{UCD} principles, making the intelligent agent's design and implementation responsive to clinicians' real-world requirements.}

Throughout this process, a set of design guidelines have been derived.
To investigate how the clinical {\it workflow} proceeds, affinity diagrams were used to connect ideas and functionalities to a set of guidelines that will be described next.
For this purpose, three central design components were created that can be applied for medical imaging systems with \ac{AI} behind:
(i) highlighting the essential lesion regions;
(ii) explaining the \ac{AI} results for higher interpretability; and
(iii) providing control of the final result.
As follows, these three design components are translated into four design guidelines.

\vspace{2.00mm}

\noindent
From Figure~\ref{fig:fig039} and from the feedback obtained when building the affinity diagrams, the following design guidelines were considered:

\vspace{1.50mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{description}
\item[Relevance to Diagnostic] - the \ac{AI} system ({\it Assistant}) should provide additional relevant clinical information so that clinicians can explore more granular details of the diagnosis.
For instance, information that allows clinicians to understand the relevant lesions (Figure~\ref{fig:fig032}) and the respective severity levels regarding both the shape and size of the lesion.

\vspace{1.50mm}

\item[Clinician-Centered Activities] - since data must be shared between clinicians, the \ac{AI} system should be designed to mimic collaboration.
For instance, clinicians should be able to remotely visualize the same lesion annotation synchronously.
This means the \ac{AI} system should support and enhance activities that facilitate discussion, leading to more robust decision-making.

\vspace{1.50mm}

\item[Provide Explanations] - the system must provide answers regarding the final \ac{AI} result.
In this work, an ``Explain'' button (Figure~\ref{fig:fig040}) was created so that clinicians can open the heatmaps (Figure \ref{fig:fig032}) on the image to explain the \ac{AI} recommendations.
The heatmaps will show the variability (color) of the important regions, which is information that will explain the final \ac{BI-RADS}.

\vspace{1.50mm}

\item[Feeling in Control] - the {\it Assistant} must provide control for the final decision. Clinicians must feel that, in case of a wrong \ac{AI} diagnostic, the final result must be changed ({\it reject}) by them so that we can guarantee the patient's safety and the right classification of the lesion.
\end{description}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{2.00mm}

\textcolor{revised}{To summarize, clinicians envision a transformation in their work processes as \ac{AI} tools integrate into breast cancer diagnosis.
This evolution requires comprehensive training for their adjustment to new \acs{AI}-augmented workflows and decision-making.
The collaboration between clinicians and \ac{AI} continuously refines itself through ongoing learning from new data, progressively improving diagnostic accuracy and efficiency.
In this section (Section~\ref{sec:chap005003003004}), we delve into the key role of data clustering within our research methodology.
Clustering, guided by the inherent `affinity' among collected ideas and functionalities, proves indispensable in uncovering common themes and patterns in the data, aligning seamlessly with established \ac{UCD} methodologies for informed design decisions~\cite{10.1145/3290605.3300234, 10.1145/3313831.3376718}.
In our \ac{UCD} approach, this clustering efficiently distills data from interviews and workshops into essential design components for medical imaging systems with \ac{DL} methods, ensuring user needs shape the design of intelligent agents.}

\subsubsection{Essential Data}
\label{sec:chap005003003004}

Analyzing the essential data is vital for the developed \ac{UI}.
Indeed, the \ac{MRI} data is inherently chaotic since each exam contains tens of volumes.
The volumes can be part of several sequences\footnotemark[9] for the \ac{MRI} modality.
Thus, designing a comprehensive visualization for such chaotic data is necessary.

\vspace{1.00mm}

\noindent
Specifically, for the medical imaging background (Chapter~\ref{chap:chap002}), the following \ac{MRI} characteristics were addressed:

\vspace{0.05mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{multicols}{4}
\begin{enumerate}
\item T1;
\item T2;
\item T2 Fat-Sat;
\item T2 TIRM;
\item Diffusion;
\item DCE MIP;
\item DCE WO;
\item DCE PEI;
\end{enumerate}
\end{multicols}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.05mm}

\textcolor{revised}{To address the ``chaotic data problem'' in our work, affinity diagramming was utilized~\cite{harrington2016affinity}.
The method streamlined the organization of notes by clustering them according to shared topics, thereby forming structured data groups.
Through an iterative process of labeling and clustering, we distilled the information into a few high-level groups.
These groups were crucial for pinpointing prevalent issues and viable solutions.
Employing this structured approach proved pivotal in delineating user needs and design challenges, ultimately guiding the design and development of the intelligent agent.}

\textcolor{revised}{During focus groups (Section~\ref{sec:chap005003003002}), participants pinpointed several user needs and requirements deemed essential (as shown in the ``Essential'' column of Figure~\ref{fig:fig039}).
These insights were critical in defining the most pertinent modalities and procedures for the medical imaging workflow (Figure~\ref{fig:fig018}).
Given the plethora of \ac{MRI} sequences available, clinicians often grapple with the challenge of visualizing all volumes effectively.
Identifying the \ac{MRI} volumes that align closely with clinicians' needs was thus imperative.
This identification was facilitated by the affinity diagrams, which distilled user needs and requirements, helping to define essential modalities and procedures for the workflow.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[9]{As the most sensitive method for detection of breast cancer (\href{https://radiopaedia.org/articles/breast-mri?lang=us}{radiopaedia.org/articles/breast-mri}), the breast MRI aims to obtain a reliable evaluation of any lesion within the breast. However, the modality relies on several sequence options, such as: (1) T1 (longitudinal relaxation time), the time constant which determines the rate at which excited protons return to equilibrium; (2) T2 (transverse relaxation time), similar to T1, but with the second time constant; (3) T2 Fat-Sat, pulses are short-duration tuned to the resonance frequency of fat; (4) T2 Turbo Inversion Recovery Magnitude (TIRM); (5) Diffusion, method that produces invivo MRI of tissues sensitized with the local characteristics of molecular diffusion; (6) DCE Maximum Intensity Projection (MIP); (7) DCE WithOut (WO) contrast agent; and (8) DCE Positive Enhancement Integral (PEI). Although they are more, these were the MRI sequence options used by the nine institutions. Nevertheless, it is important to underline that the MRI volumes are always used as an adjunct to the standard diagnostic procedures of the breast, {\it i.e.}, clinical examination, MG and US.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We also observed that clinicians from different hospitals had different preferences for \ac{MRI} sequences.
However, since the medical imaging data used was from the \acs{HFF} clinical institution, their main sequence (\acs{DCE-MRI} in a second instant) was chosen as the standard.
Through data clustering, the need for each modality (\acs{MG}, \acs{US} and \acs{DCE-MRI} at the second time instant) and its meaning to the clinical workflow (Figure~\ref{fig:fig018}) were identified.
The workshops (Section~\ref{sec:chap005003003001}) and focus groups (Section~\ref{sec:chap005003003002}) helped to gather essential data on how these modalities can provide complementary information for a reliable diagnosis, tailored to each institution's needs.

\subsubsection{Prototype Requirements}
\label{sec:chap005003003005}

% \vspace{2.50mm}

\noindent
\textcolor{revised}{In adherence to our human-centered design philosophy, the development of the \ac{AI}-assisted prototype was guided by two principal objectives:}

\vspace{1.00mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}
\item \textcolor{revised}{\textbf{Enhanced Diagnostic Capabilities through Multi-Modal Medical Imaging:} The prototype integrates a suite of functionalities specifically designed to assist clinicians.
These tools, prioritized during our iterative design interventions, aim to augment the diagnostic process by leveraging the strengths of multi-modal imaging.}
\item \textcolor{revised}{\textbf{Automated Severity Assessment of Lesions:} Incorporating a DenseNet architecture, the prototype functions as an anthropomorphic intelligent agent.
This agent is responsible for providing \ac{BI-RADS} scores and detailed explanations, thereby enhancing the interpretability and reliability of lesion severity classification.}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{1.00mm}

\textcolor{revised}{The iterative design process, encompassing workshops and focus groups, facilitated a deeper engagement with clinicians, enabling us to garner valuable insights and feedback.
This participatory approach was instrumental in refining the prototype to better align with clinical needs.
For example, a significant modification, based on clinician feedback, involved repositioning the \ac{UI} of the intelligent agent.
Originally positioned at the upper and central part of the display, the \ac{UI} was repositioned to the lower right corner within the {\it Viewports} ({\it Re-5.1.} of Figure~\ref{fig:fig040}).
This adjustment was determined to be more user-friendly and less disruptive to the clinical workflow.}

\textcolor{revised}{With a direct outcome from our design process, this relocation is anticipated to enhance clinicians' efficiency in decision-making and reduce the time required for patient diagnosis.
Furthermore, it addresses the potential for reducing medical errors.
The decision to integrate the {\it Assistant} ({\it Re-6.} of Figure~\ref{fig:fig040}) avatar within the {\it Viewports} ({\it Re-5.1.} of Figure~\ref{fig:fig040}) was driven by the need for seamless accessibility and minimal disruption to the clinicians' established workflow patterns.
This integration exemplifies \ac{UCD} principles, with iterative feedback and testing crucial in evolving the design to meet user needs.
In the subsequent Section~\ref{sec:chap005003004}, we explore how these design choices enhance breast cancer diagnosis through intelligent agent integration.}

\textcolor{revised}{Anticipating that these recommendations will enhance clinicians' decision-making efficiency, as well as reduce diagnostic time and medical errors, our design activities led to significant conclusions (Section~\ref{sec:app003004005} of Appendix~\ref{chap:app003}).
In summary, the strategic placement of the {\it Assistant} avatar ({\it Re-6.} of Figure~\ref{fig:fig040}) within the {\it Viewports} ({\it Re-5.1.} of Figure~\ref{fig:fig040}) ensures easy accessibility, aligning with clinicians' usual workspace and reducing interaction time.
This placement highlights our commitment to user-centric design, ensuring the tool meets clinical needs and integrates smoothly into the existing workflow.
By focusing on \ac{UX} enhancement, we aim to improve the acceptance and effectiveness of \ac{AI}-assisted diagnostic tools, contributing to more efficient and accurate medical assessments.}

% \vspace{2.50mm}

\noindent
\textcolor{revised}{Because of that, this design choice addresses visibility concerns in two ways:}

\vspace{1.00mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{enumerate}[(a)]
\item \textcolor{revised}{Primarily, the majority of \ac{MG} and \ac{MRI} imaging modalities typically do not display critical information in the lower right area of the {\it Viewports} ({\it Re-5.1.} of Figure~\ref{fig:fig040}), where the avatar is positioned.}
\item \textcolor{revised}{Additionally, we integrated a feature enabling the {\it Assistant} avatar ({\it Re-6.} of Figure~\ref{fig:fig040}) to be temporarily hidden via a discreet button.
This ensures clinicians have an unobstructed view of the entire image when needed, preserving the diagnostic process's integrity.}
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{1.00mm}

\textcolor{revised}{These user-centered design adaptations (detailed in Section~\ref{sec:app003003001}) not only make the intelligent agent more accessible, but also seamlessly integrate it into the clinicians' existing workflow.
This integration is a testament to the application of \ac{UCD} principles, emphasizing iterative feedback and refinement in developing \acs{AI}-assisted tools.
In the following Section~\ref{sec:chap005003004}, we are further exploring the integration of \acs{AI}-assisted methods in the design of intelligent agents.
Specifically, we will examine how the {\it BreastScreening-AI} design contributes to mitigating challenges in breast cancer diagnosis, aligning with overarching healthcare design objectives.}

\subsection{Design Goals}
\label{sec:chap005003004}

In this section, it is investigated how \ac{AI}-assisted methods could be integrated into the design of an intelligent agent for the medical imaging diagnostic on breast cancer.
The purpose is to help mitigate breast cancer diagnosis, while meeting overall design goals.
This solution provides an absolute scale for clinicians' performance and leads to the instrumentation of the hereby design goals and constrains.
With the introduction of intelligent agents, the designed {\it BreastScreening-AI} framework~\cite{CALISTO2021102607} dictated a departure from the later {\it BreastScreening} annotating tool~\cite{10.1145/3399715.3399744} wrapping approach of \ac{AI} techniques, toward a new communication that only exposes the required patient information, as well as lesion classification and segmentation functionalities (Appendix~\ref{chap:app008}).

The {\it BreastScreening-AI} framework is designed to reduce the burden of usage and expand clinicians' performance by simplifying the complexities that are frequently encountered when clinicians are diagnosing a patient.
Here, the main goal is to expose the \ac{AI} algorithm results in a readily available format~\cite{CALISTO2022102285}.
The design goals of {\it BreastScreening-AI} have been for a robust, reliable, and elegant \ac{UI} to promote the integration of intelligent agents in the \ac{RRR} workflow.

The main design goals are closely related to the research insights and challenges of the previous section (Section~\ref{sec:chap005003002}), namely:
(1) collection of a \ac{GT} annotations, {\it i.e.}, masses in all imaging modalities and microcalcification lesions in \ac{MG} (for both \ac{CC} and \ac{MLO} views);
(2) classification of the lesion severity using the \ac{BI-RADS}~\cite{aghaei2018association};
(3) categorization of the breast tissues (dense vs non-dense);
(4) clinical co-variables, such as personal and family records; and
(5) visualizations for clinical summary which are crucial for a proper diagnosis and to perform patient follow-up.

% \vspace{1.50mm}

\noindent
These five insights were fused into three corresponding design goals, as follows:

\vspace{1.00mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{description}
\item[\ac{MID}] focusing on how to provide the best visualization strategy, given the heterogeneous information coming from the multi-modal nature of the information;

\vspace{0.50mm}

\item[\ac{CRD}] focusing on improving the clinician's ability to {\it accept} or {\it reject} the \ac{AI}-assisted results;

\vspace{0.50mm}

\item[\ac{EXD}] focusing on increasing physician's understanding of how the \ac{AI} techniques operate. By increasing understanding of how \ac{AI} works, physicians can update their expectations of how well and in which situations the system is likely to work;
\end{description}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{1.50mm}

Until now, this is the first attempt to holistically integrate these design goals in the context of medical imaging diagnosis supported by \ac{AI}-assisted methods.
Through user studies, it was identified the above three ({\it i.e.}, \ac{MID}, \ac{CRD} and \ac{EXD}) design goals.
Next, the document will describe the {\it BreastScreening-AI} framework~\cite{CALISTO2021102607} taking into account these design goals.

\section{BreastScreening-AI}
\label{sec:chap005004}

To validate the proposed design goals, a prototype called {\it BreastScreening-AI} framework was developed~\cite{CALISTO2021102607}.
As a proof-of-concept fully functional prototype, this tool aims to be evaluated in a realistic clinical scenario.
In the following sections, the document will describe the main functionalities for prototyping the {\it BreastScreening-AI} framework.
Next, the document describes the prototype details and system implementation.

\subsection{Implementation}
\label{sec:chap005004001}

Similar to an earlier version, the {\it BreastScreening-AI} framework was implemented using \href{https://cornerstonejs.org/}{CornerstoneJS} with a \href{https://nodejs.org/}{NodeJS} server.
Once the set of medical images is loaded in the visualization viewport (Figure \ref{fig:fig040}) the user can interact with the data by manipulating the visualization through the mouse and keyboard.
For instance, rolling the mouse wheel to navigate across the volume slices (\acs{MRI}) or even moving the mouse to drag-and-drop the several modalities to the viewport.
The goal of the proposed multi-modal strategy is then to provide the visualization and manipulation of several modalities, comparing lesion patterns among medical images.

Due to the integration of intelligent agents, the new developments of the {\it BreastScreening-AI} prototype were giving this thesis the opportunity to test properly what are the implications of \ac{AI} techniques on the \ac{RRR} workflow.
Such implications are achieved through the implementation and integration of a classifier model (DenseNet) into the designed \ac{UI}~\cite{maicas2018training}.
By showing the work design decisions, the following sections will cover these prototyping directions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{images/fig040}
\caption{\textcolor{revised}{The proposed {\it BreastScreening-AI} provides several functionalities. Specifically, it is possible to validate the DenseNet output classification along with radiologists. The system is framed in the following subcategories: Study List Tabs (Re-4.5.); Viewports (Re-5.1.); Toolbars (Re-5.2.); Modality Selection (Re-5.3.); Assistant (Re-6.); Accept (Re-6.1.); Explain (Re-6.2.); Reject (Re-6.3.); and Physician Severity (Re-6.3.1.). On Explain (Re-6.2.), the assistant will pop-up several heatmaps. The proposed model has two main stages: (i)  first it computes the BI-RADS, based on the output classification of the DenseNet; and (ii) it computes the size and circularity of the lesion based on the heatmaps.}}
\label{fig:fig040}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{User Interface}
\label{sec:chap005004002}

In this section, we describe the design and implementation of the \ac{UI} for the {\it BreastScreening-AI} prototype based on identified user needs (Section~\ref{sec:chap005003003}).
The \ac{UI} includes a set of refinement mechanisms to guide clinicians during the diagnostic process (Figure~\ref{fig:fig040}), comprising two main components:
(1) the list of patients; and
(2) medical imaging views.
The \textcolor{revised}{{\it List of Patients Views} ({\it Re-4.})} include a \textcolor{revised}{{\it List of Patients} ({\it Re-4.1.})} with the most important and required information for clinicians.
From here, users can search all patients using criteria such as {\bf Patient ID}, {\bf Study Date}, available {\bf Modality} sets, {\bf Study Description}, and number of {\bf Images}.
The \textcolor{revised}{{\it Study List Tabs} ({\it Re-4.5.})} allow clinicians to switch between diagnosed patients and medical imaging diagnosis views.
The \ac{UI} is also informing clinicians about how to classify and use the system, where we designed the \textcolor{revised}{{\it Toolbars} ({\it Re-5.2.})} functionality to match the user's requirements, and \textcolor{revised}{{\it Viewports} ({\it Re-5.1.})} to process the image by using \textcolor{revised}{{\it Toolbars} ({\it Re-5.2.})} provided functionalities.
In the end, \textcolor{revised}{inserting the \ac{BI-RADS} use case was held by the {\it Physician Severity} ({\it Re-6.3.1.}) functionality}, allowing clinicians to classify the severity of the breast lesion for each patient.

Overall, this section describes the design and implementation of the \ac{UI} for prototyping the first iterations of the {\it BreastScreening-AI} framework.
Specifically, it includes refinement mechanisms to guide clinicians during the diagnostic process.
The following sections will map the two main \ac{UI} functionalities, {\it i.e.}, assistant (Section~\ref{sec:chap005004002001}) and explainability (Section~\ref{sec:chap005004002002}), between the design goals (Section~\ref{sec:chap005003002}) under this thesis.

\subsubsection{Assistant}
\label{sec:chap005004002001}

\textcolor{revised}{Figure~\ref{fig:fig040} shows the {\it Assistant} ({\it Re-6.}) with its {\it Accept} ({\it Re-6.1.}) and {\it Reject} ({\it Re-6.3.}) functionalities, enabling clinicians to directly control the \ac{DNN} classifications derived from the DenseNet model~\cite{Huang_2017_CVPR}.
However, integrating a \ac{DNN} needs special attention (Appendix~\ref{chap:app004}).
Typically, the training of a \ac{DNN} is expensive regarding the time spent (Section~\ref{sec:app004001}), since its classification performance will improve as the training dataset becomes larger.
Thus, training the model from scratch is not the best option.
For this reason, we pre-train ({\it i.e.}, off-line training before the \ac{UI} integration) the \ac{DNN} on the ImageNet dataset~\cite{10.1145/3351095.3375709} and fine-tuned using our multi-modal breast dataset (Section~\ref{sec:app004005}).
Specifically, we fine-tune the \ac{DNN} using supervised learning.
Only afterwards, the pre-trained DenseNet is incorporated into the \ac{UI}.}

The implemented DenseNet takes medical images as an input and outputs the severity probability.
The input consists of images ({\it i.e.} \ac{MG}, \ac{US} and \ac{MRI} slices) with the corresponding label ({\it i.e.}, the \ac{BI-RADS}) that is previously classified by an expert.
The output consists of having five nodes in the last layer of the \ac{DNN}.
Each node is assigned to a given class that corresponds to each \ac{BI-RADS} score.
After this stage, we have conditions for the integration, since now the DenseNet is tuned to perform the classification in unseen test images.
The classification is fast, being tailored for an online diagnosis.

\textcolor{revised}{When several modalities (\ac{MID} and \ac{CRD}) are correctly used, regarding the {\it Modality~Selection} ({\it Re-5.3.}) on a multimodality view, the clinician can find more accurately the right severity classification, as concluded in Section~\ref{sec:app003003002} of Appendix~\ref{chap:app003}.
For the {\it Reject} ({\it Re-6.3.}) option, the physician will have the opportunity to insert (\ac{CRD}) the proposed \ac{BI-RADS} on a drag-and-drop menu of severity options by using the {\it Physician Severity} ({\it Re-6.3.1.}) functionality.
Both \ac{MID} and \ac{CRD} goals are supporting our {\bf RQ5.1} question (Section~\ref{sec:chap005001002}).}

\subsubsection{Explainability}
\label{sec:chap005004002002}

\textcolor{revised}{Finally, the clinician may press for the {\it Explain} ({\it Re-6.2.}) functionality  by looking at the generated heatmaps (Figure~\ref{fig:fig032}).
The generation of the above colour maps come from the following information:
(i) the area ({\it Lesion Size}) of the lesion that comes from the delineation process,
(ii) the circularity/sharpness ({\it Lesion Shape}) that can be computed from the annotation in (i), and
(iii) the \ac{BI-RADS} score automatically provided by the DenseNet ({\it i.e.}, classifier intelligent agent).
The \ac{EXD} design goal is performed as above described helping to answer to research questions {\bf RQ5.2} and {\bf RQ5.3} (Section~\ref{sec:chap005001002}).}

Covered by the \ac{EXD} design goal, the thesis can provide a key component to disambiguate the \ac{AI} result with the application of an explanation technique (Section~\ref{sec:chap003007}).
For a better prediction, the result of this explanation process is a heatmap visualizing the importance of each pixel.
With heatmaps, clinicians can capture and understand the logic arguments of the DenseNet (Section~\ref{sec:chap005006002}) by giving images and pixels a color meaning of the lesion severity.
Thus, the \ac{EXD} design goal is bringing the opportunity to disambiguate this \ac{DL} method for a more transparent and explainable (\ac{XAI}) process.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\includegraphics[width=\columnwidth]{images/fig032}
\caption{On Explain (Re-6.2.), the assistant will pop-up several {\it heatmaps}. The {\it heatmaps} represent two different scales: (a) {\it Shape}; and (b) {\it Size} of the lesion. First, the model computes the BI-RADS using the DenseNet classification. Second, the model computes the lesion circularity (top scale) and size (bottom scale) and associate it to the colors regarding both circularity/size and BI-RADS.}
\label{fig:fig032}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Methods}
\label{sec:chap005005}

For this study, an evaluation of {\it BreastScreening-AI} simulating real-world conditions with 45 clinicians, within-subject, in nine different clinical institutions was conducted.
The study goal was to quantitatively and qualitatively assess the proposed design principles that the {\it BreastScreening-AI} embodies, and to understand how these principles would work in practice.
The experimental setup aimed at testing two conditions: {\bf Clinician-Only} ({\it Current}) -- simulating clinicians' {\it current} setup, equal to what they have in their clinical institutions, {\it i.e.}, a multimodality strategy without any \ac{AI}-assisted technique; {\bf Clinician-AI} ({\it Assistant}) -- multimodality strategy taking advantage of the \ac{AI}-assisted ({\it e.g.}, DenseNet~\cite{9098470}), supporting clinician's second opinion and autonomous patient diagnostic.

\vspace{2.00mm}

\noindent
For each condition, three classes of patients were defined:

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{itemize}
\item {\bf Class 1}: patients such that \ac{BI-RADS} $\leq$ 1 (low severity);
\item {\bf Class 2}: patients such that 1 $<$ \ac{BI-RADS} $\leq$ 3 (medium severity);
\item {\bf Class 3}: patients such that \ac{BI-RADS} $>$ 3 (high severity);
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Having data available is challenging and requires multiple steps (Section~\ref{sec:app004002} of Appendix~\ref{chap:app004}), including anonymization of data.
The ideal approach is a collaboration between clinicians and \ac{AI} researchers, either in-house or through collaborative research agreements.
Therefore, a protocol was celebrated with \acs{HFF} so that the interchange of patients could be possible.
The purpose of this protocol is to establish bases of collaboration in all scientific and technological areas, as well as education and training in which \ac{IST} and \acs{HFF} carry out their activities.
From this protocol, the exams were annotated by eight radiologists and classified with a \ac{BI-RADS} severity from an expert doctor.
The expert doctor is the head of the radiologist services of the \acs{HFF} clinical institution.

\subsection{Participants}
\label{sec:chap005005001}

In this study, participants were asked to practice with three predefined sets of patients randomly selected from the three above classes.
To accomplish this, each patient was randomly selected ({\it i.e.}, {\bf P1}, {\bf P2} and {\bf P3}) from each class ({\it i.e.}, {\bf Class 1}, {\bf Class 2} and {\bf Class 3}), respectively.
Then, participants were asked to diagnose each patient.
A natural expectation is that the intelligent agent would minimize the time required and accuracy ({\it e.g.}, improving \ac{FP} or \ac{FN} values).
The study involved 45 clinicians, recruited on a volunteer basis from a broad range of clinical scenarios, including nine different health institutions (two public hospitals, two cancer institutes, one private hospital, and two private clinics).

\vspace{4.00mm}

\noindent
In the following list, the number of clinicians and respective clinical institutions is provided:

\vspace{2.00mm}

\begin{multicols}{2}
\begin{itemize}
\item 12 clinicians of \acs{HFF};  % HFF
\item 10 clinicians of \acs{IPOL}; %IPOL
\item 2 clinicians of \acs{HSM};   %HSM
\item 9 clinicians of \acs{IPOC};  %IPOC
\item 1 clinician of \acs{MMC};    %MMC
\item 1 clinician of \acs{SAMS};   %SAMS
\item 8 clinicians of \acs{HB};    %HB
\item 1 clinician of \acs{HSA};    %HSA
\item 1 clinician of \acs{JCCC}.   %JCCC
\end{itemize}
\end{multicols}

\vspace{2.00mm}

Before the experiment, clinicians first filled out a pre-study questionnaire eliciting demographic information (Appendix~\ref{chap:app006}), including age group, gender, and medical professional experience, among others.
From the demographic questionnaires:
24.4\% of the clinicians have between 31 and 40 years of practical experience (seniors);
31.1\% have between 11 and 30 years of experience (middles);
17.8\% have between 6 and 10 years of experience (juniors); and
26.7\% have limited experience (interns).
Interviews were conducted in a semi-structured fashion, taking about 30 minutes.
Overall, 57 days were spent on the clinical institutions for the observation process and six months for the classification.

\subsection{Apparatus}
\label{sec:app002005002}

To track user interactions across the evaluated system, we used the \hyperlink{https://www.hotjar.com/}{Hotjar} tool.
This tool is an analytic package allowing this study to follow users remotely.
It also provides two critical pieces of functionality, among others, that can aid in remote user testing.
First, the frequency areas allow us to see where users are clicking, tapping and scrolling on the system.
Second, it records a video playback of the entire user session.
To record the task activities and the interview, the \hyperlink{https://support.apple.com/downloads/quicktime}{QuickTime} application was used for user's screen recording.
It was also useful for identifying any issues or errors that occurred during the user testing sessions.

Finally, to understand radiologists' reading behaviour an eye-tracking device was used while they were interacting with the intelligent agent.
The selected device was the \hyperlink{https://gaming.tobii.com/product/tobii-eye-tracker-4c/}{Tobii Eye Tracker 4C}, since Tobii is the largest commercial eye tracking manufacturer, and is one of the most common trackers among usability practitioners~\cite{CALISTO2021102607}.
Also, the \hyperlink{https://www.tobiipro.com/product-listing/tobii-pro-sdk/}{Tobii Pro SDK} was used, providing the thesis results with gaze information of the eye tracking device.

\subsection{Procedure}
\label{sec:chap005005003}

After providing informed consent for participation in the study, clinicians reported information about their demographics (age, gender, etc) and professional background (professional or academic training, number of years of clinical experience).
Next, clinicians familiarized themselves for about 30 seconds with \ac{UI} and with the basic interface components common to both Clinician-Only and Clinician-AI conditions (Section~\ref{sec:chap005005}).
However, the two conditions are different.

The first condition (Clinician-Only) relies on classifying patients without \ac{AI} assistance.
The goal was to understand what is the actual clinicians' performance.
Thus, a simulation of the current clinicians' available tools on the \ac{RRR} was held, while interacting with the first developed tool.

For the second condition (Clinician-AI), the procedure required to reject (or accept) the proposed \ac{BI-RADS} (Section~\ref{sec:app003003} of Appendix~\ref{chap:app003}) provided by the intelligent agent.
At this stage, participants will interact with the new framework ({\it i.e.}, the {\it BreastScreening-AI} prototype) using the multi-modal dataset acquired and curated under this thesis.
The test set is comprising a number of 289 patients (Section~\ref{sec:app003003004} of Appendix~\ref{chap:app003}).
In the dataset, there are cases where the patient does not have all the image modalities (recall Figure~\ref{fig:fig018} where the acquisition may finish before all the modalities are available).
Thus, the following requirements were defined to conduct the study work analysis.

\vspace{2.00mm}

\noindent
The requirements are as follows:

\vspace{0.05mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}
\item All patients must have each of the three available modalities;
\item All patients were annotated and classified by the radiology team of \acs{HFF};
\item The patients were grouped in low, medium, and high severity according to the \ac{BI-RADS};
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{0.05mm}

The above procedure allowed this work to obtain a set of 415 cases.
Notice that the dataset is partitioned according to the three classes mentioned above.
Similar for both conditions (Clinician-Only and Clinician-AI), the first task was to fill out pre-test forms, as already mentioned.
The second task was the user characterization form, providing participant demographic data.
Next, each participant accessed the system via a web browser.
Each of the 45 clinicians were assigned three patients ({\it e.g.}, {\bf P1}, {\bf P2} or {\bf P3}), for diagnosis.
Thus, for each clinician, it was assigned one patient with low severity, one with medium severity, and another one with high severity.

When analyzing the patients, for the second condition (Clinician-AI), the main task was to {\it accept} or {\it reject} the proposed \ac{BI-RADS} value provided by an intelligent agent.
This may increase the diagnostic time slightly.
In case of {\it rejecting} the proposed value, participants were asked to provide a new \ac{BI-RADS} value on the \ac{UI}.
An {\it explain} functionality was provided to be used informing participants concerning where and how much sever the lesions are (Figure~\ref{fig:fig032}).
However, for the first condition (Clinician-Only), the \ac{BI-RADS} classification was provided by clinicians in the end of patient analysis alongside filling a form (Appendix~\ref{chap:app006}).
These setups will be used to support the work results (Section~\ref{sec:chap005006}).

Before the main test, every interaction was shown by the facilitator, and upcoming questions were clarified (Appendix~\ref{chap:app007}).
In the end, for each participant it was applied both \ac{SUS}~\cite{Tyllinen:2016:WNN:2858036.2858570} and \ac{NASA-TLX}~\cite{10.1145/3399715.3399744} on two different questionnaires for usability\footnotemark[10] and workload\footnotemark[11] measurements.
Moreover, trust\footnotemark[12] is measured through three questions adapted from the Model of Trust~\cite{CALISTO2021102607} that is mentioned in this work as \ac{DOTS}.
Finally, a {\it post-task} questionnaire~\cite{10.1145/3132272.3134111} was carried out.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[10]{For SUS scores, we used a 5 item scale. The scores range from 1 - ``{\bf Strong Disagree}'' to 5 - ``{\bf Strong Agree}'' as a simple scale to measure usability. The mean across all individual questionnaires was computed over studies. We provide an available {\it dataset} (\href{https://mimbcd-ui.github.io/dataset-uta7-sus/}{mimbcd-ui.github.io/dataset-uta7-sus}) from our SUS data.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[11]{For NASA-TLX scores, we used a 20 item scale. The scores range from 1 - ``{\bf Very Low}'' to 20 - ``{\bf Very High}'' with more item options to measure workload. Again, we provide an available {\it dataset} (\href{https://mimbcd-ui.github.io/dataset-uta7-nasa-tlx/}{mimbcd-ui.github.io/dataset-uta7-nasa-tlx}) from our NASA-TLX data.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[12]{For DOTS scores, we used a 20 item scale comprised by three questions: \ac{DOTS}: (1) {\bf Understanding}: ``{\it I understand what the system is thinking}''; (2) {\bf Capability}: ``{\it The system seems capable}''; and (3) {\bf Benevolence}: ``{\it The system seems benevolent}''. The three questions were answered on a 20-point scale from ``{\bf 0\% - Totally Disagree}'' to ``{\bf 100\% - Totally Agree}'' with 5\% increments.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Analysis}
\label{sec:chap005005004}

In this study, we aim to understand user behavior during decision-making by taking into account differences between medical expert levels ({\it i.e.}, {\it Intern}, {\it Junior}, {\it Middle}, and {\it Senior}), user characteristics, and medical imaging interpretation.
The study included both quantitative (Section~\ref{sec:chap005005004001}) and qualitative (Section~\ref{sec:chap005005004002}) analyses.
The quantitative analysis focused on not only measuring usability, workload, and trust but also evaluating the radiologists' performance ({\it e.g.}, number of \acp{FP} and \acp{FN}) during diagnosis of three groups of patients ({\it i.e.}, low, medium, and high severity) for each doctor.
In addition, the qualitative analysis aimed to provide a more in-depth understanding of the radiologists' experience with the {\it BreastScreening-AI} prototype, including the feedback provided by clinicians on ease of use, usefulness, and overall satisfaction with the system.
Qualitative data were collected through interviews, and the analysis was conducted using established qualitative research methods.
Both quantitative and qualitative analyses were compared between Clinician-Only and Clinician-AI setups.

\subsubsection{Quantitative Analysis}
\label{sec:chap005005004001}

For the quantitative\footnotemark[13] analysis, we used several measures to evaluate the impact of intelligent agents on the medical workflow and to understand the clinicians' experience during diagnostic.
In addition to the well-known \ac{SUS} to assess the perceived workload required by the complex, highly demanding tasks of medical imaging diagnosis.
To further understand the impact of the intelligent agent on the medical workflow, we also measured trust through three questions adapted from the Model of Trust~\cite{CALISTO2021102607}, which we referred to in this work as \ac{DOTS}. 
The diagnostic classification was also measured to find correlations with the lesion severity ({\it i.e.}, Low, Medium, and High values of the \acs{BI-RADS}).
For that, we measured the number of \acp{FP} and \acp{FN} to understand severity rates.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[13]{By {\bf quantitative analysis}, it means the use of metrics to measure tasks, which will reflect on the task performance, efficiency and efficacy. Measuring {\bf quantitative data} offer an indirect assessment of the design usability as well.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{1.5mm}

\noindent
Hence, four relations emerged under this analysis:

\vspace{0.5mm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{enumerate}[label=\alph*]
\item - differences between {\it \ac{SUS} Scores} and {\it \ac{SUS} Questions} across the groups of medical experience ({\it i.e.}, {\it Intern}, {\it Junior}, {\it Middle}, and {\it Senior}) on both setups;
\item - workload measurements of both Clinician-Only and Clinician-AI setups;
\item - trust evaluation of the system capability for providing \ac{AI} recommendations;
\item - relation between diagnostic {\it time} and lesion severity on both conditions ({\it i.e.}, Clinician-Only and Clinician-AI), among different groups of medical experience; and
\item - \acf{FP} and \acf{FN} ratios;
\end{enumerate}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\vspace{1.5mm}

To compare both conditions with respect to outcome measures per clinician, we used the one-way \ac{ANOVA} test~\cite{SADEGHI2022105554, 10.1145/3491102.3517791}.
We measured the time taken by clinicians in seconds for diagnosing each of the three patients ({\it i.e.}, {\bf P1}, {\bf P2} and {\bf P3}), and accuracy rates via \acp{FP} and \acp{FN} of the clinician-provided classifications.
To assess the efficacy differences between intern, junior, middle, and senior clinicians during decision-making, we used the chi-squared test of independence~\cite{10.1145/3411764.3445464} to evaluate the relationship between the dependent and independent variables.

Although \ac{SUS} is more regularly used as a single score, in this study the scale was used as individual questionnaires.
Individual \ac{SUS} scores have typically negative skew~\cite{10.1145/3399715.3399744}, but the mean sample values are usually normally distributed.
Therefore, we took advantage of this statistical behavior to compute the quantitative analysis (Section~\ref{sec:chap005006001}) under this thesis.
On the other hand, the basic \ac{NASA-TLX} scores were used to measure workload, which is highly reliable~\cite{10.1145/3399715.3399744}.
\ac{NASA-TLX} questionnaire consistently exhibits high reliability, user acceptance, and low inter-subject variability to measure workload.
In this study, \ac{NASA-TLX} was used to identify clinicians' workload during various stages of the workflow.

Trust in the intelligent agent was a critical factor in determining its effectiveness in the medical workflow.
To further elaborate on the \ac{DOTS} metric, it is a widely used measure of trust that evaluates individuals' perceptions of trust in automation.
The \ac{DOTS} questionnaire (Appendix~\ref{chap:app006}) comprised three questions: understanding, capability, and benevolence.
These questions allowed us to assess how well the clinicians understood what the system was thinking (Section~\ref{sec:app003004009003} of Appendix~\ref{chap:app003}), whether they believed the system was capable of supporting their decision-making process, and whether the system acted in their best interests.
By measuring trust using this scale, we gained insights into clinicians' perceptions through the capabilities of the intelligent agent and their trust in its decision-making processes.

Result metrics of precision and recall were also measured (Section~\ref{sec:app003004009002} of Appendix~\ref{chap:app003}).
Then, it was applied to a standard analysis to determine the effect of the attributes on the clinician's interpretation and expectations (Section~\ref{sec:app003004007}).
To have a fair measure of the system performance, the \ac{GT} of the real \ac{BI-RADS} values (provided by the head of the radiology department) was calculated and used as a comparison metric (Section~\ref{sec:app003004006}).
From the \ac{GT} (Section~\ref{sec:app003004009001}), the number of \acfp{TP}, \acfp{TN}, \acfp{FP} and \acfp{FN} were computed.

In order to take further conclusions of the acquired data, the following performance measures are summarized as: \underline{R}ecall (R = \ac{TP} / (\ac{TP} + \ac{FN})), \underline{P}recision (P = \ac{TP} / (\ac{TP} + \ac{FP})).
For instance, if a clinician provides a \ac{BI-RADS} of 3 but the real \ac{BI-RADS} is a 5 we consider it as an \ac{FN} result.
On the other hand, if the real \ac{BI-RADS} is a 2 but the clinician provides a \ac{BI-RADS} of 4 we consider it as an \ac{FP} result.
Another factor to take into account is that the \ac{BI-RADS} is a scale (Section~\ref{sec:chap002003}), {\it i.e.}, it has an order.
This means that, if the model says the \ac{BI-RADS} is 3 ({\it i.e.}, {\it Medium} severity), when the real \ac{BI-RADS} is 5 ({\it i.e.}, {\it High} severity), it should be less serious than the model saying it is a \ac{BI-RADS} of 1 ({\it i.e.}, {\it Low} severity).

\subsubsection{Qualitative Analysis}
\label{sec:chap005005004002}

The qualitative\footnotemark[14] analysis in this study aimed to provide a deeper understanding of the radiologists' experience with the {\it BreastScreening-AI} prototype.
The feedback provided by clinicians, such as convenience, utility, and fulfillment with the system, was obtained through interviews.
The objective was to extract opinion-based feedback from the recorded audio and translate it into a set of sentences, counting the number of clinicians who shared a similar opinion.
Clinicians were asked to provide feedback on how they made decisions for each patient case ({\it i.e.}, {\bf P1}, {\bf P2}, and {\bf P3}), what information they used to make these decisions, and how the explainability information affected their decision-making.
The subjective feedback obtained from the interviews helped to provide valuable insights into the clinicians' perception of performance and accuracy (Section~\ref{sec:app003004009}), which can be used to improve and refine the prototype.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\footnotetext[14]{By {\bf qualitative analysis}, it means the observational findings from clinicians that identify and answer our design methods and features to use. The {\bf qualitative data} was divided into two groups: (1) {\bf qualitative attitudinal data}; and (2) {\bf qualitative behavioral data}. The first one, can be defined as clinician's thoughts, beliefs and self-reported needs obtained from the user interviews, focus groups and affinity diagrams.}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Results}
\label{sec:chap005006}

In this chapter, we present the findings of our work across the impact of \ac{AI} assistance in radiology.
Our analysis encompassed multiple aspects, including usability (measured by the \ac{SUS} questionnaire), workload (measured by the \ac{NASA-TLX} questionnaire), and usefulness.
By examining these aspects comprehensively, we gained valuable insights into the effectiveness of our design interventions in improving user satisfaction, acceptance, and overall usability of \ac{AI} assistance systems in the radiology domain.
Additionally, we explored the impact of \ac{AI} assistance on clinicians' understanding, trust, and workflow, shedding light on the benefits of \ac{AI} in terms of accuracy, time performance, and variability in patient classification.
These results provide a comprehensive understanding of the impact of \ac{AI} assistance on the medical workflow and highlight the potential of \ac{AI} to enhance decision-making, efficiency, and patient care in radiology.
Additional findings and analysis are provided in Section~\ref{sec:app003004} of Appendix~\ref{chap:app003}.
Next, we will address specific research questions, providing detailed insights into each aspect of our work.

\subsection{RQ5.1: Satisfaction and Acceptance}
\label{sec:chap005006001}

In this section, we outline the consolidated results of our study on clinicians' satisfaction and acceptance of \ac{AI} assistance in radiology.
We applied a human-centered approach, utilizing design interventions such as focus groups, observations, and interviews.
Usability was gauged using the \ac{SUS} questionnaire, with more in-depth findings presented in Sections~\ref{sec:app003004001}~and~\ref{sec:app003004002} of Appendix~\ref{chap:app003}.
The workload was quantified using the \ac{NASA-TLX} questionnaire, with additional results found in Sections~\ref{sec:app003004003}~and~\ref{sec:app003004004}.
The aspects of usefulness are further discussed in Section~\ref{sec:app003005002}.
Our user-centric approach, integrating various measures, tools, and methodologies, allowed us to capture a comprehensive view of clinicians' perceptions of \ac{AI} assistance in radiology.

The \ac{SUS} questionnaire (Figure~\ref{fig:fig109}) was employed to assess usability in terms of reliability, learnability, and satisfaction.
The results revealed positive usability outcomes for the {\it assistant} (Clinician-AI) condition.
Clinicians agreed that introducing \ac{AI} assistance did not bring more complexity to the diagnostic task (86\% agreement).
Moreover, 85\% of clinicians preferred the Clinician-AI, indicating positive perceptions of the system's usability (Section~\ref{sec:app003004001}).
The \ac{SUS} questionnaire results showed that introducing the \ac{AI} assistant (Clinician-AI) significantly increased clinicians' acceptance and satisfaction compared to the {\it current} (Clinician-Only) scenario.
The Clinician-AI obtained a higher agreement percentage (69\%) than the Clinician-Only (22\%), indicating a higher acceptance of the \ac{AI}-assisted techniques.
Additionally, the Clinician-AI condition showed higher agreement percentages for ease of use (85\%) and integration with workflow (82\%) compared to the Clinician-Only condition (71\% and 83\%, respectively).
These findings underscore the effectiveness of the design interventions in enhancing clinicians' satisfaction and acceptance of AI assistance in radiology.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[ht]
\centering
\includegraphics[width=\columnwidth]{images/fig109}
\caption{Results of SUS scores between {\it current} (Clinician-Only) and {\it assistant} (Clinician-AI) conditions. The bars represent the mean score for each question, {\it i.e.}, ranging from 1 = ``Strongly disagree'' to 5 = ``Strongly agree'' of the scale. The SUS questionnaire consists of ten questions (Q1 to Q10), displaying the results of each question in two rows of {\it current} and {\it assistant} conditions. A visual representation provides information on participants' responses to each question, allowing for comparative analysis.}
\label{fig:fig109}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\textcolor{revised}{The \ac{NASA-TLX} questionnaire was utilized to assess perceived workload, enabling an analysis of cognitive load changes across different conditions.
A one-way \ac{ANOVA} test was conducted for this purpose, revealing significant differences in workload between the Clinician-AI and Clinician-Only conditions.
The test yielded an F(3, 41) = 3.274, indicating statistical significance (p = 0.03 $<$ 0.05).
These results highlight the Clinician-AI condition's effectiveness in reducing perceived workload compared to the Clinician-Only condition ($\sim$48\%).
Regarding specific values, the Clinician-AI condition resulted in a lower perceived workload (M = 5.729, SD = 0.819) than the Clinician-Only condition (M = 11.99, SD = 5.556).
Cohen's effect size was calculated with {\it f} = 0.081, suggesting a small effect, while $\eta^{2}$ = 0.0066, explaining approximately 0.7\% of the variance in workload between conditions.}

\textcolor{revised}{The Clinician-AI condition resulted in lower perceived mental and physical demands (Section~\ref{sec:app003004003} of Appendix~\ref{chap:app003}).
However, its performance was perceived less favorably (Section~\ref{sec:app003004004} of Appendix~\ref{chap:app003}), possibly due to more visualization modalities and a larger amount of information, including explanations.
Nonetheless, these results show the \ac{AI} assistant's role in reducing cognitive and physiological strains in medical decision-making.
Clinicians noted enhanced efficiency and performance, highlighting the \ac{AI} system's effectiveness in easing cognitive burden and improving workflow productivity.}

In assessing the usefulness of the \ac{AI} assistance, structured {\it post-task} interviews and comprehensive {\it open-ended} queries were conducted, as referenced in Section~\ref{sec:app003005002} of Appendix~\ref{chap:app003}.
This approach was specifically chosen to objectively capture clinicians' insights regarding the system's efficacy and integration into their regular practice.
Analysis of these qualitative inputs revealed that the majority of clinicians (41/45) have actively incorporated the \ac{AI} algorithm into their daily clinical routines.
Moreover, clinicians reported noticeable enhancements in their operational efficiency and workflow optimization (28/45), attributable to the \ac{AI} tool.
These results not only demonstrate a robust adoption of the \ac{AI} assistant but also suggest its significant impact in augmenting clinical performance and workflow management.

\vspace{2.50mm}

\noindent
Comments highlighted the valuable role of the assistant in enhancing diagnostic accuracy, reducing workload, and enabling new quantitative information to be added to reports:

\vspace{2.50mm}

\noindent
``The system [{\it BreastScreening-AI} assistant] will be a great asset for us.'' (C6)

\vspace{2.50mm}


Indeed, clinicians (33/45) expressed positive views on the system's ability to improve diagnostic accuracy, provide timely and relevant information, and facilitate more informed decision-making.
The results indicated that design interventions played a crucial role in enhancing the perceived usefulness of the system.
Integrating \ac{AI} technologies in radiology was seen as a promising approach to augment clinical practices and enable better patient care.

In conclusion, integrating an intelligent agent into the clinical workflow was well-received by clinicians.
This success is due to strategic design interventions, informed by a human-centered approach, providing substantial insights for our {\bf RQ5.1}.
The \ac{AI} assistant received favorable feedback from clinicians, resulting in higher levels of acceptance, satisfaction, and usability when compared to the Clinician-Only scenario.
Notably, the \ac{AI} assistant effectively reduced workload, while also being perceived as valuable in enhancing diagnostic accuracy and improving overall clinical practices.
These findings underscore the potential of \ac{AI}-assisted techniques in optimizing the radiology workflow and empowering clinicians to make well-informed decisions.

The positive reception and acceptance of the \ac{AI} assistant by clinicians highlight the importance of integrating intelligent agents into medical practices, paving the way for continued advancements in healthcare delivery.
As \ac{AI} technologies continue to evolve and improve, it is crucial to foster ongoing collaboration between clinicians, researchers, and technology developers to ensure the responsible and ethical integration of \ac{AI} in radiology and beyond.
By harnessing the full potential of \ac{AI}-assisted techniques, we can aspire to achieve higher levels of precision, productivity, and quality in healthcare, ultimately benefitting both medical professionals and the patients they serve.

\subsection{RQ5.2: Understanding and Trust Enhancement}
\label{sec:chap005006002}

To address the research question {\bf RQ5.2}, we investigated how design techniques can improve clinicians' understanding and trust of the \ac{AI} recommendations by considering the explainability power of the system (Figure~\ref{fig:fig111}).
We measured clinicians' understating, while assessing clinicians' trust across the Model of Trust~\cite{CALISTO2021102607} using the \ac{DOTS} questionnaire (Section~\ref{sec:app003004007} of Appendix~\ref{chap:app003}) for this purpose.
In addition, we collected feedback (Section~\ref{sec:app003005002} of Appendix~\ref{chap:app003}) on the explainability functionalities of the system through qualitative interviews so that we can understand how well the system provides explanations for its \ac{AI} recommendations.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure}[htbp]
\centering
\includegraphics[width=\columnwidth]{images/fig111}
\caption{Results of DOTS and acceptance scores for the {\it assistant} (Clinician-AI) conditions. Each question is ranging from 1 = ``Strongly disagree'' to 20 = ``Strongly agree'' of the scale. The figure provides a visual representation of the participant's responses to perceived {\it Understanding}, {\it Capability}, and {\it Benevolence} of the DOTS scores. Additionally, we measured perceived overall {\it Acceptance} on the assistant, as well as differences in acceptance when clinicians do not ask ({\it No Explain}) or ask ({\it Explain}) for explanations.}
\label{fig:fig111}
\end{figure}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this study, we employed a visual technique utilizing heatmaps to highlight regions of severity in the recommendations of the \ac{AI} system.
The heatmap information visualization effectively conveyed the severity of lesions, with hotter colors (Figure~\ref{fig:fig032}) indicating higher severity.
Results from the \ac{DOTS} questionnaire (Figure~\ref{fig:fig111}) indicated that 98\% of the clinicians comprehended the reasoning behind the system, demonstrating a high level of understanding.
Specifically, clinicians exhibited greater levels of perceived understanding when actively engaging with the assistant by pressing the {\it Explain} button (M = 19.7, SD = 2.92) compared to refraining from pressing it (M = 10, SD = 7).
This highlights the role of more granular explanations~\cite{10.1145/3544548.3580945}, enhancing clinicians' understanding of \ac{AI}-assisted diagnostics.

A notable 93\% of clinicians conveyed confidence in the system's abilities, underscoring their trust in the \ac{AI} system's recommendations for precise patient diagnosis.
Through the introduction of {\it Accept} ({\it Re-6.1.}), {\it Reject} ({\it Re-6.3.}), and {\it Explain} ({\it Re-6.2.}) buttons (Figure~\ref{fig:fig040}), perceived benevolence (M = 14.67, SD = 5.24) was increased while providing control and flexibility of the final diagnosis.
After asking for an explanation, 76\% of the clinicians increased their agreement ({\it i.e.}, pressing the {\it Accept} button) with the final diagnostic.

Finally, 91\% accept and prefer the \ac{AI} setup (Figure~\ref{fig:fig111}).
Trust values in our assistant (M = 18.81, SD = 2.96) were significantly higher (p = 0.0003 $<$ 0.05) when compared to clinicians who did not press the {\it Explain} button (M = 12.43, SD = 3.21).
Bringing higher levels of acceptance to the \ac{AI} recommendations of the assistant when explaining the severity classification of lesions through heatmaps.
Additionally, there was no significant imbalance in prior frequency for using the {\it BreastScreening-AI} framework.

In conclusion, our study addressed the research question {\bf RQ5.2} by investigating how design techniques can enhance clinicians' understanding and trust in \ac{AI} recommendations, considering the explainability power of the system.
We employed various metrics and questionnaires to assess clinicians' understanding and trust.
Using heatmaps as a visual information technique effectively conveyed the severity of lesions, and clinicians exhibited a high level of understanding, comprehending the reasoning behind the system.
This resulted in higher levels of perceived understanding, where clinicians expressed increased trust in the system's capabilities.

The inclusion of control functionalities further increased perceived benevolence.
Moreover, clinicians preferred the \ac{AI} setup, indicating a positive acceptance of the \ac{AI} recommendations.
Our findings demonstrate that the explainability functionalities achieved through our design process enhance clinicians' understanding and trust in autonomous recommendations, promoting their acceptance and preference for the \ac{AI} setup.

\subsection{RQ5.3: Workflow Impact}
\label{sec:chap005006003}

In this section, we present the results obtained to answer research question {\bf RQ5.3}, which focuses on the impact of \ac{AI} assistance on the medical workflow, including accuracy (Section~\ref{sec:app003004009003} of Appendix~\ref{chap:app003}), time performance (Section~\ref{sec:app003004009}), and variability (Section~\ref{sec:app003004008}) in patient classification.
We begin by investigating the rates of \acp{FP} and \acp{FN} with and without \ac{AI} assistance.
Then, we examine the diagnostic time and breast severity concerning using \ac{AI} assistance.
Next, we delve into the clinical impact of \ac{AI} assistance, exploring the improvement in accuracy and time performance.
Lastly, we discuss the alterations in clinical workflows resulting from integrating \ac{AI} assistance.
By presenting these results, we aim to provide a comprehensive understanding of the \ac{AI} assistance impact on the medical workflow.
The findings shed light on the benefits of \ac{AI} in healthcare settings, including enhanced accuracy, reduced diagnostic time, and improved consistency in patient classification.

\textcolor{revised}{In Table~\ref{tab:tab017}, a comparison of \ac{FP} and \ac{FN} rates was conducted between scenarios where clinicians worked alone and those where they were assisted by \ac{AI} (Section~\ref{sec:app003004009001} of Appendix~\ref{chap:app003}).
The findings revealed a notable decline in \acp{FP} when \ac{AI} was utilized, signifying an adaptation in the risk tolerance of radiologists.
In particular, the incidence of \acp{FP} fell from 39\% to 15\% \textcolor{revised}{{\it compound reduction}} with the aid of our intelligent agents, demonstrating a decreased tendency towards overestimating diagnoses.
This substantial 24\% \textcolor{revised}{{\it compound reduction}} in \acp{FP} underscores the effectiveness of \ac{AI} in refining the accuracy of patient classification and curtailing superfluous treatments~\cite{10.1001/jamainternmed.2014.981}.
Furthermore, there was a 19\% \textcolor{revised}{{\it compound reduction}} in \acp{FN} with \ac{AI} assistance, indicating a more measured approach to risk.
This suggests that \ac{AI}'s application mitigates the issue of overdiagnosis and bolsters the identification and categorization of breast anomalies, thereby ensuring more precise diagnoses and minimizing the likelihood of overlooking critical conditions.
These insights highlight the significant role of \ac{AI} in augmenting the precision of patient classification and judicious risk management in clinical decision-making processes.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\input{tables/tab017}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

From a dataset of 289 patients, we analyzed our results to explore the relationship between diagnostic time and breast severity (Section~\ref{sec:app003004005} of Appendix~\ref{chap:app003}).
Our findings revealed notable differences in diagnostic time across different severity levels.
For patients with low severity ({\bf P1}), the average diagnostic time in the Clinician-Only condition was 146 seconds (SD = 86.17), whereas the Clinician-AI condition showed a shorter average of 89 seconds (SD = 74.13).
Similarly, for patients with medium severity ({\bf P2}), the Clinician-Only condition had an average diagnostic time of 78 seconds (SD = 48.05), while the Clinician-AI condition exhibited a slightly lower average of 77 seconds (SD = 96.80).
Notably, patients with high severity ({\bf P3}) experienced a longer average diagnostic time of 116 seconds (SD = 65.70) in the Clinician-Only condition compared to the Clinician-AI condition, which had an average of 64 seconds (SD = 86.94).
\textcolor{revised}{Moreover, the one-way \ac{ANOVA} test, resulting in F(1, 44) = 11.31 with a p-value of 0.005 (p $<$ 0.05), indicates a significant influence of clinical experience on the time taken to diagnose cases of varying severity.
This result underscores that \ac{AI} assistance notably decreases diagnostic time across different severity levels.
The analysis further reveals that the clinicians' level of medical experience affects the time efficiency in decision-making.}

The introduction of \ac{AI} assistance positively influenced both inter-variability and intra-variability agreement (Section~\ref{sec:app003004008} of Appendix~\ref{chap:app003}) among clinicians during patient classification.
With \ac{AI} assistance, there were significant reductions in variability.
Regarding inter-variability, the \ac{CV} decreased from 57.69\% to 46.69\% for patients with low severity, demonstrating improved agreement and consistency among clinicians.
For patients with a medium severity, inter-variability improved by 3.28\%, while the most notable improvement of 34.10\% was observed for patients with high severity.
Intra-variability also decreased within specific clinician groups, including interns, juniors, middles, and seniors, with reductions ranging from 6.65\% to 23.66\%.
These findings indicate that \ac{AI} assistance enhances inter-variability agreement and reduces variability within clinician groups based on their medical professional experience.

Overall, \ac{AI} assistance promotes more reliable and consistent patient classification outcomes, improving diagnostic decisions.
Therefore, clinicians benefit from improved agreement and enhanced diagnosis consistency, improving patient care.
The results of this study demonstrate the positive impact of \ac{AI} assistance on the medical workflow.
The utilization of \ac{AI} assistance significantly improves accuracy in patient classification, reduces the time required for various tasks, and enhances inter-rater agreement.
These findings support the integration of \ac{AI} technologies in healthcare settings, emphasizing their potential to enhance efficiency, accuracy, and consistency in decision-making during breast cancer diagnosis.

\subsection{Summary}
\label{sec:chap005006004}

Here, we encapsulate the main findings of our study.
These results summarize each facet of our investigation, elucidating the impact of \ac{AI} medical assistance and the advantages of employing a human-centered design approach.
By analyzing these crucial aspects, we aim to elucidate the effects of design interventions on clinicians' experiences and perceptions.
The analysis of satisfaction and acceptance encompasses usability, workload, and usefulness, while understanding and trust enhancement focuses on clinicians' comprehension and confidence in \ac{AI} recommendations.
Finally, the investigation of workflow impact delves into accuracy, diagnostic time, and variability in patient classification.

\textcolor{revised}{In addressing satisfaction and acceptance ({\bf RQ5.1}), our study found that implementing \ac{AI} assistance with targeted design interventions markedly enhanced clinicians' satisfaction and acceptance in radiology settings.
According to the \ac{SUS} questionnaire, the \ac{AI}-assisted condition achieved a 69\% higher agreement rate, reflecting a 91\% increase in perceived usefulness of \ac{AI}-assisted techniques over the Clinician-Only approach.
Notably, 82\% of clinicians affirmed the system's usability, ease of use, and effective integration into their workflow.
The \ac{NASA-TLX} scores confirm a notable decrease in cognitive workload ($\sim$48\%) with \ac{AI} assistance.
Post-task feedback indicates clinicians appreciate the \ac{AI} system's clear insights for better diagnostics.
These findings emphasize user-centered design's importance in improving clinician satisfaction with \ac{AI} tools in radiology, leading to more efficient, effective care.}

Regarding understanding and trust enhancement ({\bf RQ5.2}), our study revealed that design techniques could improve clinicians' understanding and trust in \ac{AI} recommendations.
About 85\% of clinicians exhibited a high level of understanding and trust in the system's capabilities.
Including explainability functionalities, such as heatmaps and control functionalities, increased perceived understanding and benevolence, respectively.
Specifically, 62\% of clinicians positively accepted the \ac{AI} setup, indicating their preference for \ac{AI} recommendations.
These findings emphasize the importance of explainability in enhancing clinicians' understanding and trust in \ac{AI} assistance.

Regarding workflow impact ({\bf RQ5.3}), our results demonstrated that \ac{AI} assistance positively impacts the medical workflow in radiology.
Using \ac{AI} assistance reduced the medical error percentile by 15\% for \acp{FP} and 2\% for \acp{FN}, improving patient classification accuracy.
Diagnostic time was significantly reduced by an average of 50 seconds per patient across different severity levels, indicating enhanced efficiency.
Furthermore, \ac{AI} assistance improved clinician agreement and consistency, reducing inter-variability and intra-variability.
These findings highlight the potential of \ac{AI} assistance to optimize the medical workflow, leading to better patient care and treatment decisions.

\textcolor{revised}{In conclusion, our research explored clinician interactions with \ac{AI} assistance in radiology, focusing on satisfaction, acceptance, understanding, trust, and workflow enhancement.
A human-centered approach facilitated the effective integration of intelligent agents into clinical practice, enhancing user satisfaction and trust in \ac{AI} recommendations.
This integration optimized the medical workflow, improving diagnostic accuracy, reducing time, and increasing consistency, thereby enhancing decision-making reliability and clinician efficiency.}

\section{Discussion}
\label{sec:chap005007}

In this section, we summarize the study's findings, discuss their implications, and identify areas for further investigation.
We contextualize our findings within the existing research landscape, compare them with previous studies, and highlight their practical significance.
We also acknowledge the limitations of the study and propose future directions.
Further discussion are provided in Section~\ref{sec:app003005} of Appendix~\ref{chap:app003}.

\subsection{Findings}
\label{sec:chap005007001}

Interpreting the results in light of existing literature~\cite{10.1145/3411764.3445432} and theoretical frameworks~\cite{10.1145/3311957.3361858} allows us to contextualize our findings within the broader research landscape and theoretical understanding of the topic.
It provides an opportunity to compare and contrast our results with previous studies~\cite{CALISTO2022102285, CALISTO2021102607}, identify areas of alignment or divergence, and discuss the practical significance of our findings.
Additionally, addressing the study's limitations and suggesting areas for further investigation helps to acknowledge the scope of our work and identify avenues for future research (Section~\ref{sec:app003005004}).

Our study examined various elements of clinician interactions with \ac{AI} assistance in radiology.
Using a human-centered approach and design interventions, we successfully integrated intelligent agents into clinical settings.
The research revealed significant results and new insights into the practical advantages of medical \ac{AI} assistance.

Starting with satisfaction and acceptance ({\bf RQ5.1}), our findings highlight the crucial role of integrating \ac{HCI} principles into the design process of \ac{AI} systems.
Through these design interventions, we notably enhanced clinicians' satisfaction and acceptance of the final solution.
Our results align with prior studies~\cite{10.1145/3411764.3445432}, emphasizing the benefits of design interventions and reinforcing the essential role of \ac{HCI} principles in promoting positive \ac{AI} system engagement.
The higher agreement percentages and positive perceptions of usability, ease of use, and workflow integration highlight the effectiveness of design interventions in enhancing clinicians' satisfaction and acceptance of \ac{AI} assistance (Section~\ref{sec:app003005002} of Appendix~\ref{chap:app003}).
By incorporating \ac{HCI} principles like \ac{UCD} and usability testing in \ac{AI} system development, we ensure design interventions align with clinicians' needs, enhancing user satisfaction and acceptance.

In terms of understanding and trust enhancement ({\bf RQ5.2}), our study demonstrated the effectiveness of design techniques in improving clinicians' understanding and trust in \ac{AI} recommendations.
The results align with theoretical frameworks~\cite{10.1145/3311957.3361858} that emphasize the significance of explainability and transparency in fostering trust in \ac{AI} systems.
By incorporating explainability functionalities, such as heatmaps and control functionalities, we observed improvements in clinicians' understanding and perceived benevolence of the \ac{AI} system.
These enhancements contributed to their acceptance and preference for \ac{AI} recommendations.
The findings highlight the importance of incorporating explainability features in \ac{AI} system design to promote understanding and trust among clinicians.

Regarding workflow impact ({\bf RQ5.3}), our results indicated that \ac{AI} assistance positively impacts the medical workflow in radiology (Section~\ref{sec:app003005001} of Appendix~\ref{chap:app003}).
The reduction in \acp{FP} and \acp{FN}, improved accuracy in patient classification, and reduced diagnostic time highlight the potential of \ac{AI} assistance to optimize the medical workflow and enhance patient care.
These findings align with previous studies demonstrating the benefits of \ac{AI} in improving diagnostic accuracy and efficiency in healthcare settings.
The enhanced inter-rater agreement and reduced variability further support the notion that \ac{AI} assistance promotes more consistent and reliable patient classification outcomes.

In this study, we explored how design interventions could guide us in developing an optimal solution for radiology (Section~\ref{sec:app003006}), thereby underscoring the pivotal role of \ac{HCI} principles in designing \ac{AI} systems.
Our findings reveal the transformative potential of design interventions in augmenting decision-making and boosting diagnostic efficiency.
The outcomes underscore the necessity of considering \ac{HCI} principles and optimizing workflow integration when introducing \ac{AI} systems into healthcare environments.
We advocate for embracing \ac{HCI} principles in the design process to develop \ac{AI} systems that cater more effectively to clinicians' needs, ultimately enhancing diagnostic performance.

\subsection{Design Implications}
\label{sec:chap005007002}

Our findings highlight the potential of \ac{AI} assistance to enhance clinicians' decision-making, efficiency, and patient care in radiology.
The effective execution of design interventions and \ac{HCI} principles is crucial for achieving optimal solutions, resulting in enhanced user satisfaction, acceptance, understanding, and trust.
Applying \ac{HCI} principles and strategic design interventions is vital for successful \ac{AI} incorporation in clinical practice.
Enhancing clinicians' satisfaction and acceptance enables more effective utilization of \ac{AI} technologies in healthcare settings.
Design techniques that promote understanding and trust in \ac{AI} recommendations empower clinicians to make informed decisions, leading to better patient care outcomes.
Workflow improvements, including reduced diagnostic time, increased accuracy, and enhanced consistency, have significant implications for clinical practice, potentially improving the efficiency and effectiveness of diagnoses.
Optimizing the medical workflow through \ac{AI} assistance ultimately improves patient outcomes and enhances the overall quality of healthcare delivery.

\vspace{1.00mm}

\noindent
Based on our findings, we propose the following design implications:

\vspace{0.05mm}

\begin{itemize}

\item \textbf{Workflow Understanding and Task-Specific Evaluations}:
Researchers should aim to develop \ac{AI} systems tailored to the specific characteristics of clinical workflows and the straightforward tasks of clinicians.
This understanding is essential for recognizing clinicians' requirements and designing intelligent agents that effectively support their decision-making processes.
When evaluating the performance of \ac{AI} systems, it is vital to consider the high-level workflow actions and diagnostic mechanisms to ensure that the evaluations are task agnostic and provide comprehensive insights.

\vspace{0.025mm}

\item \textbf{Concrete Evidence and Insights}:
Intelligent agents should provide clinicians with concrete empirical evidence and insights, highlighting the consequences or benefits of heeding or disregarding different types of \ac{AI} predictions to mitigate diagnostic errors.
This can help address model ambiguity and build trust in the \ac{AI} system.
Researchers can enhance clinicians' understanding of the system's capabilities and limitations by detailing the areas in the \ac{AI} reasoning where mistakes occur and the potential impact on patients.
Providing transparent explanations and granular insights will empower clinicians to make well-informed decisions based on the \ac{AI} outputs.

\vspace{0.025mm}

\item \textbf{Optimizing Precision and Recall with Uncertainty and Explanations}:
When designing \ac{AI} systems, consider optimizing precision and recall metrics while incorporating model uncertainty and explanations.
By optimizing precision and recall, designers can strike a balance between minimizing \acp{FP} and \acp{FN} in the \ac{AI} outputs.
Additionally, providing clinicians with explanations and insights into model uncertainty and misunderstandings can help them better interpret and utilize the \ac{AI} system's recommendations.
This approach ensures clinicians know potential misunderstandings and can make informed decisions based on the system's outputs.

\end{itemize}

% \vspace{0.05mm}

\textcolor{revised}{These design implications emphasize \ac{HCI} principles in developing \ac{AI} systems for radiology.
By deepening the understanding of clinical workflows, providing tangible evidence, and fine-tuning key metrics like precision and recall, they guide tailored \ac{AI} tool creation.
This is pivotal for successful \ac{AI} integration in clinical settings, as following discussed in our design recommendations (Section~\ref{sec:chap005007003}).
They highlight the significant contributions of the \ac{HCI} community in shaping transparent, user-friendly \ac{AI} systems supportive of clinicians' decision-making, promoting a collaborative human-\acs{AI} relationship.}

\subsection{Design Recommendations}
\label{sec:chap005007003}

\textcolor{revised}{In the context of optimizing workflow integration for \ac{AI} systems in clinical radiology, we propose targeted design recommendations.
These are grounded in \ac{HCI} principles and aim at fostering a cycle of continuous evaluation and improvement.
The focus is developing user-centric \ac{AI} systems tailored for radiology practice, enhancing healthcare quality and efficiency.}

\vspace{1.00mm}

\noindent
\textcolor{revised}{Reflecting on our research findings, we present the following specialized design recommendations for the integration of \ac{AI} assistance in radiology:}

\vspace{0.025mm}

\begin{enumerate}

\item \textcolor{revised}{\textbf{Healthcare Professional-Oriented Usability}:
Prioritize user-centered design principles by involving clinicians in all stages of usability testing.
Include iterative sessions where radiologists interact with \ac{AI} prototypes, giving feedback on interface, responsiveness, and tool integration.
The aim is to develop \ac{AI} systems that seamlessly fit into radiology workflows, addressing clinician needs and boosting satisfaction and acceptance.}

\vspace{0.025mm}

\item \textcolor{revised}{\textbf{Targeted Explainability and Transparency}:
Develop and integrate explainability features for radiological applications, including advanced visualization tools mapping \ac{AI} decisions onto images, and interactive controls for clinicians to query \ac{AI} outputs.
These features aim to enhance clinicians' understanding of \ac{AI} recommendations, fostering transparency and interpretability crucial for informed decision-making.}

\vspace{0.025mm}

\item \textcolor{revised}{\textbf{Workflow-Specific Integration and Enhancement}:
Design \ac{AI} systems attuned to radiology workflows, customizing tools to match typical diagnostic processes.
Optimize compatibility with existing solutions, enhance image processing speed, and improve efficiency to reduce diagnostic time, boosting clinical productivity and patient throughput.}

\vspace{0.05mm}

\item \textcolor{revised}{\textbf{Adaptive Design through Longitudinal Studies}:
Conduct longitudinal studies that involve continuous engagement with radiologists to gather in-depth feedback on the \ac{AI} system's performance in real-world clinical settings.
Use this feedback for iterative design adjustments, allowing the \ac{AI} system to evolve with changing clinical practices and user needs.
This approach guarantees the long-term effectiveness and clinical relevance of \ac{AI} systems in the ever-evolving field of radiology.}

\end{enumerate}

% \vspace{0.05mm}

\textcolor{revised}{Central to these design recommendations is the concept of \textit{healthcare professional-oriented usability}.
This involves designing \ac{AI} systems that are inherently user-friendly for radiologists, facilitating smoother technology interactions.
Additionally, \textit{targeted explainability and transparency} in \ac{AI} decision-making processes are crucial.
This aspect is further explored in Chapter~\ref{chap:chap006}, emphasizing the importance of clear and transparent \ac{AI}-clinician communication.
Moreover, \textit{workflow-specific integration and enhancement} are key, advocating for the seamless incorporation of \ac{AI} into existing clinical workflows, thus augmenting rather than disrupting medical practices.
Lastly, the principle of \textit{adaptive design through longitudinal studies} underscores the necessity of continually evolving \ac{AI} systems to align with the dynamic needs of radiology, informed by ongoing research and clinician feedback.
These guidelines collectively advocate for \ac{AI} tools that are technologically advanced but also relevant and user-friendly, aiming to transform healthcare into a more efficient, precise, and collaborative field.}

\textcolor{revised}{Our design recommendations are key to successfully integrating \ac{AI} in radiology, as detailed in Section~\ref{sec:app003005003} of Chapter~\ref{chap:app003}.
These guidelines aim to enhance user satisfaction, acceptance, understanding, trust, and workflow efficiency, making \ac{AI} intuitive and effective for healthcare professionals.
This approach not only improves \ac{AI}'s reliability in clinical settings but also ensures alignment with healthcare professionals' specific needs and workflows.
By focusing on patient care, these design recommendations aid in accurate diagnoses with personalized strategies and foster collaboration between \ac{AI} systems and medical practitioners (Chapter~\ref{chap:chap006}), addressing the unique challenges of radiology.}

\subsection{Limitations}
\label{sec:chap005007004}

While our study provides valuable insights, it is essential to acknowledge its limitations.
One limitation is the specific focus on radiology, which may limit the generalizability of the findings to other medical domains.
Future research should explore the applicability and effectiveness of design interventions in different medical domains to gain a more comprehensive understanding of the impact of \ac{AI} assistance.

Further investigations should also consider longitudinal studies to examine \ac{AI} assistance's long-term effects and sustainability in clinical practice.
Understanding the evolving dynamics of clinician-\ac{AI} interaction over time and capturing potential challenges or benefits that emerge in the real-world deployment of \ac{AI} assistance would provide valuable insights for successfully integrating \ac{AI} technologies into routine healthcare practice.
Additionally, it is crucial to continue exploring the ethical and social implications of \ac{AI} assistance in radiology and healthcare in general.
This includes examining the impact on the roles and responsibilities of healthcare professionals, trust and acceptance, privacy and security considerations, and the potential biases or disparities that may arise in using \ac{AI} algorithms.

\section{Conclusion}
\label{sec:chap005008}

Integrating \ac{AI} techniques into the clinical workflow, along with design interventions, presents promising opportunities in healthcare.
The effective execution of design interventions and applying \ac{HCI} principles are crucial for achieving optimal solutions, leading to enhanced user satisfaction, acceptance, understanding, and trust.
By interpreting our results in the context of existing literature and theoretical frameworks, we have gained valuable insights into the practical implications of \ac{AI} assistance in radiology, underscoring the significance of incorporating \ac{HCI} principles in designing \ac{AI} systems.
The consolidation of \ac{HCI} principles and strategic design interventions is vital for successfully integrating \ac{AI} into clinical practice, playing a crucial role in achieving optimal solutions and enhancing diagnostic performance.

When considering \ac{HCI} principles such as user-centered design and usability testing, designers can create \ac{AI} systems that effectively address clinicians' needs and preferences, leading to improved user satisfaction and acceptance.
Furthermore, the study demonstrates the effectiveness of design techniques in enhancing clinicians' understanding and trust in \ac{AI} recommendations.
Incorporating explainability functionalities, such as heatmap visualizations and control mechanisms, improve clinicians' understanding of the system's reasoning and fosters trust in \ac{AI} recommendations.
This finding aligns with theoretical frameworks emphasizing transparency and explainability in building trust in \ac{AI} systems.

The workflow impact of \ac{AI} assistance is also evident from the results.
The reduction in \acp{FP} and \acp{FN}, improved accuracy in patient classification, and reduced diagnostic time indicate the potential of \ac{AI} assistance to optimize the medical workflow and enhance patient care.
These findings align with previous research demonstrating the benefits of \ac{AI} in improving diagnostic accuracy and efficiency in healthcare settings.
To optimize workflow integration, ensuring the effective development and implementation of \ac{AI} systems in clinical settings, several design recommendations are proposed.
These recommendations emphasize the importance of usability, explainability, transparency, integration, and continuous evaluation.
By following these recommendations, designers can create user-centric \ac{AI} systems that enhance the overall quality of healthcare delivery.

It is essential to acknowledge the limitations of the study.
The specific focus on radiology may limit the generalizability of the findings to other medical domains.
Future research should explore the applicability and effectiveness of design interventions in different healthcare contexts.
Longitudinal studies are also needed to examine the long-term effects and sustainability of \ac{AI} assistance in clinical practice.

In conclusion, this study highlights the promising opportunities of integrating \ac{AI} techniques into the clinical workflow through design interventions, particularly in radiology.
Our results show that the effective execution of these interventions and applying \ac{HCI} principles are crucial for achieving optimal solutions.
By incorporating \ac{HCI} principles and optimizing workflow integration, \ac{AI} systems can support decision-making and enhance clinicians' efficiency.
The findings provide valuable insights for successfully integrating \ac{AI} technologies into routine healthcare practice.