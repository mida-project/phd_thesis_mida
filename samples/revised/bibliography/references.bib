% Encoding: UTF-8

@article{Tschandl2020,
author={Tschandl, Philipp
and Rinner, Christoph
and Apalla, Zoe
and Argenziano, Giuseppe
and Codella, Noel
and Halpern, Allan
and Janda, Monika
and Lallas, Aimilios
and Longo, Caterina
and Malvehy, Josep
and Paoli, John
and Puig, Susana
and Rosendahl, Cliff
and Soyer, H. Peter
and Zalaudek, Iris
and Kittler, Harald},
title={Human--computer collaboration for skin cancer recognition},
journal={Nature Medicine},
year={2020},
month={Aug},
day={01},
volume={26},
number={8},
pages={1229-1234},
abstract={The rapid increase in telemedicine coupled with recent advances in diagnostic artificial intelligence (AI) create the imperative to consider the opportunities and risks of inserting AI-based support into new paradigms of care. Here we build on recent achievements in the accuracy of image-based AI for skin cancer diagnosis to address the effects of varied representations of AI-based support across different levels of clinical expertise and multiple clinical workflows. We find that good quality AI-based support of clinical decision-making improves diagnostic accuracy over that of either AI or physicians alone, and that the least experienced clinicians gain the most from AI-based support. We further find that AI-based multiclass probabilities outperformed content-based image retrieval (CBIR) representations of AI in the mobile technology environment, and AI-based support had utility in simulations of second opinions and of telemedicine triage. In addition to demonstrating the potential benefits associated with good quality AI in the hands of non-expert clinicians, we find that faulty AI can mislead the entire spectrum of clinicians, including experts. Lastly, we show that insights derived from AI class-activation maps can inform improvements in human diagnosis. Together, our approach and findings offer a framework for future studies across the spectrum of image-based diagnostics to improve human--computer collaboration in clinical practice.},
issn={1546-170X},
doi={10.1038/s41591-020-0942-0},
url={https://doi.org/10.1038/s41591-020-0942-0}
}

@inproceedings{10.1145/3313831.3376290,
author = {Schaekermann, Mike and Cai, Carrie J. and Huang, Abigail E. and Sayres, Rory},
title = {Expert Discussions Improve Comprehension of Difficult Cases in Medical Image Assessment},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376290},
doi = {10.1145/3313831.3376290},
abstract = {Medical data labeling workflows critically depend on accurate assessments from human experts. Yet human assessments can vary markedly, even among medical experts. Prior research has demonstrated benefits of labeler training on performance. Here we utilized two types of labeler training feedback: highlighting incorrect labels for difficult cases ("individual performance" feedback), and expert discussions from adjudication of these cases. We presented ten generalist eye care professionals with either individual performance alone, or individual performance and expert discussions from specialists. Compared to performance feedback alone, seeing expert discussions significantly improved generalists' understanding of the rationale behind the correct diagnosis while motivating changes in their own labeling approach; and also significantly improved average accuracy on one of four pathologies in a held-out test set. This work suggests that image adjudication may provide benefits beyond developing trusted consensus labels, and that exposure to specialist discussions can be an effective training intervention for medical diagnosis.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {labeler training, diagnosis, medical images, adjudication},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{He2019,
author={He, Jianxing
and Baxter, Sally L.
and Xu, Jie
and Xu, Jiming
and Zhou, Xingtao
and Zhang, Kang},
title={The practical implementation of artificial intelligence technologies in medicine},
journal={Nature Medicine},
year={2019},
month={Jan},
day={01},
volume={25},
number={1},
pages={30-36},
abstract={The development of artificial intelligence (AI)-based technologies in medicine is advancing rapidly, but real-world clinical implementation has not yet become a reality. Here we review some of the key practical issues surrounding the implementation of AI into existing clinical workflows, including data sharing and privacy, transparency of algorithms, data standardization, and interoperability across multiple platforms, and concern for patient safety. We summarize the current regulatory environment in the United States and highlight comparisons with other regions in the world, notably Europe and China.},
issn={1546-170X},
doi={10.1038/s41591-018-0307-0},
url={https://doi.org/10.1038/s41591-018-0307-0}
}

@article{McKinney2020,
author={McKinney, Scott Mayer
and Sieniek, Marcin
and Godbole, Varun
and Godwin, Jonathan
and Antropova, Natasha
and Ashrafian, Hutan
and Back, Trevor
and Chesus, Mary
and Corrado, Greg S.
and Darzi, Ara
and Etemadi, Mozziyar
and Garcia-Vicente, Florencia
and Gilbert, Fiona J.
and Halling-Brown, Mark
and Hassabis, Demis
and Jansen, Sunny
and Karthikesalingam, Alan
and Kelly, Christopher J.
and King, Dominic
and Ledsam, Joseph R.
and Melnick, David
and Mostofi, Hormuz
and Peng, Lily
and Reicher, Joshua Jay
and Romera-Paredes, Bernardino
and Sidebottom, Richard
and Suleyman, Mustafa
and Tse, Daniel
and Young, Kenneth C.
and De Fauw, Jeffrey
and Shetty, Shravya},
title={International evaluation of an AI system for breast cancer screening},
journal={Nature},
year={2020},
month={Jan},
day={01},
volume={577},
number={7788},
pages={89-94},
abstract={Screening mammography aims to identify breast cancer at earlier stages of the disease, when treatment can be more successful1. Despite the existence of screening programmes worldwide, the interpretation of mammograms is affected by high rates of false positives and false negatives2. Here we present an artificial intelligence (AI) system that is capable of surpassing human experts in breast cancer prediction. To assess its performance in the clinical setting, we curated a large representative dataset from the UK and a large enriched dataset from the USA. We show an absolute reduction of 5.7{\%} and 1.2{\%} (USA and UK) in false positives and 9.4{\%} and 2.7{\%} in false negatives. We provide evidence of the ability of the system to generalize from the UK to the USA. In an independent study of six radiologists, the AI system outperformed all of the human readers: the area under the receiver operating characteristic curve (AUC-ROC) for the AI system was greater than the AUC-ROC for the average radiologist by an absolute margin of 11.5{\%}. We ran a simulation in which the AI system participated in the double-reading process that is used in the UK, and found that the AI system maintained non-inferior performance and reduced the workload of the second reader by 88{\%}. This robust assessment of the AI system paves the way for clinical trials to improve the accuracy and efficiency of breast cancer screening.},
issn={1476-4687},
doi={10.1038/s41586-019-1799-6},
url={https://doi.org/10.1038/s41586-019-1799-6}
}

@article{Ribli2018,
author={Ribli, Dezs{\H{o}}
and Horv{\'a}th, Anna
and Unger, Zsuzsa
and Pollner, P{\'e}ter
and Csabai, Istv{\'a}n},
title={Detecting and classifying lesions in mammograms with Deep Learning},
journal={Scientific Reports},
year={2018},
month={Mar},
day={15},
volume={8},
number={1},
pages={4165},
abstract={In the last two decades, Computer Aided Detection (CAD) systems were developed to help radiologists analyse screening mammograms, however benefits of current CAD technologies appear to be contradictory, therefore they should be improved to be ultimately considered useful. Since 2012, deep convolutional neural networks (CNN) have been a tremendous success in image recognition, reaching human performance. These methods have greatly surpassed the traditional approaches, which are similar to currently used CAD solutions. Deep CNN-s have the potential to revolutionize medical image analysis. We propose a CAD system based on one of the most successful object detection frameworks, Faster R-CNN. The system detects and classifies malignant or benign lesions on a mammogram without any human intervention. The proposed method sets the state of the art classification performance on the public INbreast database, AUC = 0.95. The approach described here has achieved 2nd place in the Digital Mammography DREAM Challenge with AUC = 0.85. When used as a detector, the system reaches high sensitivity with very few false positive marks per image on the INbreast dataset. Source code, the trained model and an OsiriX plugin are published online at https://github.com/riblidezso/frcnn{\_}cad.},
issn={2045-2322},
doi={10.1038/s41598-018-22437-z},
url={https://doi.org/10.1038/s41598-018-22437-z}
}

@inproceedings{10.1145/3290605.3300233,
author = {Amershi, Saleema and Weld, Dan and Vorvoreanu, Mihaela and Fourney, Adam and Nushi, Besmira and Collisson, Penny and Suh, Jina and Iqbal, Shamsi and Bennett, Paul N. and Inkpen, Kori and Teevan, Jaime and Kikin-Gil, Ruth and Horvitz, Eric},
title = {Guidelines for Human-AI Interaction},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300233},
doi = {10.1145/3290605.3300233},
abstract = {Advances in artificial intelligence (AI) frame opportunities and challenges for user interface design. Principles for human-AI interaction have been discussed in the human-computer interaction community for over two decades, but more study and innovation are needed in light of advances in AI and the growing uses of AI technologies in human-facing applications. We propose 18 generally applicable design guidelines for human-AI interaction. These guidelines are validated through multiple rounds of evaluation including a user study with 49 design practitioners who tested the guidelines against 20 popular AI-infused products. The results verify the relevance of the guidelines over a spectrum of interaction scenarios and reveal gaps in our knowledge, highlighting opportunities for further research. Based on the evaluations, we believe the set of design guidelines can serve as a resource to practitioners working on the design of applications and features that harness AI technologies, and to researchers interested in the further development of human-AI interaction design principles.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {design guidelines, human-ai interaction, ai-infused systems},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{10.1145/3411286,
author = {Thieme, Anja and Cutrell, Ed and Morrison, Cecily and Taylor, Alex and Sellen, Abigail},
title = {Interpretability as a Dynamic of Human-AI Interaction},
year = {2020},
issue_date = {September - October 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {27},
number = {5},
issn = {1072-5520},
url = {https://doi.org/10.1145/3411286},
doi = {10.1145/3411286},
journal = {Interactions},
month = sep,
pages = {40–45},
numpages = {6}
}

@inproceedings{10.1145/3313831.3376301,
author = {Yang, Qian and Steinfeld, Aaron and Ros\'{e}, Carolyn and Zimmerman, John},
title = {Re-Examining Whether, Why, and How Human-AI Interaction Is Uniquely Difficult to Design},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376301},
doi = {10.1145/3313831.3376301},
abstract = {Artificial Intelligence (AI) plays an increasingly important role in improving HCI and user experience. Yet many challenges persist in designing and innovating valuable human-AI interactions. For example, AI systems can make unpredictable errors, and these errors damage UX and even lead to undesired societal impact. However, HCI routinely grapples with complex technologies and mitigates their unintended consequences. What makes AI different? What makes human-AI interaction appear particularly difficult to design? This paper investigates these questions. We synthesize prior research, our own design and research experience, and our observations when teaching human-AI interaction. We identify two sources of AI's distinctive design challenges: 1) uncertainty surrounding AI's capabilities, 2) AI's output complexity, spanning from simple to adaptive complex. We identify four levels of AI systems. On each level, designers encounter a different subset of the design challenges. We demonstrate how these findings reveal new insights for designers, researchers, and design tool makers in productively addressing the challenges of human-AI interaction going forward.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {prototyping, user experience, sketching, artificial intelligence},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376807,
author = {Xie, Yao and Chen, Melody and Kao, David and Gao, Ge and Chen, Xiang 'Anthony'},
title = {CheXplain: Enabling Physicians to Explore and Understand Data-Driven, AI-Enabled Medical Imaging Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376807},
doi = {10.1145/3313831.3376807},
abstract = {The recent development of data-driven AI promises to automate medical diagnosis; however, most AI functions as 'black boxes' to physicians with limited computational knowledge. Using medical imaging as a point of departure, we conducted three iterations of design activities to formulate CheXplain — a system that enables physicians to explore and understand AI-enabled chest X-ray analysis: (i) a paired survey between referring physicians and radiologists reveals whether, when, and what kinds of explanations are needed; (ii) a low-fidelity prototype co-designed with three physicians formulates eight key features; and (iii) a high-fidelity prototype evaluated by another six physicians provides detailed summative insights on how each feature enables the exploration and understanding of AI. We summarize by discussing recommendations for future work to design and implement explainable medical AI systems that encompass four recurring themes: motivation, constraint, explanation, and justification.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–13},
numpages = {13},
keywords = {explainable artificial intelligence, system design, physician-centered design},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@Article{doi:10.1148/radiol.2019182627,
  author   = {Geras, Krzysztof J. and Mann, Ritse M. and Moy, Linda},
  title    = {Artificial Intelligence for Mammography and Digital Breast Tomosynthesis: Current Concepts and Future Perspectives},
  doi      = {10.1148/radiol.2019182627},
  eprint   = {https://doi.org/10.1148/radiol.2019182627},
  note     = {PMID: 31549948},
  number   = {2},
  pages    = {246-259},
  url      = {https://doi.org/10.1148/radiol.2019182627},
  volume   = {293},
  abstract = {Although computer-aided diagnosis (CAD) is widely used in mammography, conventional CAD programs that use prompts to indicate potential cancers on the mammograms have not led to an improvement in diagnostic accuracy. Because of the advances in machine learning, especially with use of deep (multilayered) convolutional neural networks, artificial intelligence has undergone a transformation that has improved the quality of the predictions of the models. Recently, such deep learning algorithms have been applied to mammography and digital breast tomosynthesis (DBT). In this review, the authors explain how deep learning works in the context of mammography and DBT and define the important technical challenges. Subsequently, they discuss the current status and future perspectives of artificial intelligence–based clinical applications for mammography, DBT, and radiomics. Available algorithms are advanced and approach the performance of radiologists—especially for cancer detection and risk prediction at mammography. However, clinical validation is largely lacking, and it is not clear how the power of deep learning should be used to optimize practice. Further development of deep learning models is necessary for DBT, and this requires collection of larger databases. It is expected that deep learning will eventually have an important role in DBT, including the generation of synthetic images.© RSNA, 2019Online supplemental material is available for this article.},
  journal  = {Radiology},
  year     = {2019},
}

@article{doi:10.3322/caac.21492,
author = {Bray, Freddie and Ferlay, Jacques and Soerjomataram, Isabelle and Siegel, Rebecca L. and Torre, Lindsey A. and Jemal, Ahmedin},
title = {Global cancer statistics 2018: GLOBOCAN estimates of incidence and mortality worldwide for 36 cancers in 185 countries},
journal = {CA: A Cancer Journal for Clinicians},
volume = {68},
number = {6},
pages = {394-424},
keywords = {cancer, epidemiology, incidence, survival},
doi = {10.3322/caac.21492},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.3322/caac.21492},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21492},
abstract = {Abstract This article provides a status report on the global burden of cancer worldwide using the GLOBOCAN 2018 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer, with a focus on geographic variability across 20 world regions. There will be an estimated 18.1 million new cancer cases (17.0 million excluding nonmelanoma skin cancer) and 9.6 million cancer deaths (9.5 million excluding nonmelanoma skin cancer) in 2018. In both sexes combined, lung cancer is the most commonly diagnosed cancer (11.6\% of the total cases) and the leading cause of cancer death (18.4\% of the total cancer deaths), closely followed by female breast cancer (11.6\%), prostate cancer (7.1\%), and colorectal cancer (6.1\%) for incidence and colorectal cancer (9.2\%), stomach cancer (8.2\%), and liver cancer (8.2\%) for mortality. Lung cancer is the most frequent cancer and the leading cause of cancer death among males, followed by prostate and colorectal cancer (for incidence) and liver and stomach cancer (for mortality). Among females, breast cancer is the most commonly diagnosed cancer and the leading cause of cancer death, followed by colorectal and lung cancer (for incidence), and vice versa (for mortality); cervical cancer ranks fourth for both incidence and mortality. The most frequently diagnosed cancer and the leading cause of cancer death, however, substantially vary across countries and within each country depending on the degree of economic development and associated social and life style factors. It is noteworthy that high-quality cancer registry data, the basis for planning and implementing evidence-based cancer control programs, are not available in most low- and middle-income countries. The Global Initiative for Cancer Registry Development is an international partnership that supports better estimation, as well as the collection and use of local data, to prioritize and evaluate national cancer control efforts. CA: A Cancer Journal for Clinicians 2018;0:1-31. © 2018 American Cancer Society},
year = {2018}
}

@article{doi:10.1002/cncr.32859,
author = {Duffy, Stephen W. and Tabár, László and Yen, Amy Ming-Fang and Dean, Peter B. and Smith, Robert A. and Jonsson, Håkan and Törnberg, Sven and Chen, Sam Li-Sheng and Chiu, Sherry Yueh-Hsia and Fann, Jean Ching-Yuan and Ku, May Mei-Sheng and Wu, Wendy Yi-Ying and Hsu, Chen-Yang and Chen, Yu-Ching and Svane, Gunilla and Azavedo, Edward and Grundström, Helene and Sundén, Per and Leifland, Karin and Frodis, Ewa and Ramos, Joakim and Epstein, Birgitta and Åkerlund, Anders and Sundbom, Ann and Bordás, Pál and Wallin, Hans and Starck, Leena and Björkgren, Annika and Carlson, Stina and Fredriksson, Irma and Ahlgren, Johan and Öhman, Daniel and Holmberg, Lars and Chen, Tony Hsiu-Hsi},
title = {Mammography screening reduces rates of advanced and fatal breast cancers: Results in 549,091 women},
journal = {Cancer},
volume = {126},
number = {13},
pages = {2971-2979},
keywords = {breast cancer, fatality, mammography, mortality, screening},
doi = {10.1002/cncr.32859},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.1002/cncr.32859},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.1002/cncr.32859},
abstract = {Background It is of paramount importance to evaluate the impact of participation in organized mammography service screening independently from changes in breast cancer treatment. This can be done by measuring the incidence of fatal breast cancer, which is based on the date of diagnosis and not on the date of death. Methods Among 549,091 women, covering approximately 30\% of the Swedish screening-eligible population, the authors calculated the incidence rates of 2473 breast cancers that were fatal within 10 years after diagnosis and the incidence rates of 9737 advanced breast cancers. Data regarding each breast cancer diagnosis and the cause and date of death of each breast cancer case were gathered from national Swedish registries. Tumor characteristics were collected from regional cancer centers. Aggregated data concerning invitation and participation were provided by Sectra Medical Systems AB. Incidence rates were analyzed using Poisson regression. Results Women who participated in mammography screening had a statistically significant 41\% reduction in their risk of dying of breast cancer within 10 years (relative risk, 0.59; 95\% CI, 0.51-0.68 [P < .001]) and a 25\% reduction in the rate of advanced breast cancers (relative risk, 0.75; 95\% CI, 0.66-0.84 [P < .001]). Conclusions Substantial reductions in the incidence rate of breast cancers that were fatal within 10 years after diagnosis and in the advanced breast cancer rate were found in this contemporaneous comparison of women participating versus those not participating in screening. These benefits appeared to be independent of recent changes in treatment regimens.},
year = {2020}
}

@article{10.1093/jnci/djaa080,
    author = {Farber, Rachel and Houssami, Nehmat and Wortley, Sally and Jacklyn, Gemma and Marinovich, Michael L and McGeechan, Kevin and Barratt, Alexandra and Bell, Katy},
    title = "{Impact of Full-Field Digital Mammography Versus Film-Screen Mammography in Population Screening: A Meta-Analysis}",
    journal = {JNCI: Journal of the National Cancer Institute},
    year = {2020},
    month = {06},
    abstract = "{Breast screening programs replaced film mammography with digital mammography, and the effects of this practice shift in population screening on health outcomes can be measured through examination of cancer detection and interval cancer rates.A systematic review and random effects meta-analysis were undertaken. Seven databases were searched for publications that compared film with digital mammography within the same population of asymptomatic women and reported cancer detection and/or interval cancer rates.The analysis included 24 studies with 16 583 743 screening examinations (10 968 843 film and 5 614 900 digital). The pooled difference in the cancer detection rate showed an increase of 0.51 per 1000 screens (95\% confidence interval [CI] = 0.19 to 0.83), greater relative increase for ductal carcinoma in situ (25.2\%, 95\% CI = 17.4\% to 33.5\%) than invasive (4\%, 95\% CI = −3\% to 13\%), and a recall rate increase of 6.95 (95\% CI = 3.47 to 10.42) per 1000 screens after the transition from film to digital mammography. Seven studies (80.8\% of screens) reported interval cancers: the pooled difference showed no change in the interval cancer rate with −0.02 per 1000 screens (95\% CI = −0.06 to 0.03). Restricting analysis to studies at low risk of bias resulted in findings consistent with the overall pooled results for all outcomes.The increase in cancer detection following the practice shift to digital mammography did not translate into a reduction in the interval cancer rate. Recall rates were increased. These results suggest the transition from film to digital mammography did not result in health benefits for screened women. This analysis reinforces the need to carefully evaluate effects of future changes in technology, such as tomosynthesis, to ensure new technology leads to improved health outcomes and beyond technical gains.}",
    issn = {0027-8874},
    doi = {10.1093/jnci/djaa080},
    url = {https://doi.org/10.1093/jnci/djaa080},
    note = {djaa080},
    eprint = {https://academic.oup.com/jnci/advance-article-pdf/doi/10.1093/jnci/djaa080/33801195/djaa080.pdf},
}

@article{Seely2018,
author={Seely, J. M.
and Alhassan, T.},
title={Screening for breast cancer in 2018-what should we be doing today?},
journal={Current oncology (Toronto, Ont.)},
year={2018},
month={Jun},
edition={2018/06/13},
publisher={Multimed Inc.},
volume={25},
number={Suppl 1},
pages={S115-S124},
keywords={*Breast cancer; *digital breast tomosynthesis; *overdiagnosis; *screening mammography; Biopsy; Breast Neoplasms/*diagnosis/epidemiology/pathology; *Early Detection of Cancer/history/methods/trends; False Positive Reactions; Female; History, 21st Century; Humans; Magnetic Resonance Imaging; Mammography; Mass Screening/history/methods/trends; Medical Oncology/history/methods/trends; Ultrasonography, Mammary},
abstract={Although screening mammography has delivered many benefits since its introduction in Canada in 1988, questions about perceived harms warrant an up-to-date review. To help oncologists and physicians provide optimal patient recommendations, the literature was reviewed to find the latest guidelines for screening mammography, including benefits and perceived harms of overdiagnosis, false positives, false negatives, and technologic advances. For women 40-74 years of age who actually participate in screening every 1-2 years, breast cancer mortality is reduced by 40{\%}. With appropriate corrections, overdiagnosis accounts for 10{\%} or fewer breast cancers. False positives occur in about 10{\%} of screened women, 80{\%} of which are resolved with additional imaging, and 10{\%}, with breast biopsy. An important limitation of screening is the false negatives (15{\%}-20{\%}). The technologic advances of digital breast tomosynthesis, breast ultrasonography, and magnetic resonance imaging counter the false negatives of screening mammography, particularly in women with dense breast tissue.},
issn={1718-7729},
doi={10.3747/co.25.3770},
url={https://doi.org/10.3747/co.25.3770},
language={eng}
}

@article{Oeffinger2015,
author={Oeffinger, Kevin C.
and Fontham, Elizabeth T. H.
and Etzioni, Ruth
and Herzig, Abbe
and Michaelson, James S.
and Shih, Ya-Chen Tina
and Walter, Louise C.
and Church, Timothy R.
and Flowers, Christopher R.
and LaMonte, Samuel J.
and Wolf, Andrew M. D.
and DeSantis, Carol
and Lortet-Tieulent, Joannie
and Andrews, Kimberly
and Manassaram-Baptiste, Deana
and Saslow, Debbie
and Smith, Robert A.
and Brawley, Otis W.
and Wender, Richard
and Society, American Cancer},
title={Breast Cancer Screening for Women at Average Risk: 2015 Guideline Update From the American Cancer Society},
journal={JAMA},
year={2015},
month={Oct},
day={20},
volume={314},
number={15},
pages={1599-1614},
keywords={Adult; Age Factors; Breast Neoplasms/*diagnostic imaging/mortality; Early Detection of Cancer; Evidence-Based Medicine; Female; Health Status; Humans; Life Expectancy; Mammography/*standards; Middle Aged; Review Literature as Topic; Risk; Ultrasonography},
abstract={IMPORTANCE: Breast cancer is a leading cause of premature mortality among US women. Early detection has been shown to be associated with reduced breast cancer morbidity and mortality. OBJECTIVE: To update the American Cancer Society (ACS) 2003 breast cancer screening guideline for women at average risk for breast cancer. PROCESS: The ACS commissioned a systematic evidence review of the breast cancer screening literature to inform the update and a supplemental analysis of mammography registry data to address questions related to the screening interval. Formulation of recommendations was based on the quality of the evidence and judgment (incorporating values and preferences) about the balance of benefits and harms. EVIDENCE SYNTHESIS: Screening mammography in women aged 40 to 69 years is associated with a reduction in breast cancer deaths across a range of study designs, and inferential evidence supports breast cancer screening for women 70 years and older who are in good health. Estimates of the cumulative lifetime risk of false-positive examination results are greater if screening begins at younger ages because of the greater number of mammograms, as well as the higher recall rate in younger women. The quality of the evidence for overdiagnosis is not sufficient to estimate a lifetime risk with confidence. Analysis examining the screening interval demonstrates more favorable tumor characteristics when premenopausal women are screened annually vs biennially. Evidence does not support routine clinical breast examination as a screening method for women at average risk. RECOMMENDATIONS: The ACS recommends that women with an average risk of breast cancer should undergo regular screening mammography starting at age 45 years (strong recommendation). Women aged 45 to 54 years should be screened annually (qualified recommendation). Women 55 years and older should transition to biennial screening or have the opportunity to continue screening annually (qualified recommendation). Women should have the opportunity to begin annual screening between the ages of 40 and 44 years (qualified recommendation). Women should continue screening mammography as long as their overall health is good and they have a life expectancy of 10 years or longer (qualified recommendation). The ACS does not recommend clinical breast examination for breast cancer screening among average-risk women at any age (qualified recommendation). CONCLUSIONS AND RELEVANCE: These updated ACS guidelines provide evidence-based recommendations for breast cancer screening for women at average risk of breast cancer. These recommendations should be considered by physicians and women in discussions about breast cancer screening.},
note={26501536[pmid]},
issn={1538-3598},
doi={10.1001/jama.2015.12783},
url={https://doi.org/10.1001/jama.2015.12783},
language={eng}
}

@article{Dafni2019,
author={Dafni, U.
and Tsourti, Z.
and Alatsathianos, I.},
title={Breast Cancer Statistics in the European Union: Incidence and Survival across European Countries},
journal={Breast Care},
year={2019},
volume={14},
number={6},
pages={344-353},
abstract={The current status and time trends in breast cancer incidence and survival in the 28 European Union countries (EU-28) is presented here. Rates reported are age adjusted and standardized (ASR). A high incidence and high survival rates were observed in the Northern and Western European countries, with the exception of the Baltic countries. The higher incidence is partly attributed to the higher prevalence of lifestyle risk factors, while the higher survival is attributed to better access to beneficial treatments and general health care. Most of the countries in Southern Europe or the former Eastern Bloc have not yet reached the high GDP per capita status (2017 purchasing power parity; PPP) of the earlier established Western democracies. The breast cancer incidence and survival are associated with the PPP level (both higher for the higher PPP category; 2017 PPP above USD 40,000). Overall, a trend toward higher survival rates was observed throughout this first period of the 21st century, with the incidence for most countries either stabilizing at the 2010 levels or decreasing further.},
issn={1661-3791},
doi={10.1159/000503219},
url={https://doi.org/10.1159/000503219}
}

@article{KIM2020e138,
title = "Changes in cancer detection and false-positive recall in mammography using artificial intelligence: a retrospective, multireader study",
journal = "The Lancet Digital Health",
volume = "2",
number = "3",
pages = "e138 - e148",
year = "2020",
issn = "2589-7500",
doi = "https://doi.org/10.1016/S2589-7500(20)30003-0",
url = "http://www.sciencedirect.com/science/article/pii/S2589750020300030",
author = "Hyo-Eun Kim and Hak Hee Kim and Boo-Kyung Han and Ki Hwan Kim and Kyunghwa Han and Hyeonseob Nam and Eun Hye Lee and Eun-Kyung Kim",
abstract = "Summary
Background
Mammography is the current standard for breast cancer screening. This study aimed to develop an artificial intelligence (AI) algorithm for diagnosis of breast cancer in mammography, and explore whether it could benefit radiologists by improving accuracy of diagnosis.
Methods
In this retrospective study, an AI algorithm was developed and validated with 170 230 mammography examinations collected from five institutions in South Korea, the USA, and the UK, including 36 468 cancer positive confirmed by biopsy, 59 544 benign confirmed by biopsy (8827 mammograms) or follow-up imaging (50 717 mammograms), and 74 218 normal. For the multicentre, observer-blinded, reader study, 320 mammograms (160 cancer positive, 64 benign, 96 normal) were independently obtained from two institutions. 14 radiologists participated as readers and assessed each mammogram in terms of likelihood of malignancy (LOM), location of malignancy, and necessity to recall the patient, first without and then with assistance of the AI algorithm. The performance of AI and radiologists was evaluated in terms of LOM-based area under the receiver operating characteristic curve (AUROC) and recall-based sensitivity and specificity.
Findings
The AI standalone performance was AUROC 0·959 (95% CI 0·952–0·966) overall, and 0·970 (0·963–0·978) in the South Korea dataset, 0·953 (0·938–0·968) in the USA dataset, and 0·938 (0·918–0·958) in the UK dataset. In the reader study, the performance level of AI was 0·940 (0·915–0·965), significantly higher than that of the radiologists without AI assistance (0·810, 95% CI 0·770–0·850; p<0·0001). With the assistance of AI, radiologists' performance was improved to 0·881 (0·850–0·911; p<0·0001). AI was more sensitive to detect cancers with mass (53 [90%] vs 46 [78%] of 59 cancers detected; p=0·044) or distortion or asymmetry (18 [90%] vs ten [50%] of 20 cancers detected; p=0·023) than radiologists. AI was better in detection of T1 cancers (73 [91%] vs 59 [74%] of 80; p=0·0039) or node-negative cancers (104 [87%] vs 88 [74%] of 119; p=0·0025) than radiologists.
Interpretation
The AI algorithm developed with large-scale mammography data showed better diagnostic performance in breast cancer detection compared with radiologists. The significant improvement in radiologists' performance when aided by AI supports application of AI to mammograms as a diagnostic support tool.
Funding
Lunit."
}

@article{10.1001/jamainternmed.2015.5231,
    author = {Lehman, Constance D. and Wellman, Robert D. and Buist, Diana S. M. and Kerlikowske, Karla and Tosteson, Anna N. A. and Miglioretti, Diana L. and for the Breast Cancer Surveillance Consortium},
    title = "{Diagnostic Accuracy of Digital Screening Mammography With and Without Computer-Aided Detection}",
    journal = {JAMA Internal Medicine},
    volume = {175},
    number = {11},
    pages = {1828-1837},
    year = {2015},
    month = {11},
    abstract = "{After the US Food and Drug Administration (FDA) approved computer-aided detection (CAD) for mammography in 1998, and the Centers for Medicare and Medicaid Services (CMS) provided increased payment in 2002, CAD technology disseminated rapidly. Despite sparse evidence that CAD improves accuracy of mammographic interpretations and costs over \\$400 million a year, CAD is currently used for most screening mammograms in the United States.To measure performance of digital screening mammography with and without CAD in US community practice.We compared the accuracy of digital screening mammography interpreted with (n = 495 818) vs without (n = 129 807) CAD from 2003 through 2009 in 323 973 women. Mammograms were interpreted by 271 radiologists from 66 facilities in the Breast Cancer Surveillance Consortium. Linkage with tumor registries identified 3159 breast cancers in 323 973 women within 1 year of the screening.Mammography performance (sensitivity, specificity, and screen-detected and interval cancers per 1000 women) was modeled using logistic regression with radiologist-specific random effects to account for correlation among examinations interpreted by the same radiologist, adjusting for patient age, race/ethnicity, time since prior mammogram, examination year, and registry. Conditional logistic regression was used to compare performance among 107 radiologists who interpreted mammograms both with and without CAD.Screening performance was not improved with CAD on any metric assessed. Mammography sensitivity was 85.3\\% (95\\% CI, 83.6\\%-86.9\\%) with and 87.3\\% (95\\% CI, 84.5\\%-89.7\\%) without CAD. Specificity was 91.6\\% (95\\% CI, 91.0\\%-92.2\\%) with and 91.4\\% (95\\% CI, 90.6\\%-92.0\\%) without CAD. There was no difference in cancer detection rate (4.1 in 1000 women screened with and without CAD). Computer-aided detection did not improve intraradiologist performance. Sensitivity was significantly decreased for mammograms interpreted with vs without CAD in the subset of radiologists who interpreted both with and without CAD (odds ratio, 0.53; 95\\% CI, 0.29-0.97).Computer-aided detection does not improve diagnostic accuracy of mammography. These results suggest that insurers pay more for CAD with no established benefit to women.}",
    issn = {2168-6106},
    doi = {10.1001/jamainternmed.2015.5231},
    url = {https://doi.org/10.1001/jamainternmed.2015.5231},
    eprint = {https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/2443369/ioi150084.pdf},
}

@article{10.1001/jamainternmed.2014.981,
    author = {Tosteson, Anna N. A. and Fryback, Dennis G. and Hammond, Cristina S. and Hanna, Lucy G. and Grove, Margaret R. and Brown, Mary and Wang, Qianfei and Lindfors, Karen and Pisano, Etta D.},
    title = "{Consequences of False-Positive Screening Mammograms}",
    journal = {JAMA Internal Medicine},
    volume = {174},
    number = {6},
    pages = {954-961},
    year = {2014},
    month = {06},
    abstract = "{False-positive mammograms, a common occurrence in breast cancer screening programs, represent a potential screening harm that is currently being evaluated by the US Preventive Services Task Force.To measure the effect of false-positive mammograms on quality of life by measuring personal anxiety, health utility, and attitudes toward future screening.The Digital Mammographic Imaging Screening Trial (DMIST) quality-of-life substudy telephone survey was performed shortly after screening and 1 year later at 22 DMIST sites and included randomly selected DMIST participants with positive and negative mammograms.Mammogram requiring follow-up testing or referral without a cancer diagnosis.The 6-question short form of the Spielberger State-Trait Anxiety Inventory state scale (STAI-6) and the EuroQol EQ-5D instrument with US scoring. Attitudes toward future screening as measured by women’s self-report of future intention to undergo mammographic screening and willingness to travel and stay overnight to undergo a hypothetical new type of mammography that would identify as many cancers with half the false-positive results.Among 1450 eligible women invited to participate, 1226 (84.6\\%) were enrolled, with follow-up interviews obtained in 1028 (83.8\\%). Anxiety was significantly higher for women with false-positive mammograms (STAI-6, 35.2 vs 32.7), but health utility scores did not differ and there were no significant differences between groups at 1 year. Future screening intentions differed by group (25.7\\% vs 14.2\\% more likely in false-positive vs negative groups); willingness to travel and stay overnight did not (9.9\\% vs 10.5\\% in false-positive vs negative groups). Future screening intention was significantly increased among women with false-positive mammograms (odds ratio, 2.12; 95\\% CI, 1.54-2.93), younger age (2.78; 1.5-5.0), and poorer health (1.63; 1.09-2.43). Women’s anticipated high-level anxiety regarding future false-positive mammograms was associated with willingness to travel overnight (odds ratio, 1.94; 95\\% CI, 1.28-2.95).False-positive mammograms were associated with increased short-term anxiety but not long-term anxiety, and there was no measurable health utility decrement. False-positive mammograms increased women’s intention to undergo future breast cancer screening and did not increase their stated willingness to travel to avoid a false-positive result. Our finding of time-limited harm after false-positive screening mammograms is relevant for clinicians who counsel women on mammographic screening and for screening guideline development groups.}",
    issn = {2168-6106},
    doi = {10.1001/jamainternmed.2014.981},
    url = {https://doi.org/10.1001/jamainternmed.2014.981},
    eprint = {https://jamanetwork.com/journals/jamainternalmedicine/articlepdf/1861037/ioi140027.pdf},
}

@article{Houssami2017,
author={Houssami, Nehmat
and Hunter, Kylie},
title={The epidemiology, radiology and biological characteristics of interval breast cancers in population mammography screening},
journal={npj Breast Cancer},
year={2017},
month={Apr},
day={13},
volume={3},
number={1},
pages={12},
abstract={An interval breast cancer is a cancer that emerges following a negative mammographic screen. This overview describes the epidemiology, and the radiological and biological characteristics of interval breast cancers in population mammography screening. Notwithstanding possible differences in ascertainment of interval breast cancers, there was broad variability in reported interval breast cancer rates (range 7.0 to 49.3 per 10,000 screens) reflecting heterogeneity in underlying breast cancer rates, screening rounds (initial or repeat screens), and the length and phase of the inter-screening interval. The majority of studies (based on biennial screening) reported interval breast cancer rates in the range of 8.4 to 21.1 per 10,000 screens spanning the two-year interval with the larger proportion occurring in the second year. Despite methodological limitations inherent in radiological surveillance (retrospective mammographic review) of interval breast cancers, this form of surveillance consistently reveals that the majority of interval cancers represent either true interval or occult cancers that were not visible on the index mammographic screen; approximately 20--25{\%} of interval breast cancers are classified as having been missed (false-negatives). The biological characteristics of interval breast cancers show that they have relatively worse tumour prognostic characteristics and biomarker profile, and also survival outcomes, than screen-detected breast cancers; however, they have similar characteristics and prognosis as breast cancers occurring in non-screened women. There was limited evidence on the effect on interval breast cancer frequency and outcomes following transition from film to digital mammography screening.},
issn={2374-4677},
doi={10.1038/s41523-017-0014-x},
url={https://doi.org/10.1038/s41523-017-0014-x}
}

@Article{doi:10.1056/NEJMe1912943,
  author  = {Longo, Dan L.},
  title   = {Detecting Breast Cancer in Women with Dense Breasts},
  doi     = {10.1056/NEJMe1912943},
  eprint  = {https://doi.org/10.1056/NEJMe1912943},
  note    = {PMID: 31774964},
  number  = {22},
  pages   = {2169-2170},
  url     = {https://doi.org/10.1056/NEJMe1912943},
  volume  = {381},
  journal = {New England Journal of Medicine},
  year    = {2019},
}

@article{Topol2019,
author={Topol, Eric J.},
title={High-performance medicine: the convergence of human and artificial intelligence},
journal={Nature Medicine},
year={2019},
month={Jan},
day={01},
volume={25},
number={1},
pages={44-56},
abstract={The use of artificial intelligence, and the deep-learning subtype in particular, has been enabled by the use of labeled big data, along with markedly enhanced computing power and cloud storage, across all sectors. In medicine, this is beginning to have an impact at three levels: for clinicians, predominantly via rapid, accurate image interpretation; for health systems, by improving workflow and the potential for reducing medical errors; and for patients, by enabling them to process their own data to promote health. The current limitations, including bias, privacy and security, and lack of transparency, along with the future directions of these applications will be discussed in this article. Over time, marked improvements in accuracy, productivity, and workflow will likely be actualized, but whether that will be used to improve the patient--doctor relationship or facilitate its erosion remains to be seen.},
issn={1546-170X},
doi={10.1038/s41591-018-0300-7},
url={https://doi.org/10.1038/s41591-018-0300-7}
}

@article{rimmer2017radiologist,
  title={Radiologist shortage leaves patient care at risk, warns royal college},
  author={Rimmer, Abi},
  journal={BMJ: British Medical Journal (Online)},
  volume={359},
  year={2017},
  publisher={BMJ Publishing Group LTD}
}

@INPROCEEDINGS{9098470,
  author={G. {Maicas} and C. {Nguyen} and F. {Motlagh} and J. C. {Nascimento} and G. {Carneiro}},
  booktitle={2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI)}, 
  title={Unsupervised Task Design to Meta-Train Medical Image Classifiers}, 
  year={2020},
  number={9098470},
  series="1945-8452",
  pages={1339-1342},
  doi={10.1109/ISBI45749.2020.9098470}
}

@techreport{hugo2020si,
  doi = {10.13140/RG.2.2.35800.24329/5},
  url = {http://rgdoi.net/10.13140/RG.2.2.35800.24329/5},
  author = {Lencastre,  Hugo},
  title = {Master Project: Breast Cancer Multimodality Scalable Interactions},
  institution = {Instituto Superior T\'{e}cnico},
  year = {2020},
  address = {Avenida Rovisco Pais 1, 1049-001 Lisboa - Portugal (EU)},
  month = {1},
  publisher = {ResearchGate},
  note = {Improving a framework with novel interactive techniques which enhances the diagnostic process.}
}

@InProceedings{Yue_2020_CVPR,
author = {Yue, Huanjing and Cao, Cong and Liao, Lei and Chu, Ronghe and Yang, Jingyu},
title = {Supervised Raw Video Denoising With a Benchmark Dataset on Dynamic Scenes},
booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2020}
}

@InProceedings{Huang_2017_CVPR,
author = {Huang, Gao and Liu, Zhuang and van der Maaten, Laurens and Weinberger, Kilian Q.},
title = {Densely Connected Convolutional Networks},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {July},
year = {2017}
}

@InProceedings{He_2016_CVPR,
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
title = {Deep Residual Learning for Image Recognition},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@inproceedings{10.1117/12.2549103,
author = {Tomoki Uemura and Janne J. Näppi and Toru Hironaka and Hyoungseop Kim and Hiroyuki Yoshida},
title = {{Comparative performance of 3D-DenseNet, 3D-ResNet, and 3D-VGG models in polyp detection for CT colonography}},
volume = {11314},
booktitle = {Medical Imaging 2020: Computer-Aided Diagnosis},
editor = {Horst K. Hahn and Maciej A. Mazurowski},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {736 -- 741},
keywords = {3D-DenseNet, Deep Learning, CT Colonography, Colorectal Cancer},
year = {2020},
doi = {10.1117/12.2549103},
URL = {https://doi.org/10.1117/12.2549103}
}

@ARTICLE{8515234,
  author={J. {Dolz} and K. {Gopinath} and J. {Yuan} and H. {Lombaert} and C. {Desrosiers} and I. {Ben Ayed}},
  journal={IEEE Transactions on Medical Imaging}, 
  title={HyperDense-Net: A Hyper-Densely Connected CNN for Multi-Modal Image Segmentation}, 
  year={2019},
  volume={38},
  number={5},
  pages={1116-1126},
  doi={10.1109/TMI.2018.2878669}}

@InProceedings{10.1007/978-3-030-46640-4_23,
author="Cheng, Xinchao
and Jiang, Zongkang
and Sun, Qiule
and Zhang, Jianxin",
editor="Crimi, Alessandro
and Bakas, Spyridon",
title="Memory-Efficient Cascade 3D U-Net for Brain Tumor Segmentation",
booktitle="Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain Injuries",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="242--253",
abstract="Segmentation is a routine and crucial procedure for the treatment of brain tumors. Deep learning based brain tumor segmentation methods have achieved promising performance in recent years. However, to pursue high segmentation accuracy, most of them require too much memory and computation resources. Motivated by a recently proposed partially reversible U-Net architecture that pays more attention to memory footprint, we further present a novel Memory-Efficient Cascade 3D U-Net (MECU-Net) for brain tumor segmentation in this work, which can achieve comparable segmentation accuracy with less memory and computation consumption. More specifically, MECU-Net utilizes fewer down-sampling channels to reduce the utilization of memory and computation resources. To make up the accuracy loss, MECU-Net employs multi-scale feature fusion module to enhance the feature representation capability. Additionally, a light-weight cascade model, which resolves the problem of small target segmentation accuracy caused by model compression to some extent, is further introduced into the segmentation network. Finally, edge loss and weighted dice loss are combined to refine the brain tumor segmentation results. Experiment results on BraTS 2019 validation set illuminate that MECU-Net can achieve average Dice coefficients of 0.902, 0.824 and 0.777 on the whole tumor, tumor core and enhancing tumor, respectively.",
isbn="978-3-030-46640-4"
}

@inproceedings{Kocielnik:2019:YAI:3290605.3300641,
 author = {Kocielnik, Rafal and Amershi, Saleema and Bennett, Paul N.},
 title = {Will You Accept an Imperfect AI?: Exploring Designs for Adjusting End-user Expectations of AI Systems},
 booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '19},
 year = {2019},
 isbn = {978-1-4503-5970-2},
 location = {Glasgow, Scotland Uk},
 pages = {411:1--411:14},
 articleno = {411},
 numpages = {14},
 url = {http://doi.acm.org/10.1145/3290605.3300641},
 doi = {10.1145/3290605.3300641},
 acmid = {3300641},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {ai infused systems, ai system on-boarding, perception and acceptance of ai, shaping ai expectations},
}

@article{DALILA2017749,
title = "Segmentation and classification of melanoma and benign skin lesions",
journal = "Optik",
volume = "140",
pages = "749 - 761",
year = "2017",
issn = "0030-4026",
doi = "https://doi.org/10.1016/j.ijleo.2017.04.084",
url = "http://www.sciencedirect.com/science/article/pii/S0030402617304886",
author = "Fekrache Dalila and Ameur Zohra and Kasmi Reda and Cherifi Hocine",
keywords = "Computer-aided diagnosis, Melanoma, Segmentation, Ant colony, Feature extraction, Dermoscopy, K-Nearest Neighbor, Neural network",
abstract = "The incidence ofmalignant melanoma has been increasing worldwide. An efficient non-invasive computer-aided diagnosis (CAD) is seen as a solution to make identification process faster, and accessible to a large population. Such automated system relies on three things: reliable lesion segmentation, pertinent features’ extraction and good lesion classifier. In this paper, we propose an automated system that uses an Ant colony based segmentation algorithm, takes into consideration three types of features to describe malignant lesion:geometrical properties, textureand relative colors from which pertinent ones are selected, and uses two classifiers K-Nearest Neighbor (KNN) and Artificial Neural Network (ANN). The objective of this paper is to test the efficiency of the proposed segmentation algorithm, extract most pertinent features that describe melanomas and compare the two classifiers. Our automated system is tested on 172 dermoscopic images where 88 are malignant melanomas and 84 benign lesions. The results of the proposed segmentation algorithm are encouraging as they gave promising results. 12 features seem to be sufficient to detect malignant melanoma. Moreover, ANN gives better results than KNN."
}

@inproceedings{pacheco2019alignment,
  title={Alignment of Player and Non-Player Character Assertiveness Levels},
  author={Pacheco, Ant{\'o}nio C and Martinho, Carlos},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment},
  volume={15},
  pages={181--187},
  year={2019},
  publisher={AAAI},
  location={Georgia Institute of Technology, Atlanta, Georgia, USA}
}

@inproceedings{10.1145/3311350.3347162,
author = {Paradeda, Raul and Ferreira, Maria Jos\'{e} and Oliveira, Raquel and Martinho, Carlos and Paiva, Ana},
title = {The Role of Assertiveness in a Storytelling Game with Persuasive Robotic Non-Player Characters},
year = {2019},
isbn = {9781450366885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311350.3347162},
doi = {10.1145/3311350.3347162},
booktitle = {Proceedings of the Annual Symposium on Computer-Human Interaction in Play},
pages = {453–465},
numpages = {13},
keywords = {interactive digital storytelling, assertiveness, persuasion, personality trait, social robotics, non-player character},
location = {Barcelona, Spain},
series = {CHI PLAY ’19}
}

@article{Lambin2017,
author={Lambin, Philippe
and Leijenaar, Ralph T.H.
and Deist, Timo M.
and Peerlings, Jurgen
and de Jong, Evelyn E.C.
and van Timmeren, Janita
and Sanduleanu, Sebastian
and Larue, Ruben T.H.M.
and Even, Aniek J.G.
and Jochems, Arthur
and van Wijk, Yvonka
and Woodruff, Henry
and van Soest, Johan
and Lustberg, Tim
and Roelofs, Erik
and van Elmpt, Wouter
and Dekker, Andre
and Mottaghy, Felix M.
and Wildberger, Joachim E.
and Walsh, Sean},
title={Radiomics: the bridge between medical imaging and personalized medicine},
journal={Nature Reviews Clinical Oncology},
year={2017},
month={Dec},
day={01},
volume={14},
number={12},
pages={749-762},
abstract={Radiomics is becoming increasingly more important in medical imagingThe explosion of medical imaging data creates an environment ideal for machine-learning and data-based scienceRadiomics-based decision-support systems for precision diagnosis and treatment can be a powerful tool in modern medicineLarge-scale data sharing is necessary for the validation and full potential that radiomics representsStandardized data collection, evaluation criteria, and reporting guidelines are required for radiomics to mature as a discipline},
issn={1759-4782},
doi={10.1038/nrclinonc.2017.141},
url={https://doi.org/10.1038/nrclinonc.2017.141}
}

@Article{doi:10.1148/radiol.2015151169,
  author   = {Gillies, Robert J. and Kinahan, Paul E. and Hricak, Hedvig},
  title    = {Radiomics: Images Are More than Pictures, They Are Data},
  doi      = {10.1148/radiol.2015151169},
  eprint   = {https://doi.org/10.1148/radiol.2015151169},
  note     = {PMID: 26579733},
  number   = {2},
  pages    = {563-577},
  url      = {https://doi.org/10.1148/radiol.2015151169},
  volume   = {278},
  abstract = {In the past decade, the field of medical image analysis has grown exponentially, with an increased number of pattern recognition tools and an increase in data set sizes. These advances have facilitated the development of processes for high-throughput extraction of quantitative features that result in the conversion of images into mineable data and the subsequent analysis of these data for decision support; this practice is termed radiomics. This is in contrast to the traditional practice of treating medical images as pictures intended solely for visual interpretation. Radiomic data contain first-, second-, and higher-order statistics. These data are combined with other patient data and are mined with sophisticated bioinformatics tools to develop models that may potentially improve diagnostic, prognostic, and predictive accuracy. Because radiomics analyses are intended to be conducted with standard of care images, it is conceivable that conversion of digital images to mineable data will eventually become routine practice. This report describes the process of radiomics, its challenges, and its potential power to facilitate better clinical decision making, particularly in the care of patients with cancer.},
  journal  = {Radiology},
  year     = {2016},
}

@article{MIAO201817,
title = "Extraction of BI-RADS findings from breast ultrasound reports in Chinese using deep learning approaches",
journal = "International Journal of Medical Informatics",
volume = "119",
pages = "17 - 21",
year = "2018",
issn = "1386-5056",
doi = "https://doi.org/10.1016/j.ijmedinf.2018.08.009",
url = "http://www.sciencedirect.com/science/article/pii/S1386505618309225",
author = "Shumei Miao and Tingyu Xu and Yonghui Wu and Hui Xie and Jingqi Wang and Shenqi Jing and Yaoyun Zhang and Xiaoliang Zhang and Yinshuang Yang and Xin Zhang and Tao Shan and Li Wang and Hua Xu and Shui Wang and Yun Liu",
keywords = "Named entity recognition, Clinical natural language processing, Deep learning",
abstract = "Background
The wide adoption of electronic health record systems (EHRs) in hospitals in China has made large amounts of data available for clinical research including breast cancer. Unfortunately, much of detailed clinical information is embedded in clinical narratives e.g., breast radiology reports. The American College of Radiology (ACR) has developed a Breast Imaging Reporting and Data System (BI-RADS) to standardize the clinical findings from breast radiology reports.
Objectives
This study aims to develop natural language processing (NLP) methods to extract BI-RADS findings from breast ultrasound reports in Chinese, thus to support clinical operation and breast cancer research in China.
Methods
We developed and compared three different types of NLP approaches, including a rule-based method, a traditional machine learning-based method using the Conditional Random Fields (CRF) algorithm, and deep learning-based approaches, to extract all BI-RADS finding categories from breast ultrasound reports in Chinese.
Results
Using a manually annotated dataset containing 540 reports, our evaluation shows that the deep learning-based method achieved the best F1-score of 0.904, when compared with rule-based and CRF-based approaches (0.848 and 0.881 respectively).
Conclusions
This is the first study that applies deep learning technologies to BI-RADS findings extraction in Chinese breast ultrasound reports, demonstrating its potential on enabling international collaborations on breast cancer research."
}

@article{10.1117/1.JBO.22.4.046008,
author = {Bernhard B. Zimmermann and Bin Deng and Bhawana Singh and Mark Martino and Juliette J. Selb and Qianqian Fang and Amir Y. Sajjadi and Jayne A. Cormier and Richard H. Moore and Daniel B. Kopans and David A. Boas and Mansi A. Saksena and Stefan A. Carp},
title = {{Multimodal breast cancer imaging using coregistered dynamic diffuse optical tomography and digital breast tomosynthesis}},
volume = {22},
journal = {Journal of Biomedical Optics},
number = {4},
publisher = {SPIE},
pages = {1 -- 10},
keywords = {diffuse optical tomography, dynamic imaging, breast cancer, digital breast tomosynthesis, multimodal, optical mammography, Digital breast tomosynthesis, Breast, Sensors, Optical fibers, Absorption, X-rays, Breast cancer, Mammography, Tumors, Imaging systems},
year = {2017},
doi = {10.1117/1.JBO.22.4.046008},
URL = {https://doi.org/10.1117/1.JBO.22.4.046008}
}

@article{10.1093/jbi/wbaa010,
    author = {Baird, Grayson L and Dibble, Elizabeth H and Mainiero, Martha B and Miles, Randy C and Lourenco, Ana P},
    title = "{Dense Breast Notification Letters: What Do Breast Radiologists Think?}",
    journal = {Journal of Breast Imaging},
    volume = {2},
    number = {3},
    pages = {225-231},
    year = {2020},
    month = {04},
    abstract = "{The Food and Drug Administration is currently creating national standards for language used in letters sent to women after mammography concerning dense breasts. The purpose of the current study is to survey breast radiologists on their opinions about language to be included in dense breast notification (DBN) letters.An anonymous survey (17 questions and 10 open-ended response fields) was sent to Society of Breast Imaging members between May 2019 and June 2019. Analyses were conducted using a chi-square test and the generalized linear model.A total of 262 surveys were completed (25\\% response rate). The majority of breast radiologists believe letters should be sent to patients (91\\%), with most (66\\%) believing that patients should receive DBN letters regardless of having dense breasts or not. The majority of breast radiologists believe DBNs should be sent to referring physicians (69\\%), include statements that define masking (89\\%), inform patients that dense breasts are associated with cancer risk (77\\%), inform patients about the possible benefits of supplemental screening (86\\%), be written at the sixth- or eighth-grade reading level (92\\%), and should be provided in other languages in addition to English (89\\%); half of the respondents (51\\%) believe the letters should contain BI-RADS density descriptors.There is consensus that patients and referring physicians should receive DBN letters and that those letters should address masking, increased cancer risk, and supplemental screening. Respondents believe the letters should be written at a sixth- or eighth-grade reading level.}",
    issn = {2631-6110},
    doi = {10.1093/jbi/wbaa010},
    url = {https://doi.org/10.1093/jbi/wbaa010},
    eprint = {https://academic.oup.com/jbi/article-pdf/2/3/225/33502034/wbaa010.pdf},
}

@article{SHAN2016980,
title = "Computer-Aided Diagnosis for Breast Ultrasound Using Computerized BI-RADS Features and Machine Learning Methods",
journal = "Ultrasound in Medicine \& Biology",
volume = "42",
number = "4",
pages = "980 - 988",
year = "2016",
issn = "0301-5629",
doi = "https://doi.org/10.1016/j.ultrasmedbio.2015.11.016",
url = "http://www.sciencedirect.com/science/article/pii/S0301562915006808",
author = "Juan Shan and S. Kaisar Alam and Brian Garra and Yingtao Zhang and Tahira Ahmed",
keywords = "Breast cancer, Computer-aided diagnosis, Computerized features, Breast Imaging Reporting and Data System, BI-RADS, Machine learning, Receiver operating characteristic, Tissue characterization, Tumor classification, Ultrasonic imaging",
abstract = "This work identifies effective computable features from the Breast Imaging Reporting and Data System (BI-RADS), to develop a computer-aided diagnosis (CAD) system for breast ultrasound. Computerized features corresponding to ultrasound BI-RADs categories were designed and tested using a database of 283 pathology-proven benign and malignant lesions. Features were selected based on classification performance using a “bottom-up” approach for different machine learning methods, including decision tree, artificial neural network, random forest and support vector machine. Using 10-fold cross-validation on the database of 283 cases, the highest area under the receiver operating characteristic (ROC) curve (AUC) was 0.84 from a support vector machine with 77.7% overall accuracy; the highest overall accuracy, 78.5%, was from a random forest with the AUC 0.83. Lesion margin and orientation were optimum features common to all of the different machine learning methods. These features can be used in CAD systems to help distinguish benign from worrisome lesions."
}

@article{pesapane2018artificial,
  title={Artificial intelligence in medical imaging: threat or opportunity? Radiologists again at the forefront of innovation in medicine},
  author={Pesapane, Filippo and Codari, Marina and Sardanelli, Francesco},
  journal={European radiology experimental},
  volume={2},
  number={1},
  pages={35},
  year={2018},
  publisher={Springer}
}

@article{HANNA20181709,
title = "The Effects of Fatigue From Overnight Shifts on Radiology Search Patterns and Diagnostic Performance",
journal = "Journal of the American College of Radiology",
volume = "15",
number = "12",
pages = "1709 - 1716",
year = "2018",
issn = "1546-1440",
doi = "https://doi.org/10.1016/j.jacr.2017.12.019",
url = "http://www.sciencedirect.com/science/article/pii/S1546144017316617",
author = "Tarek N. Hanna and Matthew E. Zygmont and Ryan Peterson and David Theriot and Haris Shekhani and Jamlik-Omari Johnson and Elizabeth A. Krupinski",
keywords = "Fatigue, medical error, radiology, overnight, search pattern",
abstract = "Purpose
The aim of this study was to assess the effect of overnight shifts (ONS) on radiologist fatigue, visual search pattern, and diagnostic performance.
Methods
This experimental study was approved by the institutional review board. Twelve radiologists (five faculty members and seven residents) each completed two sessions: one during a normal workday (“not fatigued”) and another in the morning after an ONS (“fatigued”). Each radiologist completed the Swedish Occupational Fatigue Inventory. During each session, radiologists viewed 20 bone radiographs consisting of normal and abnormal findings. Viewing time, diagnostic confidence, and eye-tracking data were recorded.
Results
Swedish Occupational Fatigue Inventory results demonstrated worsening in all five variables (lack of energy, physical exertion, physical discomfort, lack of motivation, and sleepiness) after ONS (P < .01). Overall, participants demonstrated worse diagnostic performance in the fatigued versus not fatigued state (P < .05). Total viewing time per case was longer when fatigued (35.9 ± 25.8 seconds) than not fatigued (24.8 ± 16.3 seconds) (P < .0001). Total viewing time per case was longer for residents (P < .05). Mean total fixations generated during the search increased by 60% during fatigued sessions (P < .0001). Mean time to first fixate on the fracture increased by 34% during fatigued sessions (P < .0001) and was longer for residents (P < .01). Dwell times associated with true- and false-positive decisions increased, whereas those with false negatives decreased.
Conclusions
After ONS, radiologists were more fatigued with worse diagnostic performance, a 45% increase in view time per case, a 60% increase in total gaze fixations, and a 34% increase in time to fixate on the fracture. The effects of fatigue were more pronounced in residents."
}

@article{d2018breast,
  title={Breast imaging reporting and data system (BI-RADS)},
  author={D'Orsi, Carl and Bassett, L and Feig, S and others},
  journal={Breast Imaging. Lee CI, Lehman CD, Bassett LW (ed): Oxford University Press, New York},
  year={2018}
}

@Article{doi:10.1148/radiol.2018181371,
  author   = {Rodríguez-Ruiz, Alejandro and Krupinski, Elizabeth and Mordang, Jan-Jurre and Schilling, Kathy and Heywang-Köbrunner, Sylvia H. and Sechopoulos, Ioannis and Mann, Ritse M.},
  title    = {Detection of Breast Cancer with Mammography: Effect of an Artificial Intelligence Support System},
  doi      = {10.1148/radiol.2018181371},
  eprint   = {https://doi.org/10.1148/radiol.2018181371},
  note     = {PMID: 30457482},
  number   = {2},
  pages    = {305-314},
  url      = {https://doi.org/10.1148/radiol.2018181371},
  volume   = {290},
  abstract = {PurposeTo compare breast cancer detection performance of radiologists reading mammographic examinations unaided versus supported by an artificial intelligence (AI) system.Materials and MethodsAn enriched retrospective, fully crossed, multireader, multicase, HIPAA-compliant study was performed. Screening digital mammographic examinations from 240 women (median age, 62 years; range, 39–89 years) performed between 2013 and 2017 were included. The 240 examinations (100 showing cancers, 40 leading to false-positive recalls, 100 normal) were interpreted by 14 Mammography Quality Standards Act–qualified radiologists, once with and once without AI support. The readers provided a Breast Imaging Reporting and Data System score and probability of malignancy. AI support provided radiologists with interactive decision support (clicking on a breast region yields a local cancer likelihood score), traditional lesion markers for computer-detected abnormalities, and an examination-based cancer likelihood score. The area under the receiver operating characteristic curve (AUC), specificity and sensitivity, and reading time were compared between conditions by using mixed-models analysis dof variance and generalized linear models for multiple repeated measurements.ResultsOn average, the AUC was higher with AI support than with unaided reading (0.89 vs 0.87, respectively; P = .002). Sensitivity increased with AI support (86\% [86 of 100] vs 83\% [83 of 100]; P = .046), whereas specificity trended toward improvement (79\% [111 of 140]) vs 77\% [108 of 140]; P = .06). Reading time per case was similar (unaided, 146 seconds; supported by AI, 149 seconds; P = .15). The AUC with the AI system alone was similar to the average AUC of the radiologists (0.89 vs 0.87).ConclusionRadiologists improved their cancer detection at mammography when using an artificial intelligence system for support, without requiring additional reading time.Published under a CC BY 4.0 license.See also the editorial by Bahl in this issue.},
  journal  = {Radiology},
  year     = {2019},
}

@ARTICLE{8611096,
  author={Q. {Huang} and Y. {Chen} and L. {Liu} and D. {Tao} and X. {Li}},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={On Combining Biclustering Mining and AdaBoost for Breast Tumor Classification}, 
  year={2020},
  volume={32},
  number={4},
  pages={728-738},
  doi={10.1109/TKDE.2019.2891622}
}

@INPROCEEDINGS{9231684,
  author={B. {Jaafar} and H. {Mahersia} and Z. {Lachiri}},
  booktitle={2020 5th International Conference on Advanced Technologies for Signal and Image Processing (ATSIP)}, 
  title={A survey on deep learning techniques used for breast cancer detection}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/ATSIP49331.2020.9231684}
}

@article{https://doi.org/10.1002/cncr.32910,
author = {Mutebi, Miriam and Anderson, Benjamin O. and Duggan, Catherine and Adebamowo, Clement and Agarwal, Gaurav and Ali, Zipporah and Bird, Peter and Bourque, Jean-Marc and DeBoer, Rebecca and Gebrim, Luiz Henrique and Masetti, Riccardo and Masood, Shahla and Menon, Manoj and Nakigudde, Gertrude and Ng’ang’a, Anne and Niyonzima, Nixon and Rositch, Anne F. and Unger-Saldaña, Karla and Villarreal-Garza, Cynthia and Dvaladze, Allison and El Saghir, Nagi S. and Gralow, Julie R. and Eniu, Alexandru},
title = {Breast cancer treatment: A phased approach to implementation},
journal = {Cancer},
volume = {126},
number = {S10},
pages = {2365-2378},
keywords = {breast cancer, cancer center of excellence, centralized care, decentralized care, dissemination and implementation science, early diagnosis, health disparities, low- and middle-income countries (LMICs), multidisciplinary evaluation, phased implementation, resource-stratification, supportive and palliative care, treatment, underserved communities},
doi = {https://doi.org/10.1002/cncr.32910},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.1002/cncr.32910},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.1002/cncr.32910},
abstract = {Optimal treatment outcomes for breast cancer are dependent on a timely diagnosis followed by an organized, multidisciplinary approach to care. However, in many low- and middle-income countries, effective care management pathways can be difficult to follow because of financial constraints, a lack of resources, an insufficiently trained workforce, and/or poor infrastructure. On the basis of prior work by the Breast Health Global Initiative, this article proposes a phased implementation strategy for developing sustainable approaches to enhancing patient care in limited-resource settings by creating roadmaps that are individualized and adapted to the baseline environment. This strategy proposes that, after a situational analysis, implementation phases begin with bolstering palliative care capacity, especially in settings where a late-stage diagnosis is common. This is followed by strengthening the patient pathway, with consideration given to a dynamic balance between centralization of services into centers of excellence to achieve better quality and decentralization of services to increase patient access. The use of resource checklists ensures that comprehensive therapy or palliative care can be delivered safely and effectively. Episodic or continuous monitoring with established process and quality metrics facilitates ongoing assessment, which should drive continual process improvements. A series of case studies provides a snapshot of country experiences with enhancing patient care, including the implementation of national cancer control plans in Kenya, palliative care in Romania, the introduction of a 1-stop clinic for diagnosis in Brazil, the surgical management of breast cancer in India, and the establishment of a women's cancer center in Ghana.},
year = {2020}
}

@article{DANA2020541,
title = "Multimodality Imaging and Artificial Intelligence for Tumor Characterization: Current Status and Future Perspective",
journal = "Seminars in Nuclear Medicine",
volume = "50",
number = "6",
pages = "541 - 548",
year = "2020",
note = "Imaging Biomarkers for Therapy Assessment of Malignant Disease",
issn = "0001-2998",
doi = "https://doi.org/10.1053/j.semnuclmed.2020.07.003",
url = "http://www.sciencedirect.com/science/article/pii/S000129982030074X",
author = "Jérémy Dana and Vincent Agnus and Farid Ouhmich and Benoit Gallix",
abstract = "Research in medical imaging has yet to do to achieve precision oncology. Over the past 30 years, only the simplest imaging biomarkers (RECIST, SUV,…) have become widespread clinical tools. This may be due to our inability to accurately characterize tumors and monitor intratumoral changes in imaging. Artificial intelligence, through machine learning and deep learning, opens a new path in medical research because it can bring together a large amount of heterogeneous data into the same analysis to reach a single outcome. Supervised or unsupervised learning may lead to new paradigms by identifying unrevealed structural patterns across data. Deep learning will provide human-free, undefined upstream, reproducible, and automated quantitative imaging biomarkers. Since tumor phenotype is driven by its genotype and thus indirectly defines tumoral progression, tumor characterization using machine learning and deep learning algorithms will allow us to monitor molecular expression noninvasively, anticipate therapeutic failure, and lead therapeutic management. To follow this path, quality standards have to be set: standardization of imaging acquisition as it has been done in the field of biology, transparency of the model development as it should be reproducible by different institutions, validation, and testing through a high-quality process using large and complex open databases and better interpretability of these algorithms."
}

@article{DIROBERTO2016950,
title = "Improving the Transcription of Patient Information From Image Requisitions to the Radiology Information System",
journal = "Journal of the American College of Radiology",
volume = "13",
number = "8",
pages = "950 - 955",
year = "2016",
issn = "1546-1440",
doi = "https://doi.org/10.1016/j.jacr.2016.03.030",
url = "http://www.sciencedirect.com/science/article/pii/S1546144016301740",
author = "Cole DiRoberto and Crystal Lehto and Steven J. Baccei",
keywords = "Patient information, image requisition, transcription, RIS, radiology information system, transcribing information, improving, improvement, improving communication, communication, technologists, indication, clinical order, RIS indication, CPOE, computerized physician order entry",
abstract = "Purpose
The purpose of this study was to improve the transcription of patient information from imaging study requisitions to the radiology information database at a single institution.
Methods
Five hundred radiology reports from adult outpatient radiographic examinations were chosen randomly from the radiology information system (RIS) and categorized according to their degree of concordance with their corresponding clinical order indications. The number and types of grammatical errors and types of order forms were also recorded. Countermeasures centered on the education of the technical staff and referring physician offices and the implementation of a checklist. Another sample of 500 reports was taken after the implementation of the countermeasures and compared with the baseline data using a χ2 test.
Results
The number of RIS indications perfectly concordant with their corresponding clinical order indications increased from 232 (46.4%) to 314 (62.8%) after the implementation of the countermeasures (P < .0001). The number of partially concordant matches due to inadequate RIS indications dropped from 162 (32.4%) to 114 (22.8%) (P < .001), whereas the number of partially concordant matches due to inadequate clinical order indications increased from 22 (4.4%) to 57 (11.4%) (P < .0001). The number of discordant pairings dropped from 84 (16.8%) to 15 (3%) (P < .0001). Technologists began to input additional patient information obtained from the patients (not present in the image requisitions) in the RIS after the implementation of the countermeasures.
Conclusions
The education of technical staff members and the implementation of a checklist markedly improved the information provided to radiologists on image requisitions from referring providers."
}

@article{islam2018recent,
  title={Recent advancement of clinical information systems: Opportunities and challenges},
  author={Islam, Md Mohaimenul and Poly, Tahmina Nasrin and Li, Yu-Chuan Jack},
  journal={Yearbook of medical informatics},
  volume={27},
  number={1},
  pages={83},
  year={2018},
  publisher={Thieme Medical Publishers}
}

@INPROCEEDINGS{8621479,
  author={D. {Chen} and G. {Qian} and Q. {Pan}},
  booktitle={2018 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Breast Cancer Classification with Electronic Medical Records Using Hierarchical Attention Bidirectional Networks}, 
  year={2018},
  volume={},
  number={},
  pages={983-988},
  doi={10.1109/BIBM.2018.8621479}
}

@article{GIBSON2018113,
title = "NiftyNet: a deep-learning platform for medical imaging",
journal = "Computer Methods and Programs in Biomedicine",
volume = "158",
pages = "113 - 122",
year = "2018",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2018.01.025",
url = "http://www.sciencedirect.com/science/article/pii/S0169260717311823",
author = "Eli Gibson and Wenqi Li and Carole Sudre and Lucas Fidon and Dzhoshkun I. Shakir and Guotai Wang and Zach Eaton-Rosen and Robert Gray and Tom Doel and Yipeng Hu and Tom Whyntie and Parashkev Nachev and Marc Modat and Dean C. Barratt and Sébastien Ourselin and M. Jorge Cardoso and Tom Vercauteren",
keywords = "Medical image analysis, Deep learning, Convolutional neural network, Segmentation, Image regression, Generative adversarial network",
abstract = "Background and objectives
Medical image analysis and computer-assisted intervention problems are increasingly being addressed with deep-learning-based solutions. Established deep-learning platforms are flexible but do not provide specific functionality for medical image analysis and adapting them for this domain of application requires substantial implementation effort. Consequently, there has been substantial duplication of effort and incompatible infrastructure developed across many research groups. This work presents the open-source NiftyNet platform for deep learning in medical imaging. The ambition of NiftyNet is to accelerate and simplify the development of these solutions, and to provide a common mechanism for disseminating research outputs for the community to use, adapt and build upon.
Methods
The NiftyNet infrastructure provides a modular deep-learning pipeline for a range of medical imaging applications including segmentation, regression, image generation and representation learning applications. Components of the NiftyNet pipeline including data loading, data augmentation, network architectures, loss functions and evaluation metrics are tailored to, and take advantage of, the idiosyncracies of medical image analysis and computer-assisted intervention. NiftyNet is built on the TensorFlow framework and supports features such as TensorBoard visualization of 2D and 3D images and computational graphs by default.
Results
We present three illustrative medical image analysis applications built using NiftyNet infrastructure: (1) segmentation of multiple abdominal organs from computed tomography; (2) image regression to predict computed tomography attenuation maps from brain magnetic resonance images; and (3) generation of simulated ultrasound images for specified anatomical poses.
Conclusions
The NiftyNet infrastructure enables researchers to rapidly develop and distribute deep learning solutions for segmentation, regression, image generation and representation learning applications, or extend the platform to new applications."
}

@article{https://doi.org/10.1002/cncr.32872,
author = {Anglade, Fabienne and Milner Jr, Danny A. and Brock, Jane E.},
title = {Can pathology diagnostic services for cancer be stratified and serve global health?},
journal = {Cancer},
volume = {126},
number = {S10},
pages = {2431-2438},
keywords = {breast cancer, diagnostics, guidelines, pathology, stratification, tiered},
doi = {https://doi.org/10.1002/cncr.32872},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.1002/cncr.32872},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.1002/cncr.32872},
abstract = {Background Before initiating cancer therapy, a diagnostic tumor tissue sample evaluated within a pathology laboratory by a pathologist is essential to confirm the malignancy type and provide key prognostic factors that direct the treatment offered. Methods Pathology evaluation includes multiple expensive reagents, complex equipment, and both laboratory and pathologist technical skills. By using breast cancer as an example, at a minimum, key tumor prognostic information required before the initiation of treatment includes subtype, tumor grade, tumor size, lymph node status when possible, and biomarker expression determined by immunohistochemistry for estrogen receptor. The additional determination of biomarker expression of progesterone receptor and human epidermal growth factor receptor (HER2) is the standard of care in high-resource settings, but assays may not be affordable in low-income and middle-income countries. Results With positive tests, patients are eligible for either tamoxifen (for estrogen receptor-positive/progesterone receptor-positive cancers) or monoclonal antibody therapy (for HER2-positive cancers). For settings in which endocrine therapy and/or HER2-targeted therapy is unavailable, biomarker studies have no utility, and high-resource setting standards for pathology evaluation and reporting are unachievable. Resource-stratified pathology evaluation guidelines in cancer diagnosis have not been developed, in contrast to excellent comprehensive, resource-stratified clinical guidelines for use in low-income and middle-income countries, and these are long overdue. Conclusions The challenges of pathology evaluation in the context of global health are being met by innovative solutions, which may change the face of pathology practice.},
year = {2020}
}

@article{jiang2018interpretation,
  title={Interpretation time using a concurrent-read computer-aided detection system for automated breast ultrasound in breast cancer screening of women with dense breast tissue},
  author={Jiang, Yulei and Inciardi, Marc F and Edwards, Alexandra V and Papaioannou, John},
  journal={American Journal of Roentgenology},
  volume={211},
  number={2},
  pages={452--461},
  year={2018},
  publisher={Am Roentgen Ray Soc}
}

@InProceedings{10.1007/978-3-030-59716-0_71,
author="Gammulle, Harshala
and Denman, Simon
and Sridharan, Sridha
and Fookes, Clinton",
editor="Martel, Anne L.
and Abolmaesumi, Purang
and Stoyanov, Danail
and Mateus, Diana
and Zuluaga, Maria A.
and Zhou, S. Kevin
and Racoceanu, Daniel
and Joskowicz, Leo",
title="Two-Stream Deep Feature Modelling for Automated Video Endoscopy Data Analysis",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="742--751",
abstract="Automating the analysis of imagery of the Gastrointestinal (GI) tract captured during endoscopy procedures has substantial potential benefits for patients, as it can provide diagnostic support to medical practitioners and reduce mistakes via human error. To further the development of such methods, we propose a two-stream model for endoscopic image analysis. Our model fuses two streams of deep feature inputs by mapping their inherent relations through a novel relational network model, to better model symptoms and classify the image. In contrast to handcrafted feature-based models, our proposed network is able to learn features automatically and outperforms existing state-of-the-art methods on two public datasets: KVASIR and Nerthus. Our extensive evaluations illustrate the importance of having two streams of inputs instead of a single stream and also demonstrates the merits of the proposed relational network architecture to combine those streams.",
isbn="978-3-030-59716-0"
}

@Article{doi:10.1148/radiol.2020192039,
  author   = {Kim, Jin You and Kim, Jin Joo and Hwangbo, Lee and Suh, Hie Bum and Kim, Suk and Choo, Ki Seok and Nam, Kyung Jin and Kang, Taewoo},
  title    = {Kinetic Heterogeneity of Breast Cancer Determined Using Computer-aided Diagnosis of Preoperative MRI Scans: Relationship to Distant Metastasis-Free Survival},
  doi      = {10.1148/radiol.2020192039},
  eprint   = {https://doi.org/10.1148/radiol.2020192039},
  note     = {PMID: 32228293},
  number   = {3},
  pages    = {517-526},
  url      = {https://doi.org/10.1148/radiol.2020192039},
  volume   = {295},
  abstract = {Background Higher peak enhancement and washout component values measured on preoperative breast MRI scans with computer-aided diagnosis (CAD) are presumed to be associated with worse recurrence-free survival. Purpose To investigate whether CAD-extracted kinetic features of breast cancer and the heterogeneity of these features at preoperative MRI are associated with distant metastasis-free survival in women with invasive breast cancer. Materials and Methods Consecutive women with newly diagnosed invasive breast cancer who underwent preoperative MRI were retrospectively evaluated between 2011 and 2012. A commercially available CAD system was used to extract the peak enhancement and delayed enhancement profiles of each breast cancer case from preoperative MRI data. The kinetic heterogeneity of these features (a measure of heterogeneity in the proportions of tumor pixels with delayed washout, plateau, and persistent components within a tumor) was calculated to evaluate intratumoral heterogeneity. Cox proportional hazards models were used to investigate the associations between CAD-extracted kinetic features and distant metastasis-free survival after adjusting for clinical-pathologic factors. Results A total of 276 consecutive women (mean age, 53 years) were evaluated. In 28 of 276 (10.1\%) women, distant metastasis developed at a median follow-up of 79 months. A higher degree of kinetic heterogeneity was observed in women with distant metastases than in those without distant metastases (mean, 0.70 ± 0.2 vs 0.43 ± 0.3; P < .001). Multivariable Cox proportional hazards analysis revealed that a higher degree of kinetic heterogeneity (hazard ratio [HR], 19.2; 95\% confidence interval [CI]: 4.2, 87.1; P < .001), higher peak enhancement (HR, 1.001; 95\% CI: 1.000, 1.002; P = .045), the presence of lymphovascular invasion (HR, 3.3; 95\% CI: 1.5, 7.5; P = .004), and a higher histologic grade (ie, grade 3) (HR, 2.2; 95\% CI: 1.0, 4.9; P = .044) were associated with worse distant metastasis-free survival. Conclusion Higher values of kinetic heterogeneity and peak enhancement as determined with computer-aided diagnosis of preoperative MRI were associated with worse distant metastasis-free survival in women with invasive breast cancer. © RSNA, 2020 See also the editorial by El Khouli and Jacobs in this issue.},
  journal  = {Radiology},
  year     = {2020},
}

@article{litjens2017survey,
  title={A survey on deep learning in medical image analysis},
  author={Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and Van Der Laak, Jeroen Awm and Van Ginneken, Bram and S{\'a}nchez, Clara I},
  journal={Medical image analysis},
  volume={42},
  pages={60--88},
  year={2017},
  publisher={Elsevier}
}

@Inbook{Trivedi2019,
author="Trivedi, Deven N.
and Shah, Nimit D.
and Kothari, Ashish M.
and Thanki, Rohit M.",
title="DICOM® Medical Image Standard",
bookTitle="Dental Image Processing for Human Identification",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="41--49",
abstract="This chapter gives information on Digital Imaging and Communications in Medicine (DICOM), a medical image standard, and about DICOM dental images, which are used to identify a person.",
isbn="978-3-319-99471-0",
doi="10.1007/978-3-319-99471-0_4",
url="https://doi.org/10.1007/978-3-319-99471-0_4"
}

@book{carter2018digital,
  title={Digital Radiography and PACS E-Book},
  author={Carter, Christi and Veale, Beth},
  year={2018},
  publisher={Elsevier Health Sciences}
}

@inproceedings{seifabadi2019correlation,
  title={Correlation of ultrasound tomography to MRI and pathology for the detection of prostate cancer},
  author={Seifabadi, Reza and Cheng, Alexis and Malik, Bilal and Kishimoto, Shun and Wiskin, James and Munasinghe, Jeeva and Negussie, Ayele H and Bakhutashvili, Ivane and Krishna, Murali C and Choyke, Peter and others},
  booktitle={Medical Imaging 2019: Ultrasonic Imaging and Tomography},
  volume={10955},
  pages={109550C},
  year={2019},
  organization={International Society for Optics and Photonics}
}

@inproceedings{Igarashi:2016:IVS:2984511.2984537,
 author={Igarashi, Takeo and Shono, Naoyuki and Kin, Taichi and Saito, Toki},
 title={{Interactive Volume Segmentation with Threshold Field Painting}},
 booktitle={Annual Symposium on User Interface Software and Technology (UIST)},
 year={2016},
 pages={403--413},
 doi={10.1145/2984511.2984537},
 publisher={ACM},
 address={New York, NY, USA},
}

@inproceedings{Ocegueda-Hernandez:2016:CMN:2876456.2879485,
 author={Ocegueda-Hern\'{a}ndez, Vladimir and Mendizabal-Ruiz, Gerardo},
 title={{Computational Methods for the Natural and Intuitive Visualization of Volumetric Medical Data}},
 booktitle={Int'l Conf. Intelligent User Interfaces (IUI)},
 year={2016},
 pages={54--57},
 doi={10.1145/2876456.2879485},
 publisher={ACM},
 address={New York, NY, USA},
}

@inproceedings{Sousa:2017:VVR:3025453.3025566,
 author={Sousa, Maur\'{\i}cio and Mendes, Daniel and Paulo, Soraia and Matela, Nuno and Jorge, Joaquim and Lopes, Daniel Sim\~{o}es},
 title={{VRRRRoom: Virtual Reality for Radiologists in the Reading Room}},
 booktitle={Conf. Human Factors in Computing Systems (CHI)},
 year={2017},
 location={Denver, Colorado, USA},
 pages={4057--4062},
 doi={10.1145/3025453.3025566},
 publisher={ACM},
 address={New York, NY, USA},
}

@article{Lopes:2017:UHC:3143820.3144118,
 author = {Lopes, Daniel Simes and Parreira, Pedro Duarte de Figueiredo and Paulo, Soraia Figueiredo and Nunes, Vitor and Rego, Paulo Amaral and Neves, Manuel Cassiano and Rodrigues, Pedro Silva and Jorge, Joaquim Armando},
 title = {On the Utility of 3D Hand Cursors to Explore Medical Volume Datasets with a Touchless Interface},
 journal = {J. of Biomedical Informatics},
 issue_date = {August 2017},
 volume = {72},
 number = {C},
 month = aug,
 year = {2017},
 issn = {1532-0464},
 pages = {140--149},
 numpages = {10},
 url = {https://doi.org/10.1016/j.jbi.2017.07.009},
 doi = {10.1016/j.jbi.2017.07.009},
 acmid = {3144118},
 publisher = {Elsevier Science},
 address = {San Diego, USA},
 keywords = {2Dtwo-dimensional, 3D hand cursor, 3Dthree-dimensional, Bi-manual gestures, CTcomputed tomography, DICOMdigital imaging and communications in medicine, GUIgraphical user interface, LANlocal wireless network, MRImagnetic resonance imaging, Medical volume data, Mmean, SDstandard deviation, Touchless interface, USBuniversal serial bus, User study, VEVoxel Explorer, VolVolview, WIMPwindows-icons-menus-pointers},
}

@inproceedings{lopes2018interaction,
  title={Interaction techniques for immersive ct colonography: A professional assessment},
  author={Lopes, Daniel Simoes and Medeiros, Daniel and Paulo, Soraia Figueiredo and Borges, Pedro Brasil and Nunes, Vitor and Mascarenhas, Vasco and Veiga, Marcos and Jorge, Joaquim Armando},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={629--637},
  year={2018},
  organization={Springer}
}

@inproceedings{Cai:2019:EEE:3301275.3302289,
 author = {Cai, Carrie J. and Jongejan, Jonas and Holbrook, Jess},
 title = {The Effects of Example-based Explanations in a Machine Learning Interface},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 series = {IUI '19},
 year = {2019},
 isbn = {978-1-4503-6272-6},
 location = {Marina del Ray, California},
 pages = {258--262},
 numpages = {5},
 url = {http://doi.acm.org/10.1145/3301275.3302289},
 doi = {10.1145/3301275.3302289},
 acmid = {3302289},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {example-based explanations, explainable AI, human-AI interaction, machine learning},
}

@article{hwang2019artificial,
  title={Artificial intelligence-based decision-making for age-related macular degeneration},
  author={Hwang, De-Kuang and Hsu, Chih-Chien and Chang, Kao-Jung and Chao, Daniel and Sun, Chuan-Hu and Jheng, Ying-Chun and Yarmishyn, Aliaksandr A and Wu, Jau-Ching and Tsai, Ching-Yao and Wang, Mong-Lien and others},
  journal={Theranostics},
  volume={9},
  number={1},
  pages={232},
  year={2019},
  publisher={Ivyspring International Publisher}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{esteva2019guide,
  title={A guide to deep learning in healthcare},
  author={Esteva, Andre and Robicquet, Alexandre and Ramsundar, Bharath and Kuleshov, Volodymyr and DePristo, Mark and Chou, Katherine and Cui, Claire and Corrado, Greg and Thrun, Sebastian and Dean, Jeff},
  journal={Nature medicine},
  volume={25},
  number={1},
  pages={24},
  year={2019},
  publisher={Nature Publishing Group}
}

@inproceedings{medley2019segmenting,
  title={Segmenting The Left Ventricle In Cardiac In Cardiac MRI: From Handcrafted To Deep Region Based Descriptors},
  author={Medley, Daniela O and Santiago, Carlos and Nascimento, Jacinto C},
  booktitle={2019 IEEE 16th International Symposium on Biomedical Imaging (ISBI 2019)},
  pages={644--648},
  year={2019},
  organization={IEEE}
}

@article{cole2017predicting,
  title={Predicting brain age with deep learning from raw imaging data results in a reliable and heritable biomarker},
  author={Cole, James H and Poudel, Rudra PK and Tsagkrasoulis, Dimosthenis and Caan, Matthan WA and Steves, Claire and Spector, Tim D and Montana, Giovanni},
  journal={NeuroImage},
  volume={163},
  pages={115--124},
  year={2017},
  publisher={Elsevier}
}

@inproceedings{gonzalez2018deep,
  title={Deep learning for biomarker regression: application to osteoporosis and emphysema on chest CT scans},
  author={Gonz{\'a}lez, Germ{\'a}n and Washko, George R and Est{\'e}par, Ra{\'u}l San Jos{\'e}},
  booktitle={Medical Imaging 2018: Image Processing},
  volume={10574},
  pages={105741H},
  year={2018},
  organization={International Society for Optics and Photonics}
}

@article{holzinger2019causability,
  title={Causability and explainabilty of artificial intelligence in medicine},
  author={Holzinger, Andreas and Langs, Georg and Denk, Helmut and Zatloukal, Kurt and M{\"u}ller, Heimo},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  pages={e1312},
  year={2019},
  publisher={Wiley Online Library}
}

@article{gunning2017explainable,
  title={Explainable artificial intelligence (xai)},
  author={Gunning, David},
  journal={Defense Advanced Research Projects Agency (DARPA), nd Web},
  year={2017}
}

@inproceedings{holzinger2018current,
  title={Current advances, trends and challenges of machine learning and knowledge extraction: From machine learning to explainable ai},
  author={Holzinger, Andreas and Kieseberg, Peter and Weippl, Edgar and Tjoa, A Min},
  booktitle={International Cross-Domain Conference for Machine Learning and Knowledge Extraction},
  pages={1--8},
  year={2018},
  organization={Springer}
}

@inproceedings{Bharadhwaj:2019:ERS:3308557.3308699,
 author = {Bharadhwaj, Homanga},
 title = {Explainable Recommender System That Maximizes Exploration},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion},
 series = {IUI '19},
 year = {2019},
 isbn = {978-1-4503-6673-1},
 location = {Marina del Ray, California},
 pages = {1--2},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/3308557.3308699},
 doi = {10.1145/3308557.3308699},
 acmid = {3308699},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {RNN, explainable AI, recommender systems},
}

@inproceedings{Dominguez:2019:EEA:3301275.3302274,
 author = {Dominguez, Vicente and Messina, Pablo and Donoso-Guzm\'{a}n, Ivania and Parra, Denis},
 title = {The Effect of Explanations and Algorithmic Accuracy on Visual Recommender Systems of Artistic Images},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 series = {IUI '19},
 year = {2019},
 isbn = {978-1-4503-6272-6},
 location = {Marina del Ray, California},
 pages = {408--416},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3301275.3302274},
 doi = {10.1145/3301275.3302274},
 acmid = {3302274},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {art, explainable AI, visual recommender systems},
}

@inproceedings{Weisz:2019:BTS:3301275.3302290,
 author = {Weisz, Justin D. and Jain, Mohit and Joshi, Narendra Nath and Johnson, James and Lange, Ingrid},
 title = {BigBlueBot: Teaching Strategies for Successful Human-agent Interactions},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
 series = {IUI '19},
 year = {2019},
 isbn = {978-1-4503-6272-6},
 location = {Marina del Ray, California},
 pages = {448--459},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/3301275.3302290},
 doi = {10.1145/3301275.3302290},
 acmid = {3302290},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {conversational agents, explainable AI, mechanical turk},
}

@article{shah2019artificial,
  title={Artificial intelligence and machine learning in clinical development: a translational perspective},
  author={Shah, Pratik and Kendall, Francis and Khozin, Sean and Goosen, Ryan and Hu, Jianying and Laramie, Jason and Ringel, Michael and Schork, Nicholas},
  journal={NPJ digital medicine},
  volume={2},
  number={1},
  pages={69},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{10.1145/3359206,
author = {Cai, Carrie J. and Winter, Samantha and Steiner, David and Wilcox, Lauren and Terry, Michael},
title = {"Hello AI": Uncovering the Onboarding Needs of Medical Practitioners for Human-AI Collaborative Decision-Making},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359206},
doi = {10.1145/3359206},
abstract = {Although rapid advances in machine learning have made it increasingly applicable to expert decision-making, the delivery of accurate algorithmic predictions alone is insufficient for effective human-AI collaboration. In this work, we investigate the key types of information medical experts desire when they are first introduced to a diagnostic AI assistant. In a qualitative lab study, we interviewed 21 pathologists before, during, and after being presented deep neural network (DNN) predictions for prostate cancer diagnosis, to learn the types of information that they desired about the AI assistant. Our findings reveal that, far beyond understanding the local, case-specific reasoning behind any model decision, clinicians desired upfront information about basic, global properties of the model, such as its known strengths and limitations, its subjective point-of-view, and its overall design objective--what it's designed to be optimized for. Participants compared these information needs to the collaborative mental models they develop of their medical colleagues when seeking a second opinion: the medical perspectives and standards that those colleagues embody, and the compatibility of those perspectives with their own diagnostic patterns. These findings broaden and enrich discussions surrounding AI transparency for collaborative decision-making, providing a richer understanding of what experts find important in their introduction to AI assistants before integrating them into routine practice.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {104},
numpages = {24},
keywords = {human-ai interaction, clinical health, machine learning}
}

@InProceedings{10.1007/978-3-030-50334-5_4,
author="Meske, Christian
and Bunde, Enrico",
editor="Degen, Helmut
and Reinerman-Jones, Lauren",
title="Transparency and Trust in Human-AI-Interaction: The Role of Model-Agnostic Explanations in Computer Vision-Based Decision Support",
booktitle="Artificial Intelligence in HCI",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="54--69",
abstract="Computer Vision, and hence Artificial Intelligence-based extraction of information from images, has increasingly received attention over the last years, for instance in medical diagnostics. While the algorithms' complexity is a reason for their increased performance, it also leads to the `black box' problem, consequently decreasing trust towards AI. In this regard, ``Explainable Artificial Intelligence'' (XAI) allows to open that black box and to improve the degree of AI transparency. In this paper, we first discuss the theoretical impact of explainability on trust towards AI, followed by showcasing how the usage of XAI in a health-related setting can look like. More specifically, we show how XAI can be applied to understand why Computer Vision, based on deep learning, did or did not detect a disease (malaria) on image data (thin blood smear slide images). Furthermore, we investigate, how XAI can be used to compare the detection strategy of two different deep learning models often used for Computer Vision: Convolutional Neural Network and Multi-Layer Perceptron. Our empirical results show that i) the AI sometimes used questionable or irrelevant data features of an image to detect malaria (even if correctly predicted), and ii) that there may be significant discrepancies in how different deep learning models explain the same prediction. Our theoretical discussion highlights that XAI can support trust in Computer Vision systems, and AI systems in general, especially through an increased understandability and predictability.",
isbn="978-3-030-50334-5"
}

@inproceedings{10.1145/3306618.3314293,
author = {Teso, Stefano and Kersting, Kristian},
title = {Explanatory Interactive Machine Learning},
year = {2019},
isbn = {9781450363242},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3306618.3314293},
doi = {10.1145/3306618.3314293},
abstract = {Although interactive learning puts the user into the loop, the learner remains mostly a black box for the user. Understanding the reasons behind predictions and queries is important when assessing how the learner works and, in turn, trust. Consequently, we propose the novel framework of explanatory interactive learning where, in each step, the learner explains its query to the user, and the user interacts by both answering the query and correcting the explanation. We demonstrate that this can boost the predictive and explanatory powers of, and the trust into, the learned model, using text (e.g. SVMs) and image classification (e.g. neural networks) experiments as well as a user study.},
booktitle = {Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
pages = {239–245},
numpages = {7},
keywords = {active learning, explainable artificial intelligence, interpretability, machine learning},
location = {Honolulu, HI, USA},
series = {AIES '19}
}

@INPROCEEDINGS{8851763,
  author={C. {Han} and W. {Yoon} and G. {Kwon} and D. {Kim} and S. {Nam}},
  booktitle={2019 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Representation of white- and black-box adversarial examples in deep neural networks and humans: A functional magnetic resonance imaging study}, 
  year={2019},
  volume={},
  number={},
  pages={1-8},
  doi={10.1109/IJCNN.2019.8851763}
}

@inproceedings{10.1145/3206505.3206555,
author = {Balducci, Fabrizio and Buono, Paolo},
title = {Building a Qualified Annotation Dataset for Skin Lesion Analysis Trough Gamification},
year = {2018},
isbn = {9781450356169},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3206505.3206555},
doi = {10.1145/3206505.3206555},
abstract = {The deep learning approach has increased the quality of automatic medical diagnoses at the cost of building qualified datasets to train and test such supervised machine learning methods. Image annotation is one of the main activity of dermatologists and the quality of annotation depends on the physician experience and on the number of studied cases: manual annotations are very useful to extract features like contours, intersections and shapes that can be used in the processes of lesion segmentation and classification made by automatic agents. This paper proposes the design of an interactive multimedia platform that enhance the annotation process of medical images, in the domain of dermatology, adopting gamification and "games with a purpose" (GWAP) strategies in order to improve the engagement and the production of qualified datasets also fostering their sharing and practical evaluation. A special attention is given to the design choices, theories and assumptions as well as the implementation and technological details.},
booktitle = {Proceedings of the 2018 International Conference on Advanced Visual Interfaces},
articleno = {36},
numpages = {5},
keywords = {annotation, machine learning, dermatology, GWAP, gamification},
location = {Castiglione della Pescaia, Grosseto, Italy},
series = {AVI '18}
}

@inproceedings{10.1145/3290605.3300468,
author = {Yang, Qian and Steinfeld, Aaron and Zimmerman, John},
title = {Unremarkable AI: Fitting Intelligent Decision Support into Critical, Clinical Decision-Making Processes},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300468},
doi = {10.1145/3290605.3300468},
abstract = {Clinical decision support tools (DST) promise improved healthcare outcomes by offering data-driven insights. While effective in lab settings, almost all DSTs have failed in practice. Empirical research diagnosed poor contextual fit as the cause. This paper describes the design and field evaluation of a radically new form of DST. It automatically generates slides for clinicians' decision meetings with subtly embedded machine prognostics. This design took inspiration from the notion of Unremarkable Computing, that by augmenting the users' routines technology/AI can have significant importance for the users yet remain unobtrusive. Our field evaluation suggests clinicians are more likely to encounter and embrace such a DST. Drawing on their responses, we discuss the importance and intricacies of finding the right level of unremarkableness in DST design, and share lessons learned in prototyping critical AI systems as a situated experience.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {healthcare, decision support systems, user experience},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{https://doi.org/10.1002/mp.13562,
author = {Mahadevaiah, Geetha and RV, Prasad and Bermejo, Inigo and Jaffray, David and Dekker, Andre and Wee, Leonard},
title = {Artificial intelligence-based clinical decision support in modern medical physics: Selection, acceptance, commissioning, and quality assurance},
journal = {Medical Physics},
volume = {47},
number = {5},
pages = {e228-e235},
keywords = {artificial intelligence, clinical decision support, machine learning},
doi = {https://doi.org/10.1002/mp.13562},
url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1002/mp.13562},
eprint = {https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1002/mp.13562},
abstract = {Background Recent advances in machine and deep learning based on an increased availability of clinical data have fueled renewed interest in computerized clinical decision support systems (CDSSs). CDSSs have shown great potential to improve healthcare, increase patient safety and reduce costs. However, the use of CDSSs is not without pitfalls, as an inadequate or faulty CDSS can potentially deteriorate the quality of healthcare and put patients at risk. In addition, the adoption of a CDSS might fail because its intended users ignore the output of the CDSS due to lack of trust, relevancy or actionability. Aim In this article, we provide guidance based on literature for the different aspects involved in the adoption of a CDSS with a special focus on machine and deep learning based systems: selection, acceptance testing, commissioning, implementation and quality assurance. Results A rigorous selection process will help identify the CDSS that best fits the preferences and requirements of the local site. Acceptance testing will make sure that the selected CDSS fulfills the defined specifications and satisfies the safety requirements. The commissioning process will prepare the CDSS for safe clinical use at the local site. An effective implementation phase should result in an orderly roll out of the CDSS to the well-trained end-users whose expectations have been managed. And finally, quality assurance will make sure that the performance of the CDSS is maintained and that any issues are promptly identified and solved. Conclusion We conclude that a systematic approach to the adoption of a CDSS will help avoid pitfalls, improve patient safety and increase the chances of success.},
year = {2020}
}

@article{leung2019health,
  title={E-health/m-health adoption and lifestyle improvements: Exploring the roles of technology readiness, the expectation-confirmation model, and health-related information activities},
  author={Leung, Louis and Chen, Cheng},
  journal={Telecommunications Policy},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{10.1145/3351095.3375709,
author = {Yang, Kaiyu and Qinami, Klint and Fei-Fei, Li and Deng, Jia and Russakovsky, Olga},
title = {Towards Fairer Datasets: Filtering and Balancing the Distribution of the People Subtree in the ImageNet Hierarchy},
year = {2020},
isbn = {9781450369367},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3351095.3375709},
doi = {10.1145/3351095.3375709},
abstract = {Computer vision technology is being used by many but remains representative of only a few. People have reported misbehavior of computer vision models, including offensive prediction results and lower performance for underrepresented groups. Current computer vision models are typically developed using datasets consisting of manually annotated images or videos; the data and label distributions in these datasets are critical to the models' behavior. In this paper, we examine ImageNet, a large-scale ontology of images that has spurred the development of many modern computer vision methods. We consider three key factors within the person subtree of ImageNet that may lead to problematic behavior in downstream computer vision technology: (1) the stagnant concept vocabulary of WordNet, (2) the attempt at exhaustive illustration of all categories with images, and (3) the inequality of representation in the images within concepts. We seek to illuminate the root causes of these concerns and take the first steps to mitigate them constructively.},
booktitle = {Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
pages = {547–558},
numpages = {12},
keywords = {dataset construction, computer vision, representative datasets, fairness},
location = {Barcelona, Spain},
series = {FAT* '20}
}

@inproceedings{10.1145/3287560.3287596,
author = {Mitchell, Margaret and Wu, Simone and Zaldivar, Andrew and Barnes, Parker and Vasserman, Lucy and Hutchinson, Ben and Spitzer, Elena and Raji, Inioluwa Deborah and Gebru, Timnit},
title = {Model Cards for Model Reporting},
year = {2019},
isbn = {9781450361255},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3287560.3287596},
doi = {10.1145/3287560.3287596},
abstract = {Trained machine learning models are increasingly used to perform high-impact tasks in areas such as law enforcement, medicine, education, and employment. In order to clarify the intended use cases of machine learning models and minimize their usage in contexts for which they are not well suited, we recommend that released models be accompanied by documentation detailing their performance characteristics. In this paper, we propose a framework that we call model cards, to encourage such transparent model reporting. Model cards are short documents accompanying trained machine learning models that provide benchmarked evaluation in a variety of conditions, such as across different cultural, demographic, or phenotypic groups (e.g., race, geographic location, sex, Fitzpatrick skin type [15]) and intersectional groups (e.g., age and race, or sex and Fitzpatrick skin type) that are relevant to the intended application domains. Model cards also disclose the context in which models are intended to be used, details of the performance evaluation procedures, and other relevant information. While we focus primarily on human-centered machine learning models in the application fields of computer vision and natural language processing, this framework can be used to document any trained machine learning model. To solidify the concept, we provide cards for two supervised models: One trained to detect smiling faces in images, and one trained to detect toxic comments in text. We propose model cards as a step towards the responsible democratization of machine learning and related artificial intelligence technology, increasing transparency into how well artificial intelligence technology works. We hope this work encourages those releasing trained machine learning models to accompany model releases with similar detailed evaluation numbers and other relevant documentation.},
booktitle = {Proceedings of the Conference on Fairness, Accountability, and Transparency},
pages = {220–229},
numpages = {10},
keywords = {fairness evaluation, datasheets, ethical considerations, documentation, ML model evaluation, disaggregated evaluation, model cards},
location = {Atlanta, GA, USA},
series = {FAT* '19}
}

@inproceedings{10.1145/3290605.3300509,
author = {Yin, Ming and Wortman Vaughan, Jennifer and Wallach, Hanna},
title = {Understanding the Effect of Accuracy on Trust in Machine Learning Models},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300509},
doi = {10.1145/3290605.3300509},
abstract = {We address a relatively under-explored aspect of human-computer interaction: people's abilities to understand the relationship between a machine learning model's stated performance on held-out data and its expected performance post deployment. We conduct large-scale, randomized human-subject experiments to examine whether laypeople's trust in a model, measured in terms of both the frequency with which they revise their predictions to match those of the model and their self-reported levels of trust in the model, varies depending on the model's stated accuracy on held-out data and on its observed accuracy in practice. We find that people's trust in a model is affected by both its stated accuracy and its observed accuracy, and that the effect of stated accuracy can change depending on the observed accuracy. Our work relates to recent research on interpretable machine learning, but moves beyond the typical focus on model internals, exploring a different component of the machine learning pipeline.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {trust, machine learning, human-subject experiments},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.5555/3305381.3305576,
author = {Koh, Pang Wei and Liang, Percy},
title = {Understanding Black-Box Predictions via Influence Functions},
year = {2017},
publisher = {JMLR.org},
abstract = {How can we explain the predictions of a black-box model? In this paper, we use influence functions — a classic technique from robust statistics — to trace a model's prediction through the learning algorithm and back to its training data, thereby identifying training points most responsible for a given prediction. To scale up influence functions to modern machine learning settings, we develop a simple, efficient implementation that requires only oracle access to gradients and Hessian-vector products. We show that even on non-convex and non-differentiable models where the theory breaks down, approximations to influence functions can still provide valuable information. On linear models and convolutional neural networks, we demonstrate that influence functions are useful for multiple purposes: understanding model behavior, debugging models, detecting dataset errors, and even creating visually-indistinguishable training-set attacks.},
booktitle = {Proceedings of the 34th International Conference on Machine Learning - Volume 70},
pages = {1885–1894},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ICML'17}
}

@inproceedings{10.1145/2939672.2939778,
author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
title = {"Why Should I Trust You?": Explaining the Predictions of Any Classifier},
year = {2016},
isbn = {9781450342322},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2939672.2939778},
doi = {10.1145/2939672.2939778},
abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1135–1144},
numpages = {10},
keywords = {black box classifier, interpretable machine learning, interpretability, explaining machine learning},
location = {San Francisco, California, USA},
series = {KDD '16}
}

@article{Shakerin_Gupta_2019, title={Induction of Non-Monotonic Logic Programs to Explain Boosted Tree Models Using LIME}, volume={33}, url={https://ojs.aaai.org/index.php/AAAI/article/view/4163}, DOI={10.1609/aaai.v33i01.33013052}, abstractNote={&lt;p&gt;We present a heuristic based algorithm to induce &lt;em&gt;nonmonotonic&lt;/em&gt; logic programs that will explain the behavior of XGBoost trained classifiers. We use the technique based on the LIME approach to locally select the most important features contributing to the classification decision. Then, in order to explain the model’s global behavior, we propose the LIME-FOLD algorithm —a heuristic-based inductive logic programming (ILP) algorithm capable of learning nonmonotonic logic programs—that we apply to a transformed dataset produced by LIME. Our proposed approach is agnostic to the choice of the ILP algorithm. Our experiments with UCI standard benchmarks suggest a significant improvement in terms of classification evaluation metrics. Meanwhile, the number of induced rules dramatically decreases compared to ALEPH, a state-of-the-art ILP system.&lt;/p&gt;}, number={01}, journal={Proceedings of the AAAI Conference on Artificial Intelligence}, author={Shakerin, Farhad and Gupta, Gopal}, year={2019}, month={Jul.}, pages={3052-3059} }

@InProceedings{pmlr-v80-kim18d, title = {Interpretability Beyond Feature Attribution: Quantitative Testing with Concept Activation Vectors ({TCAV})}, author = {Kim, Been and Wattenberg, Martin and Gilmer, Justin and Cai, Carrie and Wexler, James and Viegas, Fernanda and sayres, Rory}, pages = {2668--2677}, year = {2018}, editor = {Jennifer Dy and Andreas Krause}, volume = {80}, booktitle = {Proceedings of Machine Learning Research}, series = {PMLR '18}, address = {Stockholmsmässan, Stockholm Sweden}, month = {10--15 Jul}, publisher = {PMLR}, pdf = {http://proceedings.mlr.press/v80/kim18d/kim18d.pdf}, url = {http://proceedings.mlr.press/v80/kim18d.html}, abstract = {The interpretation of deep learning models is a challenge due to their size, complexity, and often opaque internal state. In addition, many systems, such as image classifiers, operate on low-level features rather than high-level concepts. To address these challenges, we introduce Concept Activation Vectors (CAVs), which provide an interpretation of a neural net’s internal state in terms of human-friendly concepts. The key idea is to view the high-dimensional internal state of a neural net as an aid, not an obstacle. We show how to use CAVs as part of a technique, Testing with CAVs (TCAV), that uses directional derivatives to quantify the degree to which a user-defined concept is important to a classification result–for example, how sensitive a prediction of “zebra” is to the presence of stripes. Using the domain of image classification as a testing ground, we describe how CAVs may be used to explore hypotheses and generate insights for a standard image classification network as well as a medical application.} }

@inproceedings{10.1145/3173574.3174156,
author = {Abdul, Ashraf and Vermeulen, Jo and Wang, Danding and Lim, Brian Y. and Kankanhalli, Mohan},
title = {Trends and Trajectories for Explainable, Accountable and Intelligible Systems: An HCI Research Agenda},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3174156},
doi = {10.1145/3173574.3174156},
abstract = {Advances in artificial intelligence, sensors and big data management have far-reaching societal impacts. As these systems augment our everyday lives, it becomes increasing-ly important for people to understand them and remain in control. We investigate how HCI researchers can help to develop accountable systems by performing a literature analysis of 289 core papers on explanations and explaina-ble systems, as well as 12,412 citing papers. Using topic modeling, co-occurrence and network analysis, we mapped the research space from diverse domains, such as algorith-mic accountability, interpretable machine learning, context-awareness, cognitive psychology, and software learnability. We reveal fading and burgeoning trends in explainable systems, and identify domains that are closely connected or mostly isolated. The time is ripe for the HCI community to ensure that the powerful new autonomous systems have intelligible interfaces built-in. From our results, we propose several implications and directions for future research to-wards this goal.},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
pages = {1–18},
numpages = {18},
keywords = {explainable artificial intelli-gence, intelligibility, interpretable machine learning, explanations},
location = {Montreal QC, Canada},
series = {CHI '18}
}

@Inbook{Crabtree2020,
author="Crabtree, Andy
and Tolmie, Peter
and Chamberlain, Alan",
title="``Research in the Wild'': Approaches to Understanding the Unremarkable as a Resource for Design",
bookTitle="Into the Wild: Beyond the Design Research Lab",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="31--53",
abstract="This chapter outlines some key approaches towards understanding the unremarkable. It focuses first on a sociological orientation to the everyday world as key to the enterprise, and then on a variety of complimentary approaches for elaborating or surfacing the unremarkable character of everyday life. It considers the kinds of data resources that are routinely used to elaborate the unremarkable, and the relationship between data resource and analysis as a constituent element of working `in the wild'. We hope this will be a valuable resource for researchers and students alike.",
isbn="978-3-030-18020-1",
doi="10.1007/978-3-030-18020-1_3",
url="https://doi.org/10.1007/978-3-030-18020-1_3"
}

@article{10.1145/3359178,
author = {Schaekermann, Mike and Beaton, Graeme and Habib, Minahz and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Understanding Expert Disagreement in Medical Data Analysis through Structured Adjudication},
year = {2019},
issue_date = {November 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {CSCW},
url = {https://doi.org/10.1145/3359178},
doi = {10.1145/3359178},
abstract = {Expert disagreement is pervasive in clinical decision making and collective adjudication is a useful approach for resolving divergent assessments. Prior work shows that expert disagreement can arise due to diverse factors including expert background, the quality and presentation of data, and guideline clarity. In this work, we study how these factors predict initial discrepancies in the context of medical time series analysis, examining why certain disagreements persist after adjudication, and how adjudication impacts clinical decisions. Results from a case study with 36 experts and 4,543 adjudicated cases in a sleep stage classification task show that these factors contribute to both initial disagreement and resolvability, each in their own unique way. We provide evidence suggesting that structured adjudication can lead to significant revisions in treatment-relevant clinical parameters. Our work demonstrates how structured adjudication can support consensus and facilitate a deep understanding of expert disagreement in medical data analysis.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {76},
numpages = {23},
keywords = {adjudication, ambiguity, disagreement, medical time series}
}

@Misc{SchaekermannMike2020,
author={{Schaekermann, Mike}},
title={Human-AI Interaction in the Presence of Ambiguity: From Deliberation-based Labeling to Ambiguity-aware AI},
year={2020},
publisher="UWSpace",
url={http://hdl.handle.net/10012/16284}
}

@article{10.1167/tvst.8.6.40,
    author = {Schaekermann, Mike and Hammel, Naama and Terry, Michael and Ali, Tayyeba K. and Liu, Yun and Basham, Brian and Campana, Bilson and Chen, William and Ji, Xiang and Krause, Jonathan and Corrado, Greg S. and Peng, Lily and Webster, Dale R. and Law, Edith and Sayres, Rory},
    title = "{Remote Tool-Based Adjudication for Grading Diabetic Retinopathy}",
    journal = {Translational Vision Science \& Technology},
    volume = {8},
    number = {6},
    pages = {40-40},
    year = {2019},
    month = {12},
    abstract = "{   To present and evaluate a remote, tool-based system and structured grading rubric for adjudicating image-based diabetic retinopathy (DR) grades.    We compared three different procedures for adjudicating DR severity assessments among retina specialist panels, including (1) in-person adjudication based on a previously described procedure (Baseline), (2) remote, tool-based adjudication for assessing DR severity alone (TA), and (3) remote, tool-based adjudication using a feature-based rubric (TA-F). We developed a system allowing graders to review images remotely and asynchronously. For both TA and TA-F approaches, images with disagreement were reviewed by all graders in a round-robin fashion until disagreements were resolved. Five panels of three retina specialists each adjudicated a set of 499 retinal fundus images (1 panel using Baseline, 2 using TA, and 2 using TA-F adjudication). Reliability was measured as grade agreement among the panels using Cohen's quadratically weighted kappa. Efficiency was measured as the number of rounds needed to reach a consensus for tool-based adjudication.    The grades from remote, tool-based adjudication showed high agreement with the Baseline procedure, with Cohen's kappa scores of 0.948 and 0.943 for the two TA panels, and 0.921 and 0.963 for the two TA-F panels. Cases adjudicated using TA-F were resolved in fewer rounds compared with TA (P \\&lt; 0.001; standard permutation test).    Remote, tool-based adjudication presents a flexible and reliable alternative to in-person adjudication for DR diagnosis. Feature-based rubrics can help accelerate consensus for tool-based adjudication of DR without compromising label quality.    This approach can generate reference standards to validate automated methods, and resolve ambiguous diagnoses by integrating into existing telemedical workflows.  }",
    issn = {2164-2591},
    doi = {10.1167/tvst.8.6.40},
    url = {https://doi.org/10.1167/tvst.8.6.40},
    eprint = {https://arvojournals.org/arvo/content\_public/journal/tvst/938258/i2164-2591-8-6-40.pdf},
}

@article{MIRANDA2015334,
title = "Computer-aided diagnosis system based on fuzzy logic for breast cancer categorization",
journal = "Computers in Biology and Medicine",
volume = "64",
pages = "334 - 346",
year = "2015",
issn = "0010-4825",
doi = "https://doi.org/10.1016/j.compbiomed.2014.10.006",
url = "http://www.sciencedirect.com/science/article/pii/S0010482514002704",
author = "Gisele Helena Barboni Miranda and Joaquim Cezar Felipe",
keywords = "Computer-aided diagnosis, Breast cancer, Fuzzy logic, Decision support, Healthcare informatics",
abstract = "Background
Fuzzy logic can help reduce the difficulties faced by computational systems to represent and simulate the reasoning and the style adopted by radiologists in the process of medical image analysis. The study described in this paper consists of a new method that applies fuzzy logic concepts to improve the representation of features related to image description in order to make it semantically more consistent. Specifically, we have developed a computer-aided diagnosis tool for automatic BI-RADS categorization of breast lesions. The user provides parameters such as contour, shape and density and the system gives a suggestion about the BI-RADS classification.
Methods
Initially, values of malignancy were defined for each image descriptor, according to the BI-RADS standard. When analyzing contour, for example, our method considers the matching of features and linguistic variables. Next, we created the fuzzy inference system. The generation of membership functions was carried out by the Fuzzy Omega algorithm, which is based on the statistical analysis of the dataset. This algorithm maps the distribution of different classes in a set.
Results
Images were analyzed by a group of physicians and the resulting evaluations were submitted to the Fuzzy Omega algorithm. The results were compared, achieving an accuracy of 76.67% for nodules and 83.34% for calcifications.
Conclusions
The fit of definitions and linguistic rules to numerical models provided by our method can lead to a tighter connection between the specialist and the computer system, yielding more effective and reliable results."
}

@article{NIAZI2019e253,
title = "Digital pathology and artificial intelligence",
journal = "The Lancet Oncology",
volume = "20",
number = "5",
pages = "e253 - e261",
year = "2019",
issn = "1470-2045",
doi = "https://doi.org/10.1016/S1470-2045(19)30154-8",
url = "http://www.sciencedirect.com/science/article/pii/S1470204519301548",
author = "Muhammad Khalid Khan Niazi and Anil V Parwani and Metin N Gurcan",
abstract = "Summary
In modern clinical practice, digital pathology has a crucial role and is increasingly a technological requirement in the scientific laboratory environment. The advent of whole-slide imaging, availability of faster networks, and cheaper storage solutions has made it easier for pathologists to manage digital slide images and share them for clinical use. In parallel, unprecedented advances in machine learning have enabled the synergy of artificial intelligence and digital pathology, which offers image-based diagnosis possibilities that were once limited only to radiology and cardiology. Integration of digital slides into the pathology workflow, advanced algorithms, and computer-aided diagnostic techniques extend the frontiers of the pathologist's view beyond a microscopic slide and enable true utilisation and integration of knowledge that is beyond human limits and boundaries, and we believe there is clear potential for artificial intelligence breakthroughs in the pathology setting. In this Review, we discuss advancements in digital slide-based image diagnosis for cancer along with some challenges and opportunities for artificial intelligence in digital pathology."
}

@article{granzier2020mri,
  title={MRI-based radiomics in breast cancer: feature robustness with respect to inter-observer segmentation variability},
  author={Granzier, RWY and Verbakel, NMH and Ibrahim, A and van Timmeren, JE and van Nijnatten, TJA and Leijenaar, RTH and Lobbes, MBI and Smidt, ML and Woodruff, HC},
  journal={Scientific reports},
  volume={10},
  number={1},
  pages={1--11},
  year={2020},
  publisher={Nature Publishing Group}
}

@misc{raghu2019direct,
      title={Direct Uncertainty Prediction for Medical Second Opinions}, 
      author={Maithra Raghu and Katy Blumer and Rory Sayres and Ziad Obermeyer and Robert Kleinberg and Sendhil Mullainathan and Jon Kleinberg},
      year={2019},
      eprint={1807.01771},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@article{10.1145/3152889,
author = {Dumitrache, Anca and Aroyo, Lora and Welty, Chris},
title = {Crowdsourcing Ground Truth for Medical Relation Extraction},
year = {2018},
issue_date = {July 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3152889},
doi = {10.1145/3152889},
abstract = {Cognitive computing systems require human labeled data for evaluation and often for training. The standard practice used in gathering this data minimizes disagreement between annotators, and we have found this results in data that fails to account for the ambiguity inherent in language. We have proposed the CrowdTruth method for collecting ground truth through crowdsourcing, which reconsiders the role of people in machine learning based on the observation that disagreement between annotators provides a useful signal for phenomena such as ambiguity in the text. We report on using this method to build an annotated data set for medical relation extraction for the cause and treat relations, and how this data performed in a supervised training experiment. We demonstrate that by modeling ambiguity, labeled data gathered from crowd workers can (1) reach the level of quality of domain experts for this task while reducing the cost, and (2) provide better training data at scale than distant supervision. We further propose and validate new weighted measures for precision, recall, and F-measure, which account for ambiguity in both human and machine performance on this task.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jul,
articleno = {11},
numpages = {20},
keywords = {natural language ambiguity, Ground truth, relation extraction, clinical natural language processing, crowd truth, crowdtruth, inter-annotator disagreement}
}

@inproceedings{schaekermann2018expert,
  title={Expert Disagreement in Sequential Labeling: A Case Study on Adjudication in Medical Time Series Analysis.},
  author={Schaekermann, Mike and Law, Edith and Larson, Kate and Lim, Andrew},
  booktitle={SAD/CrowdBias@ HCOMP},
  pages={55--66},
  year={2018}
}

@inproceedings{10.1145/3308560.3317085,
author = {Schaekermann, Mike and Beaton, Graeme and Habib, Minahz and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Capturing Expert Arguments from Medical Adjudication Discussions in a Machine-Readable Format},
year = {2019},
isbn = {9781450366755},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308560.3317085},
doi = {10.1145/3308560.3317085},
abstract = {Group-based discussion among human graders can be a useful tool to capture sources of disagreement in ambiguous classification tasks and to adjudicate any resolvable disagreements. Existing workflows for panel-based adjudication, however, capture graders’ arguments and rationales in a free-form, unstructured format, limiting the potential for automatic analysis of the discussion contents. We designed and implemented a structured adjudication system that collects graders’ arguments in a machine-readable format without limiting graders’ abilities to provide free-form justifications for their classification decisions. Our system enables graders to cite instructions from a set of labeling guidelines, specified in the form of discrete classification rules and conditions that need to be met in order for each rule to be applicable. In the present work, we outline the process of designing and implementing this adjudication system, and report preliminary findings from deploying our system in the context of medical time series analysis for sleep stage classification.},
booktitle = {Companion Proceedings of The 2019 World Wide Web Conference},
pages = {1131–1137},
numpages = {7},
keywords = {Disagreement, Ambiguity, Adjudication, Medical time series},
location = {San Francisco, USA},
series = {WWW '19}
}

@inproceedings{10.1145/3313831.3376506,
author = {Schaekermann, Mike and Beaton, Graeme and Sanoubari, Elaheh and Lim, Andrew and Larson, Kate and Law, Edith},
title = {Ambiguity-Aware AI Assistants for Medical Data Analysis},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376506},
doi = {10.1145/3313831.3376506},
abstract = {Artificial intelligence (AI) assistants for clinical decision making show increasing promise in medicine. However, medical assessments can be contentious, leading to expert disagreement. This raises the question of how AI assistants should be designed to handle the classification of ambiguous cases. Our study compared two AI assistants that provide classification labels for medical time series data along with quantitative uncertainty estimates: conventional vs. ambiguity-aware. We simulated our ambiguity-aware AI based on real-world expert discussions to highlight cases likely to lead to expert disagreement, and to present arguments for conflicting classification choices. Our results demonstrate that ambiguity-aware AI can alter expert workflows by significantly increasing the proportion of contentious cases reviewed. We also found that the relevance of AI-provided arguments (selected from guidelines either randomly or by experts) affected experts' accuracy at revising AI-suggested labels. Our work contributes a novel perspective on the design of AI for contentious clinical assessments.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {artificial intelligence, medical data analysis, ambiguity},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@inproceedings{10.1145/3313831.3376590,
author = {Liao, Q. Vera and Gruen, Daniel and Miller, Sarah},
title = {Questioning the AI: Informing Design Practices for Explainable AI User Experiences},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376590},
doi = {10.1145/3313831.3376590},
abstract = {A surge of interest in explainable AI (XAI) has led to a vast collection of algorithmic work on the topic. While many recognize the necessity to incorporate explainability features in AI systems, how to address real-world user needs for understanding AI remains an open question. By interviewing 20 UX and design practitioners working on various AI products, we seek to identify gaps between the current XAI algorithmic work and practices to create explainable AI products. To do so, we develop an algorithm-informed XAI question bank in which user needs for explainability are represented as prototypical questions users might ask about the AI, and use it as a study probe. Our work contributes insights into the design space of XAI, informs efforts to support design practices in this space, and identifies opportunities for future XAI work. We also provide an extended XAI question bank and discuss how it can be used for creating user-centered XAI.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {human-AI interaction, explainable AI, user experience},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@InProceedings{pmlr-v97-raghu19a,
  title = 	 {Direct Uncertainty Prediction for Medical Second Opinions},
  author =       {Raghu, Maithra and Blumer, Katy and Sayres, Rory and Obermeyer, Ziad and Kleinberg, Bobby and Mullainathan, Sendhil and Kleinberg, Jon},
  booktitle = 	 {Proceedings of the 36th International Conference on Machine Learning},
  pages = 	 {5281--5290},
  year = 	 {2019},
  editor = 	 {Kamalika Chaudhuri and Ruslan Salakhutdinov},
  volume = 	 {97},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Long Beach, California, USA},
  month = 	 {09--15 Jun},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v97/raghu19a/raghu19a.pdf},
  url = 	 {http://proceedings.mlr.press/v97/raghu19a.html},
  abstract = 	 {The issue of disagreements amongst human experts is a ubiquitous one in both machine learning and medicine. In medicine, this often corresponds to doctor disagreements on a patient diagnosis. In this work, we show that machine learning models can be successfully trained to give uncertainty scores to data instances that result in high expert disagreements. In particular, they can identify patient cases that would benefit most from a medical second opinion. Our central methodological finding is that Direct Uncertainty Prediction (DUP), training a model to predict an uncertainty score directly from the raw patient features, works better than Uncertainty Via Classification, the two step process of training a classifier and postprocessing the output distribution to give an uncertainty score. We show this both with a theoretical result, and on extensive evaluations on a large scale medical imaging application.}
}

@article{10.1001/jamanetworkopen.2019.0096,
    author = {Barnett, Michael L. and Boddupalli, Dhruv and Nundy, Shantanu and Bates, David W.},
    title = "{Comparative Accuracy of Diagnosis by Collective Intelligence of Multiple Physicians vs Individual Physicians}",
    journal = {JAMA Network Open},
    volume = {2},
    number = {3},
    pages = {e190096-e190096},
    year = {2019},
    month = {03},
    abstract = "{The traditional approach of diagnosis by individual physicians has a high rate of misdiagnosis. Pooling multiple physicians’ diagnoses (collective intelligence) is a promising approach to reducing misdiagnoses, but its accuracy in clinical cases is unknown to date.To assess how the diagnostic accuracy of groups of physicians and trainees compares with the diagnostic accuracy of individual physicians.Cross-sectional study using data from the Human Diagnosis Project (Human Dx), a multicountry data set of ranked differential diagnoses by individual physicians, graduate trainees, and medical students (users) solving user-submitted, structured clinical cases. From May 7, 2014, to October 5, 2016, groups of 2 to 9 randomly selected physicians solved individual cases. Data analysis was performed from March 16, 2017, to July 30, 2018.The primary outcome was diagnostic accuracy, assessed as a correct diagnosis in the top 3 ranked diagnoses for an individual; for groups, the top 3 diagnoses were a collective differential generated using a weighted combination of user diagnoses with a variety of approaches. A version of the McNemar test was used to account for clustering across repeated solvers to compare diagnostic accuracy.Of the 2069 users solving 1572 cases from the Human Dx data set, 1228 (59.4\\%) were residents or fellows, 431 (20.8\\%) were attending physicians, and 410 (19.8\\%) were medical students. Collective intelligence was associated with increasing diagnostic accuracy, from 62.5\\% (95\\% CI, 60.1\\%-64.9\\%) for individual physicians up to 85.6\\% (95\\% CI, 83.9\\%-87.4\\%) for groups of 9 (23.0\\% difference; 95\\% CI, 14.9\\%-31.2\\%; P \\&lt; .001). The range of improvement varied by the specifications used for combining groups’ diagnoses, but groups consistently outperformed individuals regardless of approach. Absolute improvement in accuracy from individuals to groups of 9 varied by presenting symptom from an increase of 17.3\\% (95\\% CI, 6.4\\%-28.2\\%; P = .002) for abdominal pain to 29.8\\% (95\\% CI, 3.7\\%-55.8\\%; P = .02) for fever. Groups from 2 users (77.7\\% accuracy; 95\\% CI, 70.1\\%-84.6\\%) to 9 users (85.5\\% accuracy; 95\\% CI, 75.1\\%-95.9\\%) outperformed individual specialists in their subspecialty (66.3\\% accuracy; 95\\% CI, 59.1\\%-73.5\\%; P \\&lt; .001 vs groups of 2 and 9).A collective intelligence approach was associated with higher diagnostic accuracy compared with individuals, including individual specialists whose expertise matched the case diagnosis, across a range of medical cases. Given the few proven strategies to address misdiagnosis, this technique merits further study in clinical settings.}",
    issn = {2574-3805},
    doi = {10.1001/jamanetworkopen.2019.0096},
    url = {https://doi.org/10.1001/jamanetworkopen.2019.0096},
    eprint = {https://jamanetwork.com/journals/jamanetworkopen/articlepdf/2726709/barnett\_2019\_oi\_190011.pdf},
}

@inproceedings{10.1145/3290605.3300831,
author = {Wang, Danding and Yang, Qian and Abdul, Ashraf and Lim, Brian Y.},
title = {Designing Theory-Driven User-Centric Explainable AI},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300831},
doi = {10.1145/3290605.3300831},
abstract = {From healthcare to criminal justice, artificial intelligence (AI) is increasingly supporting high-consequence human decisions. This has spurred the field of explainable AI (XAI). This paper seeks to strengthen empirical application-specific investigations of XAI by exploring theoretical underpinnings of human decision making, drawing from the fields of philosophy and psychology. In this paper, we propose a conceptual framework for building human-centered, decision-theory-driven XAI based on an extensive review across these fields. Drawing on this framework, we identify pathways along which human cognitive patterns drives needs for building XAI and how XAI can mitigate common cognitive biases. We then put this framework into practice by designing and implementing an explainable clinical diagnostic tool for intensive care phenotyping and conducting a co-design exercise with clinicians. Thereafter, we draw insights into how this framework bridges algorithm-generated explanations and human decision-making theories. Finally, we discuss implications for XAI design and development.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–15},
numpages = {15},
keywords = {clinical decision making, explanations, explainable artificial intelligence, decision making, intelligibility},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@article{LIU2019e271,
title = "A comparison of deep learning performance against health-care professionals in detecting diseases from medical imaging: a systematic review and meta-analysis",
journal = "The Lancet Digital Health",
volume = "1",
number = "6",
pages = "e271 - e297",
year = "2019",
issn = "2589-7500",
doi = "https://doi.org/10.1016/S2589-7500(19)30123-2",
url = "http://www.sciencedirect.com/science/article/pii/S2589750019301232",
author = "Xiaoxuan Liu and Livia Faes and Aditya U Kale and Siegfried K Wagner and Dun Jack Fu and Alice Bruynseels and Thushika Mahendiran and Gabriella Moraes and Mohith Shamdas and Christoph Kern and Joseph R Ledsam and Martin K Schmid and Konstantinos Balaskas and Eric J Topol and Lucas M Bachmann and Pearse A Keane and Alastair K Denniston",
abstract = "Summary
Background
Deep learning offers considerable promise for medical diagnostics. We aimed to evaluate the diagnostic accuracy of deep learning algorithms versus health-care professionals in classifying diseases using medical imaging.
Methods
In this systematic review and meta-analysis, we searched Ovid-MEDLINE, Embase, Science Citation Index, and Conference Proceedings Citation Index for studies published from Jan 1, 2012, to June 6, 2019. Studies comparing the diagnostic performance of deep learning models and health-care professionals based on medical imaging, for any disease, were included. We excluded studies that used medical waveform data graphics material or investigated the accuracy of image segmentation rather than disease classification. We extracted binary diagnostic accuracy data and constructed contingency tables to derive the outcomes of interest: sensitivity and specificity. Studies undertaking an out-of-sample external validation were included in a meta-analysis, using a unified hierarchical model. This study is registered with PROSPERO, CRD42018091176.
Findings
Our search identified 31 587 studies, of which 82 (describing 147 patient cohorts) were included. 69 studies provided enough data to construct contingency tables, enabling calculation of test accuracy, with sensitivity ranging from 9·7% to 100·0% (mean 79·1%, SD 0·2) and specificity ranging from 38·9% to 100·0% (mean 88·3%, SD 0·1). An out-of-sample external validation was done in 25 studies, of which 14 made the comparison between deep learning models and health-care professionals in the same sample. Comparison of the performance between health-care professionals in these 14 studies, when restricting the analysis to the contingency table for each study reporting the highest accuracy, found a pooled sensitivity of 87·0% (95% CI 83·0–90·2) for deep learning models and 86·4% (79·9–91·0) for health-care professionals, and a pooled specificity of 92·5% (95% CI 85·1–96·4) for deep learning models and 90·5% (80·6–95·7) for health-care professionals.
Interpretation
Our review found the diagnostic performance of deep learning models to be equivalent to that of health-care professionals. However, a major finding of the review is that few studies presented externally validated results or compared the performance of deep learning models and health-care professionals using the same sample. Additionally, poor reporting is prevalent in deep learning studies, which limits reliable interpretation of the reported diagnostic accuracy. New reporting standards that address specific challenges of deep learning could improve future studies, enabling greater confidence in the results of future evaluations of this promising technology.
Funding
None."
}

@inproceedings{10.1145/3136755.3143016,
author = {Wang, Shuai and Wang, Wenxuan and Zhao, Jinming and Chen, Shizhe and Jin, Qin and Zhang, Shilei and Qin, Yong},
title = {Emotion Recognition with Multimodal Features and Temporal Models},
year = {2017},
isbn = {9781450355438},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3136755.3143016},
doi = {10.1145/3136755.3143016},
abstract = {This paper presents our methods to the Audio-Video Based Emotion Recognition subtask in the 2017 Emotion Recognition in the Wild (EmotiW) Challenge. The task aims to predict one of the seven basic emotions for short video segments. We extract different features from audio and facial expression modalities. We also explore the temporal LSTM model with the input of frame facial features, which improves the performance of the non-temporal model. The fusion of different modality features and the temporal model lead us to achieve a 58.5% accuracy on the testing set, which shows the effectiveness of our methods.},
booktitle = {Proceedings of the 19th ACM International Conference on Multimodal Interaction},
pages = {598–602},
numpages = {5},
keywords = {CNN, Multimodal Features, LSTM, Emotion Recognition},
location = {Glasgow, UK},
series = {ICMI '17}
}

@book{zheng2014marginal,
  title={Marginal space learning for medical image analysis},
  author={Zheng, Yefeng and Comaniciu, Dorin},
  year={2014},
  publisher={Springer}
}

@InProceedings{10.1007/978-3-030-00934-2_99,
author="Mehta, Sachin
and Mercan, Ezgi
and Bartlett, Jamen
and Weaver, Donald
and Elmore, Joann G.
and Shapiro, Linda",
editor="Frangi, Alejandro F.
and Schnabel, Julia A.
and Davatzikos, Christos
and Alberola-L{\'o}pez, Carlos
and Fichtinger, Gabor",
title="Y-Net: Joint Segmentation and Classification for Diagnosis of Breast Biopsy Images",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="893--901",
abstract="In this paper, we introduce a conceptually simple network for generating discriminative tissue-level segmentation masks for the purpose of breast cancer diagnosis. Our method efficiently segments different types of tissues in breast biopsy images while simultaneously predicting a discriminative map for identifying important areas in an image. Our network, Y-Net, extends and generalizes U-Net by adding a parallel branch for discriminative map generation and by supporting convolutional block modularity, which allows the user to adjust network efficiency without altering the network topology. Y-Net delivers state-of-the-art segmentation accuracy while learning {\$}{\$}6.6{\backslash}times {\$}{\$}fewer parameters than its closest competitors. The addition of descriptive power from Y-Net's discriminative segmentation masks improve diagnostic classification accuracy by 7{\%} over state-of-the-art methods for diagnostic classification. Source code is available at: https://sacmehta.github.io/YNet.",
isbn="978-3-030-00934-2"
}

@InProceedings{Hou_2016_CVPR,
author = {Hou, Le and Samaras, Dimitris and Kurc, Tahsin M. and Gao, Yi and Davis, James E. and Saltz, Joel H.},
title = {Patch-Based Convolutional Neural Network for Whole Slide Tissue Image Classification},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{shen2019deep,
  title={Deep learning to improve breast cancer detection on screening mammography},
  author={Shen, Li and Margolies, Laurie R and Rothstein, Joseph H and Fluder, Eugene and McBride, Russell and Sieh, Weiva},
  journal={Scientific reports},
  volume={9},
  number={1},
  pages={1--12},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{wang2018support,
  title={A support vector machine-based ensemble algorithm for breast cancer diagnosis},
  author={Wang, Haifeng and Zheng, Bichen and Yoon, Sang Won and Ko, Hoo Sang},
  journal={European Journal of Operational Research},
  volume={267},
  number={2},
  pages={687--699},
  year={2018},
  publisher={Elsevier}
}

@article{milosevic2017comparison,
  title={A comparison of methods for three-class mammograms classification},
  author={Milosevic, Marina and Jovanovic, Zeljko and Jankovic, Dragan},
  journal={Technology and Health Care},
  volume={25},
  number={4},
  pages={657--670},
  year={2017},
  publisher={IOS Press}
}

@ARTICLE{9247957,
  author={A. M. {Alhassan} and W. M. N. W. {Zainon}},
  journal={IEEE Access}, 
  title={BAT Algorithm With fuzzy C-Ordered Means (BAFCOM) Clustering Segmentation and Enhanced Capsule Networks (ECN) for Brain Cancer MRI Images Classification}, 
  year={2020},
  volume={8},
  number={},
  pages={201741-201751},
  doi={10.1109/ACCESS.2020.3035803}
}

@article{AGRAWAL201927,
title = "Combining clustering and classification ensembles: A novel pipeline to identify breast cancer profiles",
journal = "Artificial Intelligence in Medicine",
volume = "97",
pages = "27 - 37",
year = "2019",
issn = "0933-3657",
doi = "https://doi.org/10.1016/j.artmed.2019.05.002",
url = "http://www.sciencedirect.com/science/article/pii/S0933365717303913",
author = "Utkarsh Agrawal and Daniele Soria and Christian Wagner and Jonathan Garibaldi and Ian O. Ellis and John M.S. Bartlett and David Cameron and Emad A. Rakha and Andrew R. Green",
keywords = "Ensemble clustering, Ensemble classification, Class level fusion, Refining cluster results, Breast cancer, Pipeline",
abstract = "Breast Cancer is one of the most common causes of cancer death in women, representing a very complex disease with varied molecular alterations. To assist breast cancer prognosis, the classification of patients into biological groups is of great significance for treatment strategies. Recent studies have used an ensemble of multiple clustering algorithms to elucidate the most characteristic biological groups of breast cancer. However, the combination of various clustering methods resulted in a number of patients remaining unclustered. Therefore, a framework still needs to be developed which can assign as many unclustered (i.e. biologically diverse) patients to one of the identified groups in order to improve classification. Therefore, in this paper we develop a novel classification framework which introduces a new ensemble classification stage after the ensemble clustering stage to target the unclustered patients. Thus, a step-by-step pipeline is introduced which couples ensemble clustering with ensemble classification for the identification of core groups, data distribution in them and improvement in final classification results by targeting the unclustered data. The proposed pipeline is employed on a novel real world breast cancer dataset and subsequently its robustness and stability are examined by testing it on standard datasets. The results show that by using the presented framework, an improved classification is obtained. Finally, the results have been verified using statistical tests, visualisation techniques, cluster quality assessment and interpretation from clinical experts."
}

@INPROCEEDINGS{8451510,
  author={I. {Domingues} and P. H. {Abreu} and J. {Santos}},
  booktitle={2018 25th IEEE International Conference on Image Processing (ICIP)}, 
  title={Bi-Rads Classification of Breast Cancer: A New Pre-Processing Pipeline for Deep Models Training}, 
  year={2018},
  volume={},
  number={},
  pages={1378-1382},
  doi={10.1109/ICIP.2018.8451510}
}

@INPROCEEDINGS{8462671,
  author={N. {Wu} and K. J. {Geras} and Y. {Shen} and J. {Su} and S. G. {Kim} and E. {Kim} and S. {Wolfson} and L. {Moy} and K. {Cho}},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Breast Density Classification with Deep Convolutional Neural Networks}, 
  year={2018},
  volume={},
  number={},
  pages={6682-6686},
  doi={10.1109/ICASSP.2018.8462671}
}

@INPROCEEDINGS{8622433,
  author={B. {Kovalerchuk} and N. {Neuhaus}},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Toward Efficient Automation of Interpretable Machine Learning}, 
  year={2018},
  volume={},
  number={},
  pages={4940-4947},
  doi={10.1109/BigData.2018.8622433}
}

@article{ahmed2020images,
  title={Images data practices for Semantic Segmentation of Breast Cancer using Deep Neural Network},
  author={Ahmed, Luqman and Iqbal, Muhammad Munwar and Aldabbas, Hamza and Khalid, Shehzad and Saleem, Yasir and Saeed, Saqib},
  journal={Journal of Ambient Intelligence and Humanized Computing},
  pages={1--17},
  year={2020},
  publisher={Springer}
}

@article{murtaza2019deep,
  title={Deep learning-based breast cancer classification through medical imaging modalities: state of the art and research challenges},
  author={Murtaza, Ghulam and Shuib, Liyana and Wahab, Ainuddin and Mujtaba, Ghulam and Nweke, Henry Friday and Al-garadi, Mohammed Ali and Zulfiqar, Fariha and Raza, Ghulam and Azmi, Nor Aniza},
  journal={Artificial Intelligence Review},
  pages={1--66},
  year={2019},
  publisher={Springer}
}

@inproceedings{10.1145/3373017.3373051,
author = {Ke, Jing and Liu, Changchang and Lu, Yizhou and Jing, Naifeng and Liang, Xiaoyao and Jiang, Fusong},
title = {FIMIL: A High-Throughput Deep Learning Model for Abnormality Detection with Weak Annotation in Microscopy Images},
year = {2020},
isbn = {9781450376976},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3373017.3373051},
doi = {10.1145/3373017.3373051},
abstract = {Automatic computer-aided detection plays an important role in biomedical image analysis. Many studies have focused on weak supervised learning as annotation tasks are time-consuming and tedious. Compared with pixel-wise annotation by particular software on the scanned digital high-resolution images, an alternative method of marking out of suspicious regions on microscopy slides is significantly more convenient for pathologists. Additionally, with a focus on dysplasias in the central area, there is a high likelihood of the similar tissues to be found around in clusters. In this paper, for weak annotation on microscopy images, we propose an efficient Foveated Imaging based Multiple Instance Learning (FIMIL) framework to classify weakly-labeled microscopy images. The model also provides multi-scale algorithm for arbitrary image size, in which the patches with highest possibility to contain dysplasia are considered as ”fixation points” in the image. The developed model combines deep convolutional neural networks (CNNs) with multiple instance learning (MIL) for dysplasias detection with only image-level labeling. The benchmark tests are carried out on the marked regions of 40x magnified whole-slide cytology images and the normal/abnormal label and their corresponding possibilities are predicted. Evaluated on the real-life clinical data, our proposed model shows high accuracy and efficiency by weakly-supervised learning. 1},
booktitle = {Proceedings of the Australasian Computer Science Week Multiconference},
articleno = {34},
numpages = {6},
keywords = {microscopy image, multiple instance learning, performance acceleration, foveated imaging},
location = {Melbourne, VIC, Australia},
series = {ACSW '20}
}

@article{TAJBAKHSH2020101693,
title = "Embracing imperfect datasets: A review of deep learning solutions for medical image segmentation",
journal = "Medical Image Analysis",
volume = "63",
pages = "101693",
year = "2020",
issn = "1361-8415",
doi = "https://doi.org/10.1016/j.media.2020.101693",
author = "Nima Tajbakhsh and Laura Jeyaseelan and Qian Li and Jeffrey N. Chiang and Zhihao Wu and Xiaowei Ding",
keywords = "Medical image segmentation, Imperfect dataset, Scarce annotations, Noisy annotations, Unreliable annotations, Sparse annotations, And weak annotations",
abstract = "The medical imaging literature has witnessed remarkable progress in high-performing segmentation models based on convolutional neural networks. Despite the new performance highs, the recent advanced segmentation models still require large, representative, and high quality annotated datasets. However, rarely do we have a perfect training dataset, particularly in the field of medical imaging, where data and annotations are both expensive to acquire. Recently, a large body of research has studied the problem of medical image segmentation with imperfect datasets, tackling two major dataset limitations: scarce annotations where only limited annotated data is available for training, and weak annotations where the training data has only sparse annotations, noisy annotations, or image-level annotations. In this article, we provide a detailed review of the solutions above, summarizing both the technical novelties and empirical results. We further compare the benefits and requirements of the surveyed methodologies and provide our recommended solutions. We hope this survey article increases the community awareness of the techniques that are available to handle imperfect medical image segmentation datasets."
}

@InProceedings{10.1007/978-3-030-59719-1_44,
author="Zheng, Hao
and Zhuang, Zhiguo
and Qin, Yulei
and Gu, Yun
and Yang, Jie
and Yang, Guang-Zhong",
editor="Martel, Anne L.
and Abolmaesumi, Purang
and Stoyanov, Danail
and Mateus, Diana
and Zuluaga, Maria A.
and Zhou, S. Kevin
and Racoceanu, Daniel
and Joskowicz, Leo",
title="Weakly Supervised Deep Learning for Breast Cancer Segmentation with Coarse Annotations",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2020",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="450--459",
abstract="Cancer lesion segmentation plays a vital role in breast cancer diagnosis and treatment planning. As creating labels for large medical image datasets can be time-consuming, laborious and error prone, a framework is proposed in this paper by using coarse annotations generated from boundary scribbles for training deep convolutional neural networks. These coarse annotations include locations of lesions but are lack of accurate information about boundaries. To mitigate the negative impact of annotation errors, we propose an adaptive weighted constrained loss that can change the weight of the task-specific penalty term according to the learning process. To impose further supervision about the boundaries, uncertainty-based boundary maps are generated, which can provide better descriptions for the blurry boundaries. Validation on a dataset containing 154 MRI scans has shown an average Dice coefficient of {\$}{\$}82.25{\backslash}{\%}{\$}{\$}82.25{\%}, which is comparable to results from fine annotations, demonstrating the efficacy of the proposed approach.",
isbn="978-3-030-59719-1"
}

@article {Dabbous397,
	author = {Dabbous, Firas M. and Dolecek, Therese A. and Berbaum, Michael L. and Friedewald, Sarah M. and Summerfelt, Wm. Thomas and Hoskins, Kent and Rauscher, Garth H.},
	title = {Impact of a False-Positive Screening Mammogram on Subsequent Screening Behavior and Stage at Breast Cancer Diagnosis},
	volume = {26},
	number = {3},
	pages = {397--403},
	year = {2017},
	doi = {10.1158/1055-9965.EPI-16-0524},
	publisher = {American Association for Cancer Research},
	abstract = {Background: Experiencing a false positive (FP) screening mammogram is economically, physically, and emotionally burdensome, which may affect future screening behavior by delaying the next scheduled mammogram or by avoiding screening altogether. We sought to examine the impact of a FP screening mammogram on the subsequent screening mammography behavior.Methods: Delay in obtaining subsequent screening was defined as any mammogram performed more than 12 months from index mammogram. The Kaplan{\textendash}Meier (product limit) estimator and Cox proportional hazards model were used to estimate the unadjusted delay and the hazard ratio (HR) of delay of the subsequent screening mammogram within the next 36 months from the index mammogram date.Results: A total of 650,232 true negative (TN) and 90,918 FP mammograms from 261,767 women were included. The likelihood of a subsequent mammogram was higher in women experiencing a TN result than women experiencing a FP result (85.0\% vs. 77.9\%, P \&lt; 0.001). The median delay in returning to screening was higher for FP versus TN (13 months vs. 3 months, P \&lt; 0.001). Women with TN result were 36\% more likely to return to screening in the next 36 months compared with women with a FP result HR = 1.36 (95\% CI, 1.35{\textendash}1.37). Experiencing a FP mammogram increases the risk of late stage at diagnosis compared with prior TN mammogram (P \&lt; 0.001).Conclusions: Women with a FP mammogram were more likely to delay their subsequent screening compared with women with a TN mammogram.Impact: A prior FP experience may subsequently increase the 4-year cumulative risk of late stage at diagnosis. Cancer Epidemiol Biomarkers Prev; 26(3); 397{\textendash}403. {\textcopyright}2017 AACR.},
	issn = {1055-9965},
	URL = {https://cebp.aacrjournals.org/content/26/3/397},
	eprint = {https://cebp.aacrjournals.org/content/26/3/397.full.pdf},
	journal = {Cancer Epidemiology and Prevention Biomarkers}
}

@article{CHOUGRAD201819,
title = "Deep Convolutional Neural Networks for breast cancer screening",
journal = "Computer Methods and Programs in Biomedicine",
volume = "157",
pages = "19 - 30",
year = "2018",
issn = "0169-2607",
doi = "https://doi.org/10.1016/j.cmpb.2018.01.011",
url = "http://www.sciencedirect.com/science/article/pii/S0169260717301451",
author = "Hiba Chougrad and Hamid Zouaki and Omar Alheyane",
keywords = "Deep learning, Convolutional Neural Network, Transfer learning, Computer-aided Diagnosis, Breast cancer, Breast mass lesion classification",
abstract = "Background and objective
Radiologists often have a hard time classifying mammography mass lesions which leads to unnecessary breast biopsies to remove suspicions and this ends up adding exorbitant expenses to an already burdened patient and health care system.
Methods
In this paper we developed a Computer-aided Diagnosis (CAD) system based on deep Convolutional Neural Networks (CNN) that aims to help the radiologist classify mammography mass lesions. Deep learning usually requires large datasets to train networks of a certain depth from scratch. Transfer learning is an effective method to deal with relatively small datasets as in the case of medical images, although it can be tricky as we can easily start overfitting.
Results
In this work, we explore the importance of transfer learning and we experimentally determine the best fine-tuning strategy to adopt when training a CNN model. We were able to successfully fine-tune some of the recent, most powerful CNNs and achieved better results compared to other state-of-the-art methods which classified the same public datasets. For instance we achieved 97.35% accuracy and 0.98 AUC on the DDSM database, 95.50% accuracy and 0.97 AUC on the INbreast database and 96.67% accuracy and 0.96 AUC on the BCDR database. Furthermore, after pre-processing and normalizing all the extracted Regions of Interest (ROIs) from the full mammograms, we merged all the datasets to build one large set of images and used it to fine-tune our CNNs. The CNN model which achieved the best results, a 98.94% accuracy, was used as a baseline to build the Breast Cancer Screening Framework. To evaluate the proposed CAD system and its efficiency to classify new images, we tested it on an independent database (MIAS) and got 98.23% accuracy and 0.99 AUC.
Conclusion
The results obtained demonstrate that the proposed framework is performant and can indeed be used to predict if the mass lesions are benign or malignant."
}

@ARTICLE{8861376,
  author={N. {Wu} and J. {Phang} and J. {Park} and Y. {Shen} and Z. {Huang} and M. {Zorin} and S. {Jastrzebski} and T. {Fevry} and J. {Katsnelson} and E. {Kim} and S. {Wolfson} and U. {Parikh} and S. {Gaddam} and L. L. Y. {Lin} and K. {Ho} and J. D. {Weinstein} and B. {Reig} and Y. {Gao} and H. {Toth} and K. {Pysarenko} and A. {Lewin} and J. {Lee} and K. {Airola} and E. {Mema} and S. {Chung} and E. {Hwang} and N. {Samreen} and S. G. {Kim} and L. {Heacock} and L. {Moy} and K. {Cho} and K. J. {Geras}},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Deep Neural Networks Improve Radiologists' Performance in Breast Cancer Screening}, 
  year={2020},
  volume={39},
  number={4},
  pages={1184-1194},
  doi={10.1109/TMI.2019.2945514}
}

@ARTICLE{8032490,
  author={G. {Carneiro} and J. {Nascimento} and A. P. {Bradley}},
  journal={IEEE Transactions on Medical Imaging}, 
  title={Automated Analysis of Unregistered Multi-View Mammograms With Deep Learning}, 
  year={2017},
  volume={36},
  number={11},
  pages={2355-2365},
  doi={10.1109/TMI.2017.2751523}
}

@article{lee2017curated,
  title={A curated mammography data set for use in computer-aided detection and diagnosis research},
  author={Lee, Rebecca Sawyer and Gimenez, Francisco and Hoogi, Assaf and Miyake, Kanae Kawai and Gorovoy, Mia and Rubin, Daniel L},
  journal={Scientific data},
  volume={4},
  pages={170177},
  year={2017},
  publisher={Nature Publishing Group}
}

@article{10.1145/3079765,
author = {Riegler, Michael and Pogorelov, Konstantin and Eskeland, Sigrun Losada and Schmidt, Peter Thelin and Albisser, Zeno and Johansen, Dag and Griwodz, Carsten and Halvorsen, P\r{a}l and Lange, Thomas De},
title = {From Annotation to Computer-Aided Diagnosis: Detailed Evaluation of a Medical Multimedia System},
year = {2017},
issue_date = {August 2017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {3},
issn = {1551-6857},
url = {https://doi.org/10.1145/3079765},
doi = {10.1145/3079765},
abstract = {Holistic medical multimedia systems covering end-to-end functionality from data collection to aided diagnosis are highly needed, but rare. In many hospitals, the potential value of multimedia data collected through routine examinations is not recognized. Moreover, the availability of the data is limited, as the health care personnel may not have direct access to stored data. However, medical specialists interact with multimedia content daily through their everyday work and have an increasing interest in finding ways to use it to facilitate their work processes. In this article, we present a novel, holistic multimedia system aiming to tackle automatic analysis of video from gastrointestinal (GI) endoscopy. The proposed system comprises the whole pipeline, including data collection, processing, analysis, and visualization. It combines filters using machine learning, image recognition, and extraction of global and local image features. The novelty is primarily in this holistic approach and its real-time performance, where we automate a complete algorithmic GI screening process. We built the system in a modular way to make it easily extendable to analyze various abnormalities, and we made it efficient in order to run in real time. The conducted experimental evaluation proves that the detection and localization accuracy are comparable or even better than existing systems, but it is by far leading in terms of real-time performance and efficient resource consumption.},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = may,
articleno = {26},
numpages = {26},
keywords = {Medical multimedia system, evaluation, gastrointestinal tract}
}

@inproceedings{10.1145/3313831.3376219,
author = {Kaur, Harmanpreet and Nori, Harsha and Jenkins, Samuel and Caruana, Rich and Wallach, Hanna and Wortman Vaughan, Jennifer},
title = {Interpreting Interpretability: Understanding Data Scientists' Use of Interpretability Tools for Machine Learning},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376219},
doi = {10.1145/3313831.3376219},
abstract = {Machine learning (ML) models are now routinely deployed in domains ranging from criminal justice to healthcare. With this newfound ubiquity, ML has moved beyond academia and grown into an engineering discipline. To that end, interpretability tools have been designed to help data scientists and machine learning practitioners better understand how ML models work. However, there has been little evaluation of the extent to which these tools achieve this goal. We study data scientists' use of two existing interpretability tools, the InterpretML implementation of GAMs and the SHAP Python package. We conduct a contextual inquiry (N=11) and a survey (N=197) of data scientists to observe how they use interpretability tools to uncover common issues that arise when building and evaluating ML models. Our results indicate that data scientists over-trust and misuse interpretability tools. Furthermore, few of our participants were able to accurately describe the visualizations output by these tools. We highlight qualitative themes for data scientists' mental models of interpretability tools. We conclude with implications for researchers and tool designers, and contextualize our findings in the social science literature.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {interpretability, user-centric evaluation, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{doi:10.1148/radiol.2016150409,
author = {Kelly, Brendan S. and Rainford, Louise A. and Darcy, Sarah P. and Kavanagh, Eoin C. and Toomey, Rachel J.},
title = {The Development of Expertise in Radiology: In Chest Radiograph Interpretation, "Expert" Search Pattern May Predate "Expert" Levels of Diagnostic Accuracy for Pneumothorax Identification},
journal = {Radiology},
volume = {280},
number = {1},
pages = {252-260},
year = {2016},
doi = {10.1148/radiol.2016150409},
note ={PMID: 27322975},
URL = {https://doi.org/10.1148/radiol.2016150409},
eprint = {https://doi.org/10.1148/radiol.2016150409}
}

@article{wei2019medical,
  title={Medical Hyperspectral Image Classification Based on End-to-End Fusion Deep Neural Network},
  author={Wei, Xueling and Li, Wei and Zhang, Mengmeng and Li, Qingli},
  journal={IEEE Transactions on Instrumentation and Measurement},
  year={2019},
  publisher={IEEE}
}

@article{liu2019sdfn,
  title={SDFN: Segmentation-based Deep Fusion Network for Thoracic Disease Classification in Chest X-ray Images},
  author={Liu, Han and Wang, Lei and Nan, Yandong and Jin, Faguang and Wang, Qi and Pu, Jiantao},
  journal={Computerized Medical Imaging and Graphics},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{zhao2019data,
  title={Data augmentation using learned transformations for one-shot medical image segmentation},
  author={Zhao, Amy and Balakrishnan, Guha and Durand, Fredo and Guttag, John V and Dalca, Adrian V},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={8543--8553},
  year={2019}
}

@inproceedings{zhou2019collaborative,
  title={Collaborative Learning of Semi-Supervised Segmentation and Classification for Medical Images},
  author={Zhou, Yi and He, Xiaodong and Huang, Lei and Liu, Li and Zhu, Fan and Cui, Shanshan and Shao, Ling},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={2079--2088},
  year={2019}
}

@article{philbrick2019ril,
  title={RIL-Contour: a Medical Imaging Dataset Annotation Tool for and with Deep Learning},
  author={Philbrick, Kenneth A and Weston, Alexander D and Akkus, Zeynettin and Kline, Timothy L and Korfiatis, Panagiotis and Sakinis, Tomas and Kostandy, Petro and Boonrod, Arunnit and Zeinoddini, Atefeh and Takahashi, Naoki and others},
  journal={Journal of digital imaging},
  pages={1--11},
  year={2019},
  publisher={Springer}
}

@article{soffer2019convolutional,
  title={Convolutional neural networks for radiologic images: a radiologist’s guide},
  author={Soffer, Shelly and Ben-Cohen, Avi and Shimon, Orit and Amitai, Michal Marianne and Greenspan, Hayit and Klang, Eyal},
  journal={Radiology},
  volume={290},
  number={3},
  pages={590--606},
  year={2019},
  publisher={Radiological Society of North America}
}

@article{gotz2019mitk,
  title={MITK Phenotyping: An open-source toolchain for image-based personalized medicine with radiomics},
  author={G{\"o}tz, Michael and Nolden, Marco and Maier-Hein, Klaus},
  journal={Radiotherapy and Oncology},
  volume={131},
  pages={108--111},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{wels2019general,
  title={General purpose radiomics for multi-modal clinical research},
  author={Wels, M. G and Lades, F. and Muehlberg, A. and Suehling, M.},
  booktitle={Medical Imaging 2019: Computer-Aided Diagnosis},
  volume={10950},
  pages={1095046},
  year={2019},
  organization={Intern. Soc. for Optics and Photonics}
}

@article{smailagic2019medal,
  title={O-MedAL: Online Active Deep Learning for Medical Image Analysis},
  author={Smailagic, Asim and Costa, Pedro and Gaudio, Alex and Khandelwal, Kartik and Mirshekari, Mostafa and Fagert, Jonathon and Walawalkar, Devesh and Xu, Susu and Galdran, Adrian and Zhang, Pei and others},
  journal={arXiv preprint arXiv:1908.10508},
  year={2019}
}

@article{KOUROU20158,
title = "Machine learning applications in cancer prognosis and prediction",
journal = "Computational and Structural Biotechnology Journal",
volume = "13",
pages = "8 - 17",
year = "2015",
issn = "2001-0370",
doi = "https://doi.org/10.1016/j.csbj.2014.11.005",
url = "http://www.sciencedirect.com/science/article/pii/S2001037014000464",
author = "Konstantina Kourou and Themis P. Exarchos and Konstantinos P. Exarchos and Michalis V. Karamouzis and Dimitrios I. Fotiadis",
keywords = "Machine learning, Cancer susceptibility, Predictive models, Cancer recurrence, Cancer survival",
abstract = "Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of ML methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent ML approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised ML techniques as well as on different input features and data samples. Given the growing trend on the application of ML methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes."
}

@article{antonanzas2015some,
  title={Some economics on personalized and predictive medicine},
  author={Anto{\~n}anzas, F and Ju{\'a}rez-Castell{\'o}, CA and Rodr{\'\i}guez-Ibeas, R},
  journal={The European journal of health economics},
  volume={16},
  number={9},
  pages={985--994},
  year={2015},
  publisher={Springer}
}

@article{hood2011predictive,
  title={Predictive, personalized, preventive, participatory (P4) cancer medicine},
  author={Hood, Leroy and Friend, Stephen H},
  journal={Nature reviews Clinical oncology},
  volume={8},
  number={3},
  pages={184--187},
  year={2011},
  publisher={Nature Publishing Group}
}

@inproceedings{10.1145/3313831.3376710,
author = {Laschke, Matthias and Braun, Christoph and Neuhaus, Robin and Hassenzahl, Marc},
title = {Meaningful Technology at Work - A Reflective Design Case of Improving Radiologists' Wellbeing Through Medical Technology},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376710},
doi = {10.1145/3313831.3376710},
abstract = {In radiology, medical technology providers (MTP) focus mainly on technology-related issues, such as image quality or efficiency of reporting. Broader notions of radiology as "meaningful work" are largely seen as out of scope for an MTP. The present paper challenges this. In a real-world case with a large MTP, we showed that medical technology could be designed more holistically to explicitly improve radiologists' wellbeing. We first gathered work practices experienced as especially conducive to wellbeing. From there, we distilled ideal practices to increase wellbeing and turned them into two software applications. The MTP's initial skepticism dissolved, while radiologists unanimously emphasized wellbeing and demonstrated how they work towards improving it. Based on our insights, the applications resonated well among the radiologists involved, the healthcare provider, and other customers of the MTP. We close with a critical reflection of the challenges and opportunities of designing wellbeing-driven technology in the work domain.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {job design, wellbeing-driven design, technology at work, practice-based},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{JALALIAN2013420,
title = "Computer-aided detection/diagnosis of breast cancer in mammography and ultrasound: a review",
journal = "Clinical Imaging",
volume = "37",
number = "3",
pages = "420 - 426",
year = "2013",
issn = "0899-7071",
doi = "https://doi.org/10.1016/j.clinimag.2012.09.024",
url = "http://www.sciencedirect.com/science/article/pii/S0899707112002938",
author = "Afsaneh Jalalian and Syamsiah B.T. Mashohor and Hajjah Rozi Mahmud and M. Iqbal B. Saripan and Abdul Rahman B. Ramli and Babak Karasfi",
keywords = "Computer-aided detection, Computer-aided diagnosis, Breast cancer, Mammography, Ultrasound",
abstract = "Breast cancer is the most common form of cancer among women worldwide. Early detection of breast cancer can increase treatment options and patients' survivability. Mammography is the gold standard for breast imaging and cancer detection. However, due to some limitations of this modality such as low sensitivity especially in dense breasts, other modalities like ultrasound and magnetic resonance imaging are often suggested to achieve additional information. Recently, computer-aided detection or diagnosis (CAD) systems have been developed to help radiologists in order to increase diagnosis accuracy. Generally, a CAD system consists of four stages: (a) preprocessing, (b) segmentation of regions of interest, (c) feature extraction and selection, and finally (d) classification. This paper presents the approaches which are applied to develop CAD systems on mammography and ultrasound images. The performance evaluation metrics of CAD systems are also reviewed."
}

@InProceedings{10.1007/978-3-319-59050-9_28,
author="Li, Wenqi
and Wang, Guotai
and Fidon, Lucas
and Ourselin, Sebastien
and Cardoso, M. Jorge
and Vercauteren, Tom",
editor="Niethammer, Marc
and Styner, Martin
and Aylward, Stephen
and Zhu, Hongtu
and Oguz, Ipek
and Yap, Pew-Thian
and Shen, Dinggang",
title="On the Compactness, Efficiency, and Representation of 3D Convolutional Networks: Brain Parcellation as a Pretext Task",
booktitle="Information Processing in Medical Imaging",
year="2017",
publisher="Springer International Publishing",
address="Cham",
pages="348--360",
abstract="Deep convolutional neural networks are powerful tools for learning visual representations from images. However, designing efficient deep architectures to analyse volumetric medical images remains challenging. This work investigates efficient and flexible elements of modern convolutional networks such as dilated convolution and residual connection. With these essential building blocks, we propose a high-resolution, compact convolutional network for volumetric image segmentation. To illustrate its efficiency of learning 3D representation from large-scale image data, the proposed network is validated with the challenging task of parcellating 155 neuroanatomical structures from brain MR images. Our experiments show that the proposed network architecture compares favourably with state-of-the-art volumetric segmentation networks while being an order of magnitude more compact. We consider the brain parcellation task as a pretext task for volumetric image segmentation; our trained network potentially provides a good starting point for transfer learning. Additionally, we show the feasibility of voxel-level uncertainty estimation using a sampling approximation through dropout.",
isbn="978-3-319-59050-9"
}

@article{urban2017lesiontracker,
  title={LesionTracker: Extensible open-source zero-footprint web viewer for cancer imaging research and clinical trials},
  author={Urban, Trinity and Ziegler, Erik and Lewis, Rob and Hafey, Chris and Sadow, Cheryl and Van den Abbeele, Annick D and Harris, Gordon J},
  journal={Cancer research},
  volume={77},
  number={21},
  pages={e119--e122},
  year={2017},
  publisher={AACR}
}

@Article{Jodogne2018,
  author="Jodogne, S{\'e}bastien",
  title="The {O}rthanc Ecosystem for Medical Imaging",
  journal="Journal of Digital Imaging",
  year="2018",
  month="Jun",
  day="01",
  volume="31",
  number="3",
  pages="341--352",
  issn="1618-727X",
  doi="10.1007/s10278-018-0082-y",
  url="https://doi.org/10.1007/s10278-018-0082-y"
}

@inproceedings{6556444,
author={S. {Jodogne} and C. {Bernard} and M. {Devillers} and E. {Lenaerts} and P. {Coucke}},
booktitle={2013 IEEE 10th International Symposium on Biomedical Imaging},
title={Orthanc - A lightweight, restful DICOM server for healthcare and medical research},
year={2013},
volume={},
number={},
pages={190-193},
abstract={Is this paper, the Orthanc open-source software is introduced. Orthanc is a lightweight, yet powerful standalone DICOM store for healthcare and medical research. Multiple instances of Orthanc can easily be deployed in the hospital network or even in the same computer, which simplifies the interconnection between the DICOM modalities and the data management of medical images. Orthanc is unique with respect to the fact that it provides a modern RESTful API: Orthanc can be driven from any computer language to automate clinical processes. Finally, Orthanc comes bundled with an embedded Web interface that allows the end-users to browse and interact with the content of the DICOM store.},
keywords={application program interfaces;embedded systems;graphical user interfaces;health care;Internet;medical computing;public domain software;Orthanc open-source software;DICOM server;healthcare;medical research;RESTful API;RESTful Application Programming Interface;DICOM modalities;data management;medical images;embedded Web interface;DICOM store;DICOM;Hospitals;Computers;Servers;Software;Protocols;DICOM Store;Scripting;REST},
doi={10.1109/ISBI.2013.6556444},
ISSN={1945-8452},
month={April},}

@article{HOSTETTER2018811,
title = "Integration of a Zero-footprint Cloud-based Picture Archiving and Communication System with Customizable Forms for Radiology Research and Education",
journal = "Academic Radiology",
volume = "25",
number = "6",
pages = "811 - 818",
year = "2018",
note = "Education Issue",
issn = "1076-6332",
doi = "https://doi.org/10.1016/j.acra.2018.01.031",
url = "http://www.sciencedirect.com/science/article/pii/S1076633218300710",
author = "Jason Hostetter and Nishanth Khanna and Jacob C. Mandell",
keywords = "Cloud-based PACS, web-based forms, educational case file, multireader study",
abstract = "Rationale and Objectives
The purpose of this study was to integrate web-based forms with a zero-footprint cloud-based Picture Archiving and Communication Systems (PACS) to create a tool of potential benefit to radiology research and education.
Materials and Methods
Web-based forms were created with a front-end and back-end architecture utilizing common programming languages including Vue.js, Node.js and MongoDB, and integrated into an existing zero-footprint cloud-based PACS.
Results
The web-based forms application can be accessed in any modern internet browser on desktop or mobile devices and allows the creation of customizable forms consisting of a variety of questions types. Each form can be linked to an individual DICOM examination or a collection of DICOM examinations.
Conclusions
Several uses are demonstrated through a series of case studies, including implementation of a research platform for multi-reader multi-case (MRMC) studies and other imaging research, and creation of an online Objective Structure Clinical Examination (OSCE) and an educational case file."
}

@inproceedings{10.1117/12.2513004,
author = {A. Sedghi and S. Hamidi and A. Mehrtash and E. Ziegler and C. Tempany and S. Pieper and T.  Kapur and P. Mousavi},
title = {{Tesseract-medical imaging: open-source browser-based platform for artificial intelligence deployment in medical imaging}},
volume = {10951},
booktitle = {Medical Imaging 2019: Image-Guided Procedures, Robotic Interventions, and Modeling},
editor = {B. Fei and C. A. Linte},
organization = {Intern. Soc. for Optics and Photonics},
publisher = {SPIE},
pages = {446 -- 451},
abstract = {Artificial Intelligence (AI) is increasingly becoming a tool to enhance various medical image analysis tasks with accuracies comparable to expert clinicians. Computer assisted detection and diagnosis, and image segmentation and registration have significantly benefited from AI. However, integration of AI into the clinical workflow has been slow due to requirements for libraries that are specific to each model, and also environments that are specific to clinical centers. These challenges demonstrate the need for an AI-based solution that can be integrated into any environment with minimum hardware and software overhead. Tesseract-Medical Imaging (Tesseract-MI) is an open-source, web-based platform which enables deployment of AI models while simultaneously providing standard image viewing and reporting schemes. The goal of Tesseract-MI is to augment 3D medical imaging and provide a 4<sup>th</sup> dimension (AI) when requested by a user. As a case study, we demonstrate the utility of our platform and present ProstateCancer.ai, a web application for identification of clinically significant prostate cancer in MRI.},
keywords = {Artificial Intelligence, Deployment , Clinical workflow, Integration, Deep learning, Platform, Viewer, Prostate Cancer},
year = {2019},
doi = {10.1117/12.2513004},
URL = {https://doi.org/10.1117/12.2513004}
}

@article{vayena2018machine,
  title={Machine learning in medicine: addressing ethical challenges},
  author={Vayena, Effy and Blasimme, Alessandro and Cohen, I Glenn},
  journal={PLoS medicine},
  volume={15},
  number={11},
  year={2018},
  publisher={Public Library of Science}
}

@article{ghahramani2015probabilistic,
  title={Probabilistic machine learning and artificial intelligence},
  author={Ghahramani, Zoubin},
  journal={Nature},
  volume={521},
  number={7553},
  pages={452--459},
  year={2015},
  publisher={Nature Publishing Group}
}

@article{choy2018current,
  title={Current applications and future impact of machine learning in radiology},
  author={Choy, Garry and Khalilzadeh, Omid and Michalski, Mark and Do, Synho and Samir, Anthony E and Pianykh, Oleg S and Geis, J Raymond and Pandharipande, Pari V and Brink, James A and Dreyer, Keith J},
  journal={Radiology},
  volume={288},
  number={2},
  pages={318--328},
  year={2018},
  publisher={Radiological Society of North America}
}

@article{hosny2018artificial,
  title={Artificial intelligence in radiology},
  author={Hosny, Ahmed and Parmar, Chintan and Quackenbush, John and Schwartz, Lawrence H and Aerts, Hugo JWL},
  journal={Nature Reviews Cancer},
  volume={18},
  number={8},
  pages={500},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{kooi2017large,
  title={Large scale deep learning for computer aided detection of mammographic lesions},
  author={Kooi, Thijs and Litjens, Geert and Van Ginneken, Bram and Gubern-M{\'e}rida, Albert and S{\'a}nchez, Clara I and Mann, Ritse and den Heeten, Ard and Karssemeijer, Nico},
  journal={Medical image analysis},
  volume={35},
  pages={303--312},
  year={2017},
  publisher={Elsevier}
}

@article{graffy2019automated,
  title={Automated segmentation and quantification of aortic calcification at abdominal CT: application of a deep learning-based algorithm to a longitudinal screening cohort},
  author={Graffy, Peter M and Liu, Jiamin and O’Connor, Stacy and Summers, Ronald M and Pickhardt, Perry J},
  journal={Abdominal Radiology},
  pages={1--8},
  year={2019},
  publisher={Springer}
}

@article{lakhani2017deep,
  title={Deep learning at chest radiography: automated classification of pulmonary tuberculosis by using convolutional neural networks},
  author={Lakhani, Paras and Sundaram, Baskaran},
  journal={Radiology},
  volume={284},
  number={2},
  pages={574--582},
  year={2017},
  publisher={Radiological Society of North America}
}

@article{liang2019deep,
  title={Deep-learning-based detection and segmentation of organs at risk in nasopharyngeal carcinoma computed tomographic images for radiotherapy planning},
  author={Liang, Shujun and Tang, Fan and Huang, Xia and Yang, Kaifan and Zhong, Tao and Hu, Runyue and Liu, Shangqing and Yuan, Xinrui and Zhang, Yu},
  journal={European Radiology},
  volume={29},
  number={4},
  pages={1961--1967},
  year={2019},
  publisher={Springer}
}

@Article{MAICAS2019101562,
  author    = {Gabriel Maicas and Andrew P. Bradley and Jacinto C. Nascimento and Ian Reid and Gustavo Carneiro},
  title     = {Pre and post-hoc diagnosis and interpretation of malignancy from breast DCE-MRI},
  doi       = {https://doi.org/10.1016/j.media.2019.101562},
  issn      = {1361-8415},
  pages     = {101562},
  url       = {http://www.sciencedirect.com/science/article/pii/S1361841518306893},
  volume    = {58},
  abstract  = {We propose a new method for breast cancer screening from DCE-MRI based on a post-hoc approach that is trained using weakly annotated data (i.e., labels are available only at the image level without any lesion delineation). Our proposed post-hoc method automatically diagnosis the whole volume and, for positive cases, it localizes the malignant lesions that led to such diagnosis. Conversely, traditional approaches follow a pre-hoc approach that initially localises suspicious areas that are subsequently classified to establish the breast malignancy – this approach is trained using strongly annotated data (i.e., it needs a delineation and classification of all lesions in an image). We also aim to establish the advantages and disadvantages of both approaches when applied to breast screening from DCE-MRI. Relying on experiments on a breast DCE-MRI dataset that contains scans of 117 patients, our results show that the post-hoc method is more accurate for diagnosing the whole volume per patient, achieving an AUC of 0.91, while the pre-hoc method achieves an AUC of 0.81. However, the performance for localising the malignant lesions remains challenging for the post-hoc method due to the weakly labelled dataset employed during training.},
  journal   = {Medical Image Analysis},
  keywords  = {Magnetic resonance imaging, Breast screening, Meta-learning, Few-shot learning, Weakly supervised learning, Strongly supervised learning, Model interpretation, Lesion detection, Deep reinforcement learning},
  publisher = {Elsevier},
  year      = {2019},
}

@article{Ruddle:2016:DEI:2872314.2834117,
 author = {Ruddle, Roy A. and Thomas, Rhys G. and Randell, Rebecca and Quirke, Philip and Treanor, Darren},
 title = {The Design and Evaluation of Interfaces for Navigating Gigapixel Images in Digital Pathology},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {February 2016},
 volume = {23},
 number = {1},
 month = jan,
 year = {2016},
 issn = {1073-0516},
 pages = {5:1--5:29},
 articleno = {5},
 numpages = {29},
 url = {http://doi.acm.org/10.1145/2834117},
 doi = {10.1145/2834117},
 acmid = {2834117},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Gigapixel images, navigation, overview+detail, pathology, zoomable user interface},
}

@article{Park:2015:TOA:2737795.2656213,
 author = {Park, Sun Young and Chen, Yunan and Rudkin, Scott},
 title = {Technological and Organizational Adaptation of EMR Implementation in an Emergency Department},
 journal = {ACM Transactions on Computer-Human Interaction},
 issue_date = {March 2015},
 volume = {22},
 number = {1},
 month = feb,
 year = {2015},
 issn = {1073-0516},
 pages = {1:1--1:24},
 articleno = {1},
 numpages = {24},
 url = {http://doi.acm.org/10.1145/2656213},
 doi = {10.1145/2656213},
 acmid = {2656213},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Electronic Medical Record (EMR), adaptation, clinical practices, design, implementations, workaround},
}

@article{aerts2017data,
  title={{Data science in radiology: a path forward}},
  author={Aerts, Hugo JWL},
  journal={Clinical Cancer Research},
  pages={2804},
  year={2017},
  publisher={AACR},
  number={3},
  volume={24}
}

@article{ker2018deep,
  title={{Deep learning applications in medical image analysis}},
  author={Ker, Justin and Wang, Lipo and Rao, Jai and Lim, Tchoyoson},
  journal={Access},
  volume={6},
  pages={9375--9389},
  year={2018},
  publisher={IEEE}
}

@inproceedings{Sultanum:2018:MTP:3173574.3173996,
 author={Sultanum, Nicole and Brudno, Michael and Wigdor, Daniel and Chevalier, Fanny},
 title={{More Text Please! Understanding and Supporting the Use of Visualization for Clinical Text Overview}},
 booktitle={Conf. Human Factors in Computing Systems (CHI)},
 year={2018},
 pages={1--13},
 volume={422},
 doi={10.1145/3173574.3173996},
 publisher={ACM},
 address={New York, NY, USA},
}

@article{desantis2016breast,
  title={Breast cancer statistics, 2015: Convergence of incidence rates between black and white women},
  author={DeSantis, Carol E and Fedewa, Stacey A and Goding Sauer, Ann and Kramer, Joan L and Smith, Robert A and Jemal, Ahmedin},
  journal={CA: a cancer journal for clinicians},
  volume={66},
  number={1},
  pages={31--42},
  year={2016},
  publisher={Wiley Online Library}
}

@article{torre2015global,
  title={Global cancer statistics, 2012},
  author={Torre, Lindsey A and Bray, Freddie and Siegel, Rebecca L and Ferlay, Jacques and Lortet-Tieulent, Joannie and Jemal, Ahmedin},
  journal={CA: a cancer journal for clinicians},
  volume={65},
  number={2},
  pages={87--108},
  year={2015},
  publisher={Wiley Online Library}
}

@article{welch2016breast,
  title={Breast-cancer tumor size, overdiagnosis, and mammography screening effectiveness},
  author={Welch, H Gilbert and Prorok, Philip C and O’Malley, A James and Kramer, Barnett S},
  journal={New England Journal of Medicine},
  volume={375},
  number={15},
  pages={1438--1447},
  year={2016},
  publisher={Mass Medical Soc}
}

@article{saadatmand2015influence,
  title={Influence of tumour stage at breast cancer detection on survival in modern times: population based study in 173 797 patients},
  author={Saadatmand, Sepideh and Bretveld, Reini and Siesling, Sabine and Tilanus-Linthorst, Madeleine MA},
  journal={Bmj},
  volume={351},
  pages={h4901},
  year={2015},
  publisher={British Medical Journal Publishing Group}
}

@article{Lim:2019:DDI:3319806.3301427,
 author = {Lim, Bohyeon and Rogers, Yvonne and Sebire, Neil},
 title = {Designing to Distract: Can Interactive Technologies Reduce Visitor Anxiety in a Children's Hospital Setting?},
 journal = {ACM Trans. Comput.-Hum. Interact.},
 issue_date = {April 2019},
 volume = {26},
 number = {2},
 month = apr,
 year = {2019},
 issn = {1073-0516},
 pages = {9:1--9:19},
 articleno = {9},
 numpages = {19},
 url = {http://doi.acm.org/10.1145/3301427},
 doi = {10.1145/3301427},
 acmid = {3301427},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {Children's hospital, Distraction principle, Interactive floor displays, Public displays, Reception area},
}

@article{shin2016deep,
  title={Deep convolutional neural networks for computer-aided detection: CNN architectures, dataset characteristics and transfer learning},
  author={Shin, Hoo-Chang and Roth, Holger R and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M},
  journal={IEEE transactions on medical imaging},
  volume={35},
  number={5},
  pages={1285--1298},
  year={2016},
  publisher={IEEE}
}

@article{carneiro2017automated,
  title={{Automated Analysis of Unregistered Multi-View Mammograms With Deep Learning}},
  author={Carneiro, Gustavo and Nascimento, Jacinto and Bradley, Andrew P},
  journal={Transactions on Medical Imaging},
  volume={36},
  number={11},
  pages={2355--2365},
  year={2017},
  publisher={IEEE}
}

@article{wang2016discrimination,
  title={Discrimination of breast cancer with microcalcifications on mammography by deep learning},
  author={Wang, Jinhua and Yang, Xi and Cai, Hongmin and Tan, Wanchang and Jin, Cangzheng and Li, Li},
  journal={Scientific reports},
  volume={6},
  pages={27327},
  year={2016},
  publisher={Nature Publishing Group}
}

@article{becker2017deep,
  title={Deep learning in mammography: diagnostic accuracy of a multipurpose image analysis software in the detection of breast cancer},
  author={Becker, Anton S and Marcon, Magda and Ghafoor, Soleen and Wurnig, Moritz C and Frauenfelder, Thomas and Boss, Andreas},
  journal={Investigative radiology},
  volume={52},
  number={7},
  pages={434--440},
  year={2017},
  publisher={LWW}
}

@article{khan2019novel,
  title={A novel deep learning based framework for the detection and classification of breast cancer using transfer learning},
  author={Khan, SanaUllah and Islam, Naveed and Jan, Zahoor and Din, Ikram Ud and Rodrigues, Joel JP C},
  journal={Pattern Recognition Letters},
  volume={125},
  pages={1--6},
  year={2019},
  publisher={Elsevier}
}

@article{topol2019high,
  title={High-Performance Medicine: the Convergence of Human and Artificial Intelligence},
  author={Topol, Eric J},
  journal={Nature Medicine},
  volume={25},
  number={1},
  pages={44},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{gale2017detecting,
  title={Detecting hip fractures with radiologist-level performance using deep neural networks},
  author={Gale, William and Oakden-Rayner, Luke and Carneiro, Gustavo and Bradley, Andrew P and Palmer, Lyle J},
  journal={arXiv preprint arXiv:1711.06504},
  year={2017}
}

@article{greenspan2016guest,
  title={{Guest editorial deep learning in medical imaging: Overview and future promise of an exciting new technique}},
  author={Greenspan, Hayit and van Ginneken, Bram and Summers, Ronald M},
  journal={Trans. Medical Imaging},
  volume={35},
  number={5},
  pages={1153--1159},
  year={2016},
  publisher={IEEE}
}

@article{waite2017tired,
  title={Tired in the reading room: the influence of fatigue in radiology},
  author={Waite, Stephen and Kolla, Srinivas and Jeudy, Jean and Legasto, Alan and Macknik, Stephen L and Martinez-Conde, Susana and Krupinski, Elizabeth A and Reede, Deborah L},
  journal={Journal of the American College of Radiology},
  volume={14},
  number={2},
  pages={191--197},
  year={2017},
  publisher={Elsevier}
}

@article{chatelain2018evaluation,
  title={Evaluation of Gaze Tracking Calibration for Longitudinal Biomedical Imaging Studies},
  author={Chatelain, Pierre and Sharma, Harshita and Drukker, Lior and Papageorghiou, Aris T and Noble, J Alison},
  journal={IEEE transactions on cybernetics},
  number={99},
  pages={1--11},
  year={2018},
  publisher={IEEE}
}

@article{miglioretti2007radiologist,
  title={Radiologist characteristics associated with interpretive performance of diagnostic mammography},
  author={Miglioretti, Diana L and Smith-Bindman, Rebecca and Abraham, Linn and Brenner, R James and Carney, Patricia A and Bowles, Erin J Aiello and Buist, Diana SM and Elmore, Joann G},
  journal={Journal of the National Cancer Institute},
  volume={99},
  number={24},
  pages={1854--1863},
  year={2007},
  publisher={Oxford University Press}
}

@article{rosset2004osirix,
  title={{OsiriX: an open-source software for navigating in multidimensional DICOM images}},
  author={Rosset, Antoine and Spadola, Luca and Ratib, Osman},
  journal={Journal of Digital Imaging},
  volume={17},
  number={3},
  pages={205--216},
  year={2004},
  publisher={Springer}
}

@article{wolf2005medical,
  title={{The medical imaging interaction toolkit}},
  author={Wolf, Ivo and Vetter, Marcus and Wegner, Ingmar and B{\"o}ttger, Thomas and Nolden, Marco and Sch{\"o}binger, Max and Hastenteufel, Mark and Kunert, Tobias and Meinzer, Hans-Peter},
  journal={Medical Image Analysis},
  volume={9},
  number={6},
  pages={594--604},
  year={2005},
  publisher={Elsevier}
}

@article{weese2016four,
  title={{Four challenges in medical image analysis from an industrial perspective}},
  author={Weese, J{\"u}rgen and Lorenz, Cristian},
  journal={Medical Image Analysis},
  volume={33},
  pages={44--49},
  year={2016},
  publisher={Elsevier}
}

@article{heinrich2012mind,
  title={{MIND: Modality independent neighbourhood descriptor for multi-modal deformable registration}},
  author={Heinrich, Mattias P and Jenkinson, Mark and Bhushan, Manav and Matin, Tahreema and Gleeson, Fergus V and Brady, Michael and Schnabel, Julia A},
  journal={Medical Image Analysis},
  volume={16},
  number={7},
  pages={1423--1435},
  year={2012},
  publisher={Elsevier}
}

@article{sorace2018distinguishing,
  title={Distinguishing benign and malignant breast tumors: preliminary comparison of kinetic modeling approaches using multi-institutional dynamic contrast-enhanced MRI data from the International Breast MR Consortium 6883 trial},
  author={Sorace, Anna G and Partridge, Savannah C and Li, Xia and Virostko, Jack and Barnes, Stephanie L and Hippe, Daniel S and Huang, Wei and Yankeelov, Thomas E},
  journal={Journal of Medical Imaging},
  volume={5},
  number={1},
  pages={011019},
  year={2018},
  publisher={International Society for Optics and Photonics}
}

@article{mohamed2018deep,
  title={A deep learning method for classifying mammographic breast density categories},
  author={Mohamed, Aly A and Berg, Wendie A and Peng, Hong and Luo, Yahong and Jankowitz, Rachel C and Wu, Shandong},
  journal={Medical physics},
  volume={45},
  number={1},
  pages={314--321},
  year={2018},
  publisher={Wiley Online Library}
}

@inproceedings{aghaei2018association,
  title={{Association between background parenchymal enhancement of breast MRI and BIRADS rating change in the subsequent screening}},
  author={Aghaei, Faranak and Mirniaharikandehei, Seyedehnafiseh and Hollingsworth, Alan B and Stoug, Rebecca G and Pearce, Melanie and Liu, Hong and Zheng, Bin},
  booktitle={Medical Imaging 2018},
  volume={10579},
  pages={1--8},
  year={2018},
  publisher={SPIE},
  address={Houston, Texas, United States}
}

@inproceedings{10.1145/3308558.3314123,
author = {Paranyushkin, Dmitry},
title = {InfraNodus: Generating Insight Using Text Network Analysis},
year = {2019},
isbn = {9781450366748},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3308558.3314123},
doi = {10.1145/3308558.3314123},
abstract = {In this paper we present a web-based open source tool and a method for generating insight from any text or discourse using text network analysis. The tool (InfraNodus) can be used by researchers and writers to organize and to better understand their notes, to measure the level of bias in discourse, and to identify the parts of the discourse where there is a potential for insight and new ideas. The method is based on text network analysis algorithm, which represents any text as a network and identifies the most influential words in a discourse based on the terms' co-occurrence. Graph community detection algorithm is then applied in order to identify the different topical clusters, which represent the main topics in the text as well as the relations between them. The community structure is used in conjunction with other measures to identify the level of bias or cognitive diversity of the discourse. Finally, the structural gaps in the graph can indicate the parts of the discourse where the connections are lacking, therefore highlighting the areas where there's a potential for new ideas. The tool can be used as stand-alone software by end users as well as implemented via an API into other tools. Another interesting application is in the field of recommendation systems: structural gaps could indicate potentially interesting non-trivial connections to any connected datasets.},
booktitle = {The World Wide Web Conference},
pages = {3584–3589},
numpages = {6},
keywords = {comprehension, information interfaces, cognitive science, text mining, ideation, research, bias, graph theory, TNA, network topology, network analysis, discourse bias, mental maps, creativity, topic modelling, insight, text network analysis},
location = {San Francisco, CA, USA},
series = {WWW '19}
}

@article{mullie2019coreslicer,
  title={CoreSlicer: a web toolkit for analytic morphomics},
  author={Mullie, Louis and Afilalo, Jonathan},
  journal={BMC medical imaging},
  volume={19},
  number={1},
  pages={15},
  year={2019},
  publisher={Springer}
}

@inproceedings{Tyllinen:2016:WNN:2858036.2858570,
 author = {Tyllinen, Mari and Kaipio, Johanna and L\"{a}\"{a}veri, Tinja and Nieminen, Marko H.T.},
 title = {We Need Numbers!: Heuristic Evaluation During Demonstrations (HED) for Measuring Usability in IT System Procurement},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {San Jose, California, USA},
 pages = {4129--4141},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/2858036.2858570},
 doi = {10.1145/2858036.2858570},
 acmid = {2858570},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {electronic health record, healthcare and social welfare information system, measuring usability, public procurement, summative evaluation, usability evaluation},
}

@article{liikkanen2017data,
  title={The data-driven design era in professional web design.},
  author={Liikkanen, Lassi A},
  journal={interactions},
  volume={24},
  number={5},
  pages={52--57},
  year={2017}
}

@inproceedings{10.1145/2858036.2858360,
author = {Zhang, Xiaoyi and Pina, Laura R. and Fogarty, James},
title = {Examining Unlock Journaling with Diaries and Reminders for In Situ Self-Report in Health and Wellness},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858360},
doi = {10.1145/2858036.2858360},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {5658–5664},
numpages = {7},
keywords = {personal informatics, experience sampling, self-tracking},
location = {San Jose, California, USA},
series = {CHI ’16}
}

@inproceedings{Harboe:2012:CSC:2145204.2145379,
 author = {Harboe, Gunnar and Minke, Jonas and Ilea, Ioana and Huang, Elaine M.},
 title = {Computer Support for Collaborative Data Analysis: Augmenting Paper Affinity Diagrams},
 booktitle = {Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work},
 series = {CSCW '12},
 year = {2012},
 isbn = {978-1-4503-1086-4},
 location = {Seattle, Washington, USA},
 pages = {1179--1182},
 numpages = {4},
 url = {http://doi.acm.org/10.1145/2145204.2145379},
 doi = {10.1145/2145204.2145379},
 acmid = {2145379},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {affinity diagram, augmented paper, augmented reality},
}

@inproceedings{Hoiseth:2013:DHG:2485760.2485770,
 author = {H{\o}iseth, Marikken and Giannakos, Michail N. and Alsos, Ole A. and Jaccheri, Letizia and Asheim, Jonas},
 title = {Designing Healthcare Games and Applications for Toddlers},
 booktitle = {Proceedings of the 12th International Conference on Interaction Design and Children},
 series = {IDC '13},
 year = {2013},
 isbn = {978-1-4503-1918-8},
 location = {New York, New York, USA},
 pages = {137--146},
 numpages = {10},
 url = {http://doi.acm.org/10.1145/2485760.2485770},
 doi = {10.1145/2485760.2485770},
 acmid = {2485770},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design considerations, healthcare games, toddlers, young children},
}

@inproceedings{10.1145/3290605.3300628,
author = {Subramonyam, Hariharan and Drucker, Steven M. and Adar, Eytan},
title = {Affinity Lens: Data-Assisted Affinity Diagramming with Augmented Reality},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300628},
doi = {10.1145/3290605.3300628},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
articleno = {Paper 398},
numpages = {13},
keywords = {augmented reality, visual analytics, affinity diagramming},
location = {Glasgow, Scotland Uk},
series = {CHI ’19},
pages={1--13}
}

@inproceedings{10.1145/2858036.2858373,
author = {Yang, Qian and Zimmerman, John and Steinfeld, Aaron and Carey, Lisa and Antaki, James F.},
title = {Investigating the Heart Pump Implant Decision Process: Opportunities for Decision Support Tools to Help},
year = {2016},
isbn = {9781450333627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2858036.2858373},
doi = {10.1145/2858036.2858373},
booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
pages = {4477–4488},
numpages = {12},
keywords = {clinical decision support systems, service design, qualitative methods, decision support tools, field study},
location = {San Jose, California, USA},
series = {CHI ’16}
}

@inproceedings{10.1145/3343413.3377983,
author = {McKay, Dana and Makri, Stephann and Chang, Shanton and Buchanan, George},
title = {On Birthing Dancing Stars: The Need for Bounded Chaos in Information Interaction},
year = {2020},
isbn = {9781450368926},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3343413.3377983},
doi = {10.1145/3343413.3377983},
booktitle = {Proceedings of the 2020 Conference on Human Information Interaction and Retrieval},
pages = {292–302},
numpages = {11},
keywords = {serendipity, creativity, chaos, information-seeking, browsing, information encountering, information interaction, exploration},
location = {Vancouver BC, Canada},
series = {CHIIR ’20}
}

@inproceedings{10.1145/3173574.3173704,
author = {Yang, Qian and Banovic, Nikola and Zimmerman, John},
title = {Mapping Machine Learning Advances from HCI Research to Reveal Starting Places for Design Innovation},
year = {2018},
isbn = {9781450356206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3173574.3173704},
doi = {10.1145/3173574.3173704},
booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
articleno = {Paper 130},
numpages = {11},
keywords = {machine learning, research transfer, sensitizing concept, user experience, bibliometric, data mining},
location = {Montreal QC, Canada},
series = {CHI ’18},
pages={1--11}
}

@book{szolovits2019artificial,
  title={Artificial intelligence in medicine},
  author={Szolovits, Peter},
  year={2019},
  publisher={Routledge}
}

@inproceedings{Alkhatib:2019:SAT:3290605.3300760,
 author = {Alkhatib, Ali and Bernstein, Michael},
 title = {Street-Level Algorithms: A Theory at the Gaps Between Policy and Decisions},
 booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '19},
 year = {2019},
 isbn = {978-1-4503-5970-2},
 location = {Glasgow, Scotland Uk},
 pages = {530:1--530:13},
 articleno = {530},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3290605.3300760},
 doi = {10.1145/3290605.3300760},
 acmid = {3300760},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {artificial intelligence, street-level algorithms, street-level bureaucracies},
}

@inproceedings{DeBackere:2015:DPR:2826165.2826229,
 author = {De Backere, Femke and Verstichel, Stijn and Van den Bergh, Jan and Elprama, Shirley A. and Ongenae, Femke and De Turck, Filip and Jacobs, An and Coninx, Karin},
 title = {Discovery of the Potential Role of Sensors in a Personal Emergency Response System: What Can We Learn from a Single Workshop?},
 booktitle = {Proceedings of the 9th International Conference on Pervasive Computing Technologies for Healthcare},
 series = {PervasiveHealth '15},
 year = {2015},
 isbn = {978-1-63190-045-7},
 location = {Istanbul, Turkey},
 pages = {330--333},
 numpages = {4},
 url = {http://dl.acm.org/citation.cfm?id=2826165.2826229},
 acmid = {2826229},
 publisher = {ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)},
 address = {ICST, Brussels, Belgium, Belgium},
 keywords = {care, decision, process, workshop},
}

@inproceedings{Bonham:2019:ARS:3308557.3308726,
 author = {Bonham, Matthew},
 title = {Augmented Reality Simulation Toward Improving Therapeutic Healthcare Communication Techniques},
 booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces: Companion},
 series = {IUI '19},
 year = {2019},
 isbn = {978-1-4503-6673-1},
 location = {Marina del Ray, California},
 pages = {161--162},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/3308557.3308726},
 doi = {10.1145/3308557.3308726},
 acmid = {3308726},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {healthcare communication, nurse training, therapeutic nursing},
}

@inproceedings{Gambino:2019:DDR:3290607.3312916,
 author = {Gambino, Andrew and Kim, Jinyoung and Sundar, S. Shyam},
 title = {Digital Doctors and Robot Receptionists: User Attributes That Predict Acceptance of Automation in Healthcare Facilities},
 booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
 series = {CHI EA '19},
 year = {2019},
 isbn = {978-1-4503-5971-9},
 location = {Glasgow, Scotland Uk},
 pages = {LBW0287:1--LBW0287:6},
 articleno = {LBW0287},
 numpages = {6},
 url = {http://doi.acm.org/10.1145/3290607.3312916},
 doi = {10.1145/3290607.3312916},
 acmid = {3312916},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {automation, cognitive heuristics, health information systems, self-disclosure},
}

@inproceedings{Sonntag:2012:RMD:2166966.2167031,
 author = {Sonntag, Daniel and Schulz, Christian and Reuschling, Christian and Galarraga, Luis},
 title = {RadSpeech's Mobile Dialogue System for Radiologists},
 booktitle = {Proceedings of the 2012 ACM International Conference on Intelligent User Interfaces},
 series = {IUI '12},
 year = {2012},
 isbn = {978-1-4503-1048-2},
 location = {Lisbon, Portugal},
 pages = {317--318},
 numpages = {2},
 url = {http://doi.acm.org/10.1145/2166966.2167031},
 doi = {10.1145/2166966.2167031},
 acmid = {2167031},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {healthcare, mobility, speech dialogue},
}

@inproceedings{Eslami:2016:FIL:2858036.2858494,
 author = {Eslami, Motahhare and Karahalios, Karrie and Sandvig, Christian and Vaccaro, Kristen and Rickman, Aimee and Hamilton, Kevin and Kirlik, Alex},
 title = {First I "Like" It, then I Hide It: Folk Theories of Social Feeds},
 booktitle = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '16},
 year = {2016},
 isbn = {978-1-4503-3362-7},
 location = {San Jose, California, USA},
 pages = {2371--2382},
 numpages = {12},
 url = {http://doi.acm.org/10.1145/2858036.2858494},
 doi = {10.1145/2858036.2858494},
 acmid = {2858494},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {algorithms, folk theories, seamful design, social media feeds},
}

@inproceedings{Oh:2018:ILY:3173574.3174223,
 author = {Oh, Changhoon and Song, Jungwoo and Choi, Jinhan and Kim, Seonghyeon and Lee, Sungwoo and Suh, Bongwon},
 title = {I Lead, You Help but Only with Enough Details: Understanding User Experience of Co-Creation with Artificial Intelligence},
 booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '18},
 year = {2018},
 isbn = {978-1-4503-5620-6},
 location = {Montreal QC, Canada},
 pages = {649:1--649:13},
 articleno = {649},
 numpages = {13},
 url = {http://doi.acm.org/10.1145/3173574.3174223},
 doi = {10.1145/3173574.3174223},
 acmid = {3174223},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {artificial intelligence, human computer collaboration, human-ai interaction},
}

@inproceedings{Inkpen:2019:HBG:3290607.3299002,
 author = {Inkpen, Kori and Chancellor, Stevie and De Choudhury, Munmun and Veale, Michael and Baumer, Eric P. S.},
 title = {Where is the Human?: Bridging the Gap Between AI and HCI},
 booktitle = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems},
 series = {CHI EA '19},
 year = {2019},
 isbn = {978-1-4503-5971-9},
 location = {Glasgow, Scotland Uk},
 pages = {W09:1--W09:9},
 articleno = {W09},
 numpages = {9},
 url = {http://doi.acm.org/10.1145/3290607.3299002},
 doi = {10.1145/3290607.3299002},
 acmid = {3299002},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {artificial interlligence, human computer interaction, machine learning},
}

@article{sundaram2018predicting,
  title={Predicting the clinical impact of human mutation with deep neural networks},
  author={Sundaram, Laksshman and Gao, Hong and Padigepati, Samskruthi Reddy and McRae, Jeremy F and Li, Yanjun and Kosmicki, Jack A and Fritzilas, Nondas and Hakenberg, J{\"o}rg and Dutta, Anindita and Shon, John and others},
  journal={Nature genetics},
  volume={50},
  number={8},
  pages={1161},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{madani2018deep,
  title={Deep echocardiography: data-efficient supervised and semi-supervised deep learning towards automated diagnosis of cardiac disease},
  author={Madani, Ali and Ong, Jia Rui and Tibrewal, Anshul and Mofrad, Mohammad RK},
  journal={npj Digital Medicine},
  volume={1},
  number={1},
  pages={59},
  year={2018},
  publisher={Nature Publishing Group}
}

@inproceedings{ahmad2018death,
  title={Death vs. Data Science: Predicting End of Life},
  author={Ahmad, Muhammad A and Eckert, Carly and McKelvey, Greg and Zolfagar, Kiyana and Zahid, Anam and Teredesai, Ankur},
  booktitle={Thirty-Second AAAI Conference on Artificial Intelligence},
  year={2018}
}

@incollection{benrimoh2018aifred,
  title={Aifred Health, a Deep Learning Powered Clinical Decision Support System for Mental Health},
  author={Benrimoh, David and Fratila, Robert and Israel, Sonia and Perlman, Kelly and Mirchi, Nykan and Desai, Sneha and Rosenfeld, Ariel and Knappe, Sabrina and Behrmann, Jason and Rollins, Colleen and others},
  booktitle={The NIPS'17 Competition: Building Intelligent Systems},
  pages={251--287},
  year={2018},
  publisher={Springer}
}

@article{ghosh2019artificial,
  title={Artificial Intelligence Using Open Source BI-RADS Data Exemplifying Potential Future Use},
  author={Ghosh, Adarsh},
  journal={Journal of the American College of Radiology},
  volume={16},
  number={1},
  pages={64--72},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{chen2019learning,
  title={Learning Active Contour Models for Medical Image Segmentation},
  author={Chen, Xu and Williams, Bryan M and Vallabhaneni, Srinivasa R and Czanner, Gabriela and Williams, Rachel and Zheng, Yalin},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={11632--11640},
  year={2019}
}

@article{johnson2016face,
  title={Face-to-face interaction with pedagogical agents, twenty years later},
  author={Johnson, W Lewis and Lester, James C},
  journal={International Journal of Artificial Intelligence in Education},
  volume={26},
  number={1},
  pages={25--36},
  year={2016},
  publisher={Springer}
}

@article{mou2017media,
  title={The media inequality: Comparing the initial human-human and human-AI social interactions},
  author={Mou, Yi and Xu, Kun},
  journal={Computers in Human Behavior},
  volume={72},
  pages={432--440},
  year={2017},
  publisher={Elsevier}
}

@article{miller2019intrinsically,
  title={The intrinsically linked future for human and Artificial Intelligence interaction},
  author={Miller, Anthony},
  journal={Journal of Big Data},
  volume={6},
  number={1},
  pages={38},
  year={2019},
  publisher={Springer}
}

@inproceedings{chattopadhyay2017evaluating,
  title={Evaluating visual conversational agents via cooperative human-ai games},
  author={Chattopadhyay, Prithvijit and Yadav, Deshraj and Prabhu, Viraj and Chandrasekaran, Arjun and Das, Abhishek and Lee, Stefan and Batra, Dhruv and Parikh, Devi},
  booktitle={Fifth AAAI Conference on Human Computation and Crowdsourcing},
  year={2017}
}

@article{azuaje2019artificial,
  title={Artificial intelligence for precision oncology: beyond patient stratification},
  author={Azuaje, Francisco},
  journal={NPJ precision oncology},
  volume={3},
  number={1},
  pages={6},
  year={2019},
  publisher={Nature Publishing Group}
}

@article{chin2018clinical,
  title={Clinical judgement in the era of big data and predictive analytics},
  author={Chin-Yee, Benjamin and Upshur, Ross},
  journal={Journal of evaluation in clinical practice},
  volume={24},
  number={3},
  pages={638--645},
  year={2018},
  publisher={Wiley Online Library}
}

@article{lau2018dataset,
  title={A dataset of clinically generated visual questions and answers about radiology images},
  author={Lau, Jason J and Gayen, Soumya and Abacha, Asma Ben and Demner-Fushman, Dina},
  journal={Scientific data},
  volume={5},
  pages={180251},
  year={2018},
  publisher={Nature Publishing Group}
}

@article{price2018big,
  title={Big data and black-box medical algorithms},
  author={Price, W Nicholson},
  journal={Science translational medicine},
  volume={10},
  number={471},
  pages={eaao5333},
  year={2018},
  publisher={American Association for the Advancement of Science}
}

@inproceedings{aha2017ai,
  title={The AI rebellion: Changing the narrative},
  author={Aha, David W and Coman, Alexandra},
  booktitle={Thirty-First AAAI Conference on Artificial Intelligence},
  year={2017}
}

@article{holzinger2019interactive,
  title={Interactive machine learning: experimental evidence for the human in the algorithmic loop},
  author={Holzinger, Andreas and Plass, Markus and Kickmeier-Rust, Michael and Holzinger, Katharina and Cri{\c{s}}an, Gloria Cerasela and Pintea, Camelia-M and Palade, Vasile},
  journal={Applied Intelligence},
  volume={49},
  number={7},
  pages={2401--2414},
  year={2019},
  publisher={Springer}
}

@inproceedings{Dove:2017:UDI:3025453.3025739,
 author = {Dove, Graham and Halskov, Kim and Forlizzi, Jodi and Zimmerman, John},
 title = {UX Design Innovation: Challenges for Working with Machine Learning As a Design Material},
 booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
 series = {CHI '17},
 year = {2017},
 isbn = {978-1-4503-4655-9},
 location = {Denver, Colorado, USA},
 pages = {278--288},
 numpages = {11},
 url = {http://doi.acm.org/10.1145/3025453.3025739},
 doi = {10.1145/3025453.3025739},
 acmid = {3025739},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {design material, interaction design, machine learning, ux practice},
}

@article{drnasin2017javascript,
  title={JavaScript access to DICOM network and objects in web browser},
  author={Drnasin, Ivan and Grgi{\'c}, Mislav and Gogi{\'c}, Goran},
  journal={Journal of digital imaging},
  volume={30},
  number={5},
  pages={537--546},
  year={2017},
  publisher={Springer}
}

@inproceedings{gustin2017empowerment,
  title={Empowerment of diabetic patients through mHealth technologies and education: development of a pilot self-management application},
  author={Gustin, Guillaume and Macq, Beno{\^\i}t and Gruson, Damien and Kieffer, Suzanne},
  booktitle={13th International Conference on Medical Information Processing and Analysis},
  volume={10572},
  pages={105720L},
  year={2017},
  organization={International Society for Optics and Photonics}
}

@inproceedings{NEURIPS2019_bdbca288,
 author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
 pages = {8026--8037},
 publisher = {Curran Associates, Inc.},
 title = {PyTorch: An Imperative Style, High-Performance Deep Learning Library},
 url = {https://proceedings.neurips.cc/paper/2019/file/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf},
 volume = {32},
 year = {2019}
}

@article{basheer2015certainty,
  title={Certainty, trust and evidence: Towards an integrative model of confidence in multi-agent systems},
  author={Basheer, Ghusoon Salim and Ahmad, Mohd Sharifuddin and Tang, Alicia YC and Graf, Sabine},
  journal={Computers in Human Behavior},
  volume={45},
  pages={307--315},
  year={2015},
  publisher={Elsevier}
}

@inproceedings{khalid2016prediction,
  title={Prediction of trust in scripted dialogs using neuro-fuzzy method},
  author={Khalid, HM and Liew, WS and Helander, MG and Loo, CK},
  booktitle={2016 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)},
  pages={1558--1562},
  year={2016},
  organization={IEEE}
}

@inproceedings{10.1145/2898375.2898385,
author = {Pearson, Carl J. and Welk, Allaire K. and Boettcher, William A. and Mayer, Roger C. and Streck, Sean and Simons-Rudolph, Joseph M. and Mayhorn, Christopher B.},
title = {Differences in Trust between Human and Automated Decision Aids},
year = {2016},
isbn = {9781450342773},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2898375.2898385},
doi = {10.1145/2898375.2898385},
abstract = {Humans can easily find themselves in high cost situations where they must choose between suggestions made by an automated decision aid and a conflicting human decision aid. Previous research indicates that humans often rely on automation or other humans, but not both simultaneously. Expanding on previous work conducted by Lyons and Stokes (2012), the current experiment measures how trust in automated or human decision aids differs along with perceived risk and workload. The simulated task required 126 participants to choose the safest route for a military convoy; they were presented with conflicting information from an automated tool and a human. Results demonstrated that as workload increased, trust in automation decreased. As the perceived risk increased, trust in the human decision aid increased. Individual differences in dispositional trust correlated with an increased trust in both decision aids. These findings can be used to inform training programs for operators who may receive information from human and automated sources. Examples of this context include: air traffic control, aviation, and signals intelligence.},
booktitle = {Proceedings of the Symposium and Bootcamp on the Science of Security},
pages = {95–98},
numpages = {4},
keywords = {decision-making, workload, reliance, strain, risk, trust, automation},
location = {Pittsburgh, Pennsylvania},
series = {HotSos '16}
}

@InProceedings{maicas2018training,
author="Maicas, Gabriel
and Bradley, Andrew P.
and Nascimento, Jacinto C.
and Reid, Ian
and Carneiro, Gustavo",
editor="Frangi, Alejandro F.
and Schnabel, Julia A.
and Davatzikos, Christos
and Alberola-L{\'o}pez, Carlos
and Fichtinger, Gabor",
title="Training Medical Image Analysis Systems like Radiologists ",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2018",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="546--554",
abstract="The training of medical image analysis systems using machine learning approaches follows a common script: collect and annotate a large dataset, train the classifier on the training set, and test it on a hold-out test set. This process bears no direct resemblance with radiologist training, which is based on solving a series of tasks of increasing difficulty, where each task involves the use of significantly smaller datasets than those used in machine learning. In this paper, we propose a novel training approach inspired by how radiologists are trained. In particular, we explore the use of meta-training that models a classifier based on a series of tasks. Tasks are selected using teacher-student curriculum learning, where each task consists of simple classification problems containing small training sets. We hypothesize that our proposed meta-training approach can be used to pre-train medical image analysis models. This hypothesis is tested on the automatic breast screening classification from DCE-MRI trained with weakly labeled datasets. The classification performance achieved by our approach is shown to be the best in the field for that application, compared to state of art baseline approaches: DenseNet, multiple instance learning and multi-task learning.",
isbn="978-3-030-00928-1"
}

@article{GOTTAPU2018179,
title = "DenseNet for Anatomical Brain Segmentation",
journal = "Procedia Computer Science",
volume = "140",
pages = "179 - 185",
year = "2018",
note = "Cyber Physical Systems and Deep Learning Chicago, Illinois November 5-7, 2018",
issn = "1877-0509",
doi = "https://doi.org/10.1016/j.procs.2018.10.327",
url = "http://www.sciencedirect.com/science/article/pii/S1877050918320003",
author = "Ram Deepak Gottapu and Cihan H Dagli",
keywords = "convolutional neural network (CNN), Dense Net, segmentation",
abstract = "Automated segmentation in brain magnetic resonance image (MRI) plays an important role in the analysis of many diseases and conditions. In this paper, we present a new architecture to perform MR image brain segmentation (MRI) into a number of classes based on type of tissue. Recent work has shown that convolutional neural networks (DenseNet) can be substantially more accurate with less number of parameters if each layer in the network is connected with every other layer in a feed forward fashion. We embrace this idea and generate new architecture that can assign each pixel/voxel in an MR image of the brain to its corresponding anatomical region. To benchmark our model, we used the dataset provided by the IBSR 2(Internet Brain Segmentation Repository), which consists of 18 manually segmented MR images of the brain. To our knowledge, our approach is the first to use DenseNet to perform anatomical segmentation of the whole brain."
}

@article{Savage2019,
  doi = {10.1038/d41586-019-02870-4},
  url = {https://doi.org/10.1038/d41586-019-02870-4},
  year = {2019},
  month = sep,
  publisher = {Springer Science and Business Media {LLC}},
  volume = {573},
  number = {7775},
  pages = {S98--S99},
  author = {Neil Savage},
  title = {Digital assistants aid disease diagnosis},
  journal = {Nature}
}

@article{raja2017machine,
  title={Machine learning workflow to enhance predictions of adverse drug reactions (ADRs) through drug-gene interactions: Application to drugs for cutaneous diseases},
  author={Raja, Kalpana and Patrick, Matthew and Elder, James T and Tsoi, Lam C},
  journal={Scientific reports},
  volume={7},
  number={1},
  pages={3690},
  year={2017},
  publisher={Nature Publishing Group}
}

@Inbook{Miao2019,
author="Miao, Shun
and Liao, Rui",
title="Agent-Based Methods for Medical Image Registration",
bookTitle="Deep Learning and Convolutional Neural Networks for Medical Imaging and Clinical Informatics",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="323--345",
abstract="Medical imaging registration is a critical step in a wide spectrum of medical applications from diagnosis to therapy and has been an extensively studied research field. Prior to the popularity of deep learningDeep learning, image registrationImage registration was commonly performed by optimizing an image matching metric as a cost function in search for the optimal registration. However, the optimization task is known to be challenging due to (1) the non-convex nature of the matching metric over the registration parameter space and (2) the lack of effective approaches for robust optimization. With the latest advance in deep learningDeep learning and artificial intelligence, the field of medical image registrationImage registration had a major paradigm shift, whereby learning-based image registrationImage registration methods are developed to employ deep neural networks to analyze images in order to estimate plausible registrations. Among the latest advances in learning-based registration methods, agent-based methods have been shown to be effective in both 3-D/3-D and 2-D/3-D registrations with significant robustness advantage over conventional optimization-based methods. In this chapter, we give an overview of agent-based methods for medical image registrationImage registration and its two applications on rigid-body 3-D/3-D and 2-D/3-D registrations.",
isbn="978-3-030-13969-8",
doi="10.1007/978-3-030-13969-8_16",
url="https://doi.org/10.1007/978-3-030-13969-8_16"
}

@inproceedings{sonntag2016persuasive,
  title={Persuasive AI Technologies for Healthcare Systems},
  author={Sonntag, Daniel},
  booktitle={2016 AAAI Fall Symposium Series},
  year={2016},
  publisher={AAAI},
  address={Westin Arlington Gateway, Arlington, Virginia, USA},
  pages={165--168},
  numpages={4}
}

@article{hayes2017regression,
  title={Regression-based statistical mediation and moderation analysis in clinical research: Observations, recommendations, and implementation},
  author={Hayes, Andrew F and Rockwood, Nicholas J},
  journal={Behaviour research and therapy},
  volume={98},
  pages={39--57},
  year={2017},
  publisher={Elsevier}
}

@ARTICLE{9233366,
  author={E. {Tjoa} and C. {Guan}},
  journal={IEEE Transactions on Neural Networks and Learning Systems}, 
  title={A Survey on Explainable Artificial Intelligence (XAI): Toward Medical XAI}, 
  year={2020},
  volume={},
  number={},
  pages={1-21},
  doi={10.1109/TNNLS.2020.3027314}
}

@article{andreas2020measuring,
  title={Measuring the Quality of Explanations: The System Causability Scale (SCS): Comparing Human and Machine Explanations},
  author={Andreas, Holzinger and Andr{\'e}, Carrington and Heimo, M{\"u}ller},
  journal={Kunstliche intelligenz},
  volume={34},
  number={2},
  pages={193--198},
  year={2020}
}

@article{LANGER2021106878,
title = {The future of artificial intelligence at work: A review on effects of decision automation and augmentation on workers targeted by algorithms and third-party observers},
journal = {Computers in Human Behavior},
volume = {123},
pages = {106878},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106878},
author = {Markus Langer and Richard N. Landers},
keywords = {Automated and augmented decision-making, Artificial intelligence, Algorithmic decision-making, Perceptions, Attitudes, Review paper},
abstract = {Advances in artificial intelligence are increasingly leading to the automation and augmentation of decision processes in work contexts. Although research originally generally focused upon decision-makers, the perspective of those targeted by automated or augmented decisions (whom we call “second parties”) and parties who observe the effects of such decisions (whom we call “third parties”) is now growing in importance and attention. We review the expanding literature investigating reactions to automated and augmented decision-making by second and third parties. Specifically, we explore attitude (e.g., evaluations of trustworthiness), perception (e.g., fairness perceptions), and behavior (e.g., reverse engineering of automated decision processes) outcomes of second and third parties. Additionally, we explore how characteristics of the a) decision-making process, b) system, c) second and third party, d) task, and e) outputs and outcomes moderate these effects, and provide recommendation for future research. Our review summarizes the state of the literature in these domains, concluding a) that reactions to automated decisions differ across situations in which there is remaining human decision control (i.e., augmentation contexts), b) that system design choices (e.g., transparency) are important but underresearched, and c) that the generalizability of findings might suffer from excessive reliance on specific research methodologies (e.g., vignette studies).}
}

@article{CORONATO2020101964,
title = {Reinforcement learning for intelligent healthcare applications: A survey},
journal = {Artificial Intelligence in Medicine},
volume = {109},
pages = {101964},
year = {2020},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2020.101964},
author = {Antonio Coronato and Muddasar Naeem and Giuseppe {De Pietro} and Giovanni Paragliola},
keywords = {Artificial intelligence, Reinforcement learning, Healthcare, Personalized medicine},
abstract = {Discovering new treatments and personalizing existing ones is one of the major goals of modern clinical research. In the last decade, Artificial Intelligence (AI) has enabled the realization of advanced intelligent systems able to learn about clinical treatments and discover new medical knowledge from the huge amount of data collected. Reinforcement Learning (RL), which is a branch of Machine Learning (ML), has received significant attention in the medical community since it has the potentiality to support the development of personalized treatments in accordance with the more general precision medicine vision. This report presents a review of the role of RL in healthcare by investigating past work, and highlighting any limitations and possible future contributions.}
}

@article{PARK2021106795,
title = {Use of offensive language in human-artificial intelligence chatbot interaction: The effects of ethical ideology, social competence, and perceived humanlikeness},
journal = {Computers in Human Behavior},
volume = {121},
pages = {106795},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106795},
author = {Namkee Park and Kyungeun Jang and Seonggyeol Cho and Jinyoung Choi},
keywords = {Human-AI chatbot interaction, Ethical ideology, Social competence, Perceived humanlikeness of chatbot, Offensive language use},
abstract = {This study examined the factors that affect artificial intelligence (AI) chatbot users' use of profanity and offensive words, employing the concepts of ethical ideology, social competence, and perceived humanlikeness of chatbot. The study also looked into users' liking of chatbots' responses to the users' utterance of profanity and offensive words. Using a national survey (N = 645), the study found that users' idealism orientation was a significant factor in explaining use of such offensive language. In addition, users with high idealism revealed liking of chatbots' active intervention, whereas those with high relativism displayed liking of chatbots' reactive responses. Moreover, users’ perceived humanlikeness of chatbot increased their likelihood of using offensive words targeting dislikable acquaintances, racial/ethnic groups, and political parties. These findings are expected to fill the gap between the current use of AI chatbots and the lack of empirical studies examining language use.}
}

@inproceedings{10.1145/3311957.3361858,
author = {Bennett, Sarah Joy},
title = {Investigating the Role of Moral Decision-Making in Emerging Artificial Intelligence Technologies},
year = {2019},
isbn = {9781450366922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3311957.3361858},
abstract = {In the midst of the current boom in ethical principles, frameworks and guidelines for emerging applications of artificial intelligence (AI), it is difficult to assess how these translate into the context of real-world applications. Through interviews and ethnography, my research explores AI specialists' accounts of navigating the ethical and social impact of their work, examining and providing insight into the various interactions impacting ethical decision-making in AI system development. Having investigated behavior of AI specialists as proactive moral agents, the work then aims to explore how we can support meaningful applications of ethics in system design and development.},
booktitle = {Conference Companion Publication of the 2019 on Computer Supported Cooperative Work and Social Computing},
pages = {28–32},
numpages = {5},
keywords = {artificial intelligence, design, ethics},
location = {Austin, TX, USA},
series = {CSCW '19}
}

@article{LEGRIS2003191,
title = {Why do people use information technology? A critical review of the technology acceptance model},
journal = {Information \& Management},
volume = {40},
number = {3},
pages = {191-204},
year = {2003},
issn = {0378-7206},
doi = {https://doi.org/10.1016/S0378-7206(01)00143-4},
author = {Paul Legris and John Ingham and Pierre Collerette},
keywords = {Technology acceptance model, Information technology, Ease of use, Usefulness, IS use, Change management, Innovation},
abstract = {Information systems (IS) implementation is costly and has a relatively low success rate. Since the seventies, IS research has contributed to a better understanding of this process and its outcomes. The early efforts concentrated on the identification of factors that facilitated IS use. This produced a long list of items that proved to be of little practical value. It became obvious that, for practical reasons, the factors had to be grouped into a model in a way that would facilitate analysis of IS use. In 1985, Fred Davis suggested the technology acceptance model (TAM). It examines the mediating role of perceived ease of use and perceived usefulness in their relation between systems characteristics (external variables) and the probability of system use (an indicator of system success). More recently, Davis proposed a new version of his model: TAM2. It includes subjective norms, and was tested with longitudinal research designs. Overall the two explain about 40\% of system’s use. Analysis of empirical research using TAM shows that results are not totally consistent or clear. This suggests that significant factors are not included in the models. We conclude that TAM is a useful model, but has to be integrated into a broader one which would include variables related to both human and social change processes, and to the adoption of the innovation model.}
}

@INPROCEEDINGS{772658,  author={Malhotra, Y. and Galletta, D.F.},  booktitle={Proceedings of the 32nd Annual Hawaii International Conference on Systems Sciences. 1999. HICSS-32. Abstracts and CD-ROM of Full Papers},   title={Extending the technology acceptance model to account for social influence: theoretical bases and empirical validation},   year={1999},  volume={Track1},  number={},  pages={14 pp.-},  abstract={The Technology Acceptance Model (TAM) represents an important theoretical contribution toward understanding IS usage and IS acceptance behaviors. However, as noted by several IS researchers, TAM is incomplete in one important respect: it doesn't account for social influence in the adoption and utilization of new information systems. Davis (1986) and Davis et al. (1989) noted that it is important to account for subjective norm (SN), the construct denoting social influence. However, they observed that the conceptualization of SN based on TRA (Theory of Reasoned Action) has theoretical and psychometric problems. Specifically, they observed that it is difficult to distinguish if usage behavior is caused by the influence of referents on one's intent or by one's own attitude. They suggested that this problem may be circumvented by using an alternative theoretical basis for conceptualizing SN, specifically in terms of Kelman's (1958, 1961) processes of social influence (compliance, identification and internalization). Within the context of organizational enterprisewide implementation and adoption of collaboration and communication technologies, this study establishes theoretical and empirical bases for the above conceptualization originally suggested by Davis and his colleagues. The construct of social influence is operationalized in terms of Kelman's processes of internalization, identification and compliance. Analyses of field study data provide evidence of the reliability and validity of the proposed constructs, factor structures and measures. The findings enable future researchers to account for social influence in further investigating TAM.},  keywords={},  doi={10.1109/HICSS.1999.772658},  ISSN={},  month={Jan},}

@article{KHALILZADEH2017460,
title = {Security-related factors in extended UTAUT model for NFC based mobile payment in the restaurant industry},
journal = {Computers in Human Behavior},
volume = {70},
pages = {460-474},
year = {2017},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.01.001},
author = {Jalayer Khalilzadeh and Ahmet Bulent Ozturk and Anil Bilgihan},
keywords = {Unified theory of acceptance and use of technology (UTAUT), Near-field communication (NFC) technology, Restaurants, Mobile payment, E-commerce},
abstract = {This study aims to provide an integrated model that examines the determinants of near-field communication (NFC) based mobile payment (MP) technology acceptance in the restaurant industry. The proposed model, which combines the unified theory of acceptance and use of technology (UTAUT) and technology acceptance model (TAM), was tested via structural equation modeling (SEM) by using data collected from 412 restaurant customers. The study results indicated that the proposed model provides approximately 20\% greater explanatory power and predictive accuracy than the original UTAUT model and demonstrates strong evidence of the effects of risk, security, and trust on customers' intentions to use NFC-based MP technology in restaurant settings. In addition, considering the total effect, attitude, security, and risk have the most substantial impact on customers’ behavioral intentions. The study results further demonstrate that risk, security, and trust are also important determinants, with direct and indirect impacts, of other critical constructs (i.e., effort expectancy, hedonic and utilitarian performance expectancy, attitude, and intention). The empirical findings provide valuable theoretical contributions for researchers and practical implications for restaurant operators and technology vendors by explaining the reasons as to why the NFC-based MP is not popular in North American restaurants.}
}

@article{mandrik2005exploring,
  title={Exploring the concept and measurement of general risk aversion},
  author={Mandrik, Carter A and Bao, Yeqing},
  journal={ACR North American Advances},
  year={2005}
}

@inproceedings{williams2011utaut,
booktitle = {Proceedings of the 19th European Conference on Information Systems},
title = {Is UTAUT really used or just cited for the sake of it? A systematic review of citations of UTAUT's originating article},
author = {MD Williams and NP Rana and YK Dwivedi and B Lal},
year = {2011},
url = {http://irep.ntu.ac.uk/id/eprint/17114/},
pages={1--12}
}

@article {Lee:2013:0301-2212:587,
title = "Effects of trust and perceived risk on user acceptance of a new technology service",
journal = "Social Behavior and Personality: an international journal",
parent_itemid = "infobike://sbp/sbp",
publishercode ="sbp",
year = "2013",
volume = "41",
number = "4",
pages = "587-597",
itemtype = "ARTICLE",
issn = "0301-2212",
doi = "doi:10.2224/sbp.2013.41.4.587",
keyword = "TECHNOLOGY ACCEPTANCE MODEL, TRUST, PERCEIVED RISK, CERTIFIED E-DOCUMENT AUTHORITY, UNIFIED THEORY OF ACCEPTANCE AND USE OF TECHNOLOGY",
author = "Lee, Ji-Hwan and Song, Chi-Hoon",
abstract = "We explored the precise impacts of trust and perceived risk on the core constructs of the unified theory of acceptance and use of technology (UTAUT). We applied the UTAUT model to the novel context of the Certified e-Document Authority (CeDA) service used in the Republic of Korea. Our
results from structural equation modeling largely supported our hypotheses. Trust and perceived risk were shown to be direct antecedents of intention to use, and trust functioned as an indirect antecedent. Performance expectancy and social influence were shown to positively affect behavioral
intention. Effort expectancy was also shown to influence performance expectancy. The combination of trust, perceived risk, performance expectancy, effort expectancy, and social influence accounted for 55.3\% of the variance observed in users' intention to use CeDA services.",
}

@article{LU2011393,
title = {Dynamics between the trust transfer process and intention to use mobile payment services: A cross-environment perspective},
journal = {Information \& Management},
volume = {48},
number = {8},
pages = {393-403},
year = {2011},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2011.09.006},
author = {Yaobin Lu and Shuiqing Yang and Patrick Y.K. Chau and Yuzhi Cao},
keywords = {Mobile payment services, Trust transfer theory, Valence framework, Innovation diffusion theory, Cross-environment},
abstract = {Many Internet-based services have already been ported to the mobile-based environment, embracing the new services is therefore critical to deriving revenue for services providers. Based on a valence framework and trust transfer theory, we developed a trust-based customer decision-making model of the non-independent, third-party mobile payment services context. We empirically investigated whether a customer's established trust in Internet payment services is likely to influence his or her initial trust in mobile payment services. We also examined how these trust beliefs might interact with both positive and negative valence factors and affect a customer's adoption of mobile payment services. Our SEM analysis indicated that trust indeed had a substantial impact on the cross-environment relationship and, further, that trust in combination with the positive and negative valence determinants directly and indirectly influenced behavioral intention. In addition, the magnitudes of these effects on workers and students were significantly different from each other.}
}

@INPROCEEDINGS{6038874,  author={Wilkowska, Wiktoria and Ziefle, Martina},  booktitle={2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth) and Workshops},   title={Perception of privacy and security for acceptance of E-health technologies: Exploratory analysis for diverse user groups},   year={2011},  volume={},  number={},  pages={593-600},  abstract={The present study explores perceived relevance of security and privacy aspects in different user groups and assesses the predictive power of these attributes on acceptance of medical assistive technologies. Based on previously conducted focus groups a questionnaire was developed and quantitative data from N = 104 persons were analyzed. In a descriptive manner opinions of adults in all stages of life (age groups from young, middle-aged to older people) as well as gender - and health-related are presented and discussed with regard to those characteristics, and differences between the groups are disclosed. In multivariate regressions follows the analysis of most predictive security and privacy attributes for the acceptance (i.e. perceived usefulness) of E-health technologies. Results show that both security and privacy aspects play an important role for acceptance and usage of medical assistive technologies.},  keywords={},  doi={10.4108/icst.pervasivehealth.2011.246027},  ISSN={2153-1641},  month={May},}

@inproceedings{huang2010cultural,
  title={Cultural Dimensions as Moderators of the UTAUT Model: a Research Proposal in a Healthcare Context.},
  author={Huang, Kuang-Yuan and Choi, Namjoo and Chengalur-Smith, InduShobha N},
  booktitle={AMCIS},
  pages={188},
  year={2010}
}

@article{SOHN2020101324,
title = {Technology acceptance theories and factors influencing artificial Intelligence-based intelligent products},
journal = {Telematics and Informatics},
volume = {47},
pages = {101324},
year = {2020},
issn = {0736-5853},
doi = {https://doi.org/10.1016/j.tele.2019.101324},
author = {Kwonsang Sohn and Ohbyung Kwon},
keywords = {AI-based intelligent products, Technology adoption, Purchase intention, Technology acceptance theory, Decomposition analysis},
abstract = {The rapid growth of artificial intelligence (AI) technology has prompted the development of AI-based intelligent products. Accordingly, various technology acceptance theories have been used to explain acceptance of these products. This comparative study determines which models best explain consumer acceptance of AI-based intelligent products and which factors have the greatest impact in terms of purchase intention. We assessed the utility of the Technology Acceptance Model (TAM), the Theory of Planned Behavior (TPB), the Unified Theory of Acceptance and Use of Technology (UTAUT), and the Value-based Adoption Model (VAM) using data collected from a survey sample of 378 respondents, modeling user acceptance in terms of behavioral intention to use AI-based intelligent products. In addition, we employed decomposition analysis to compare each factor included in these models in terms of influence on purchase intention. We found that the VAM performed best in modeling user acceptance. Among the various factors, enjoyment was found to influence user purchase intention the most, followed by subjective norms. The findings of this study confirm that acceptance of highly innovative products with minimal practical value, such as AI-based intelligent products, is more influenced by interest in technology than in utilitarian aspects.}
}

@inproceedings{10.1145/3018009.3018010,
author = {Hamzah, Almed and Wahid, Fathul},
title = {Participatory Design in the Development of Healthcare Systems: A Literature Review},
year = {2016},
isbn = {9781450348195},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3018009.3018010},
abstract = {This paper reports on a systematic literature review aimed at mapping current practices regarding the use of participatory design in the development of healthcare systems and identifying a future research roadmap. Our analysis of 52 papers revealed eight participatory design principles. These principles demand that designers pay attention to the actors' habits and perspectives; their relationship; their mastery of techniques, language and technology; and the implementation process and context. The review also identifies at least four future research avenues that suggest that researchers pay more attention to the variety of end users involved in the participatory design process, develop a common framework that can be used in various contexts, focus on a broader context (beyond hospital and home) in which the system is developed and used and examine what methods fit best with certain development contexts.},
booktitle = {Proceedings of the 2nd International Conference on Communication and Information Processing},
pages = {60–64},
numpages = {5},
keywords = {healthcare system, participatory design, human-computer interaction},
location = {Singapore, Singapore},
series = {ICCIP '16}
}

@article{doi:10.1148/ryai.2020190043,
author = {Reyes, Mauricio and Meier, Raphael and Pereira, Sérgio and Silva, Carlos                             A. and Dahlweid, Fried-Michael and Tengg-Kobligk, Hendrik                             von and Summers, Ronald                             M. and Wiest, Roland},
title = {On the Interpretability of Artificial Intelligence in Radiology:                     Challenges and Opportunities},
journal = {Radiology: Artificial Intelligence},
volume = {2},
number = {3},
pages = {e190043},
year = {2020},
doi = {10.1148/ryai.2020190043},
abstract = { As artificial intelligence (AI) systems begin to make their way into clinical radiology practice, it is crucial to assure that they function correctly and that they gain the trust of experts. Toward this goal, approaches to make AI “interpretable” have gained attention to enhance the understanding of a machine learning algorithm, despite its complexity. This article aims to provide insights into the current state of the art of interpretability methods for radiology AI. This review discusses radiologists’ opinions on the topic and suggests trends and challenges that need to be addressed to effectively streamline interpretability methods in clinical practice. Supplemental material is available for this article. Keywords: Convolutional Neural Network (CNN), Informatics, Radiomics, Supervised learning, Technology Assessment © RSNA, 2020 See also the commentary by Gastounioti and Kontos in this issue. }
}

@article{WAYMEL2019327,
title = {Impact of the rise of artificial intelligence in radiology: What do radiologists think?},
journal = {Diagnostic and Interventional Imaging},
volume = {100},
number = {6},
pages = {327-336},
year = {2019},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2019.03.015},
author = {Q. Waymel and S. Badr and X. Demondion and A. Cotten and T. Jacques},
keywords = {Artificial intelligence (AI), Radiologists, Machine learning, Survey},
abstract = {Purpose
The purpose of this study was to assess the perception, knowledge, wishes and expectations of a sample of French radiologists towards the rise of artificial intelligence (AI) in radiology.
Material and method
A general data protection regulation-compliant electronic survey was sent by e-mail to the 617 radiologists registered in the French departments of Nord and Pas-de-Calais (93 radiology residents and 524 senior radiologists), from both public and private institutions. The survey included 42 questions focusing on AI in radiology, and data were collected between January 16th and January 31st, 2019. The answers were analyzed together by a senior radiologist and a radiology resident.
Results
A total of 70 radiology residents and 200 senior radiologists participated to the survey, which corresponded to a response rate of 43.8\% (270/617). One hundred ninety-eight radiologists (198/270; 73.3\%) estimated they had received insufficient previous information on AI. Two hundred and fifty-five respondents (255/270; 94.4\%) would consider attending a generic continuous medical education in this field and 187 (187/270; 69.3\%) a technically advanced training on AI. Two hundred and fourteen respondents (214/270; 79.3\%) thought that AI will have a positive impact on their future practice. The highest expectations were the lowering of imaging-related medical errors (219/270; 81\%), followed by the lowering of the interpretation time of each examination (201/270; 74.4\%) and the increase in the time spent with patients (141/270; 52.2\%).
Conclusion
While respondents had the feeling of receiving insufficient previous information on AI, they are willing to improve their knowledge and technical skills on this field. They share an optimistic view and think that AI will have a positive impact on their future practice. A lower risk of imaging-related medical errors and an increase in the time spent with patients are among their main expectations.}
}

@article{AMEEN2021106548,
title = {Customer experiences in the age of artificial intelligence},
journal = {Computers in Human Behavior},
volume = {114},
pages = {106548},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106548},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220302983},
author = {Nisreen Ameen and Ali Tarhini and Alexander Reppel and Amitabh Anand},
keywords = {Artificial intelligence, Customer experience, Trust-commitment theory, trust, Beauty brands, COVID 19},
abstract = {Artificial intelligence (AI) is revolutionising the way customers interact with brands. There is a lack of empirical research into AI-enabled customer experiences. Hence, this study aims to analyse how the integration of AI in shopping can lead to an improved AI-enabled customer experience. We propose a theoretical model drawing on the trust-commitment theory and service quality model. An online survey was distributed to customers who have used an AI- enabled service offered by a beauty brand. A total of 434 responses were analysed using partial least squares-structural equation modelling. The findings indicate the significant role of trust and perceived sacrifice as factors mediating the effects of perceived convenience, personalisation and AI-enabled service quality. The findings also reveal the significant effect of relationship commitment on AI-enabled customer experience. This study contributes to the existing literature by revealing the mediating effects of trust and perceived sacrifice and the direct effect of relationship commitment on AI-enabled customer experience. In addition, the study has practical implications for retailers deploying AI in services offered to their customers.}
}

@book{2019-07124-034,
author={Mueller, Ralph O.
and Hancock, Gregory R.},
title={Structural Equation Modeling.},
series={The reviewer's guide to quantitative methods in the social sciences, 2nd ed.},
year={2019},
publisher={Routledge/Taylor {\&} Francis Group},
address={New York,  NY,  US},
pages={445--456},
keywords={Structural Equation Modeling; Confirmatory Factor Analysis; Path Analysis; Statistics},
abstract={Structural equation modeling (SEM) represents a theory-driven data analytical approach for the evaluation of a priori specified hypotheses about causal relations among measured and/or latent variables. Such hypotheses may be expressed in a variety of forms, with the most common being measured variable path analysis models, confirmatory factor analysis models, and latent variable path analysis models. For analyzing models of these as well as more complex types, SEM is not viewed as a mere statistical technique but rather as an analytical process involving model conceptualization, parameter identification and estimation, data-model fit assessment, and potential model re-specification. Ultimately, this process allows for the assessment of fit between (typically) correlational data, obtained from experimental or non-experimental research, and one or more competing causal theories specified a priori; most common SEM applications are not designed for exploratory purposes. Software packages such as AMOS, EQS, lavaan, LISREL, Mx, and Mplus are utilized to complete the computational aspects of the overall SEM process. For contemporary treatments of SEM the authors recommend texts by Byrne, Kline, and Loehlin and Beaujean, or, for more advanced readers, books by Bollen, Hancock and Mueller, Hoyle, and Kaplan. This chapter presents specific desiderata for applied studies that utilize SEM. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
isbn={9781138800120 (Hardcover); 978-1-138-80013-7 (Paperback); 978-1-315-75564-9 (Digital)},
doi={10.4324/9781315755649-33},
url={https://doi.org/10.4324/9781315755649-33}
}

@INPROCEEDINGS{9197782,
  author={Malik, Priyanka and Gautam, Shalini and Srivastava, Shreya},
  booktitle={2020 8th International Conference on Reliability, Infocom Technologies and Optimization (Trends and Future Directions) (ICRITO)}, 
  title={A Study on Behaviour Intention for using Chatbots}, 
  year={2020},
  volume={},
  number={},
  pages={332-338},
  abstract={The present study uses the primary research to find out the behavior intention of an individual to use chatbots. The study has taken the five dimensions viz., reliability, responsiveness, assurance, empathy and tangibility and find out their association with behavior intention of an individual to use the chatbots. The sample of 270 respondents are taken to conclude the findings. It was concluded that out of these five dimensions, three dimensions are significantly associated with intention of using chatbots. These are reliability, empathy and tangibility.},
  keywords={},
  doi={10.1109/ICRITO48877.2020.9197782},
  month={June}
}

@article{GANSSER2021101535,
title = {A new acceptance model for artificial intelligence with extensions to UTAUT2: An empirical study in three segments of application},
journal = {Technology in Society},
volume = {65},
pages = {101535},
year = {2021},
issn = {0160-791X},
doi = {https://doi.org/10.1016/j.techsoc.2021.101535},
url = {https://www.sciencedirect.com/science/article/pii/S0160791X21000105},
author = {Oliver Alexander Gansser and Christina Stefanie Reich},
keywords = {Artificial intelligence, Technology acceptance, Consumer behavior, User acceptance, Structural equation model},
abstract = {More and more products in everyday life are using artificial intelligence (AI). The purpose of this research is to investigate influence factors in an acceptance model on behavioral intention and use behavior for products containing AI in an everyday life environment. Using PLS-Analysis, this study analyzes additional influence factors to the UTAUT2 model in the three application segments mobility, household, and health, using a sample of 21,841 respondents. Except for safety security, all additional factors to the UTAUT2 model play a relevant role in explaining behavioral intention and use behavior of products containing AI. This study answers the applicability of an established acceptance model for products that incorporate AI, extended by five additional influencing factors.}
}

@article{SUMAK2016602,
title = {The acceptance and use of interactive whiteboards among teachers: Differences in UTAUT determinants between pre- and post-adopters},
journal = {Computers in Human Behavior},
volume = {64},
pages = {602-620},
year = {2016},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2016.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0747563216305271},
author = {Boštjan Šumak and Andrej Šorgo},
keywords = {Interactive learning environment, Interactive whiteboard, Technology acceptance, UTAUT},
abstract = {With the spread of new educational technology such as the interactive whiteboard (IWB) teachers, as potential users, need to adapt their teaching in order to successfully utilize it. Despite considerable efforts in motivating teachers to use new educational technology, there are mixed feelings about whether to accept and use this technology in the classroom or not. In this study we propose to extend the Unified Theory of Acceptance and Use of Technology (UTAUT) with a new moderator variable user type in order to investigate differences in the UTAUT determinants between pre- and post-adopters of IWBs. The results of the study showed significant differences in causal effect sizes between pre- and post-adopters for several paths of the proposed research model. When compared to post-adopters, we can see that for pre-adopters: 1) social influence has a bigger impact on behavioral intentions, 2) performance expectancy more strongly affects attitudes toward using IWBs, and 3) there is a difference in attitudes towards using IWB on users' potential use of IWBs. For post-adopters: 4) the facilitating conditions have a bigger impact on the actual use of IWBs, and 5) behavioral intention is a stronger predictor of the actual use of IWBs when compared with pre-adopters.}
}

@article{doi:10.1504/IJMDA.2017.087624,
author = {Hair, Joe F. and Matthews, Lucy M. and Matthews, Ryan L. and Sarstedt, Marko},
title = {PLS-SEM or CB-SEM: updated guidelines on which method to use},
journal = {International Journal of Multivariate Data Analysis},
volume = {1},
number = {2},
pages = {107-123},
year = {2017},
doi = {10.1504/IJMDA.2017.087624},
abstract = { Numerous statistical methods are available for social researchers. Therefore, knowing the appropriate technique can be a challenge. For example, when considering structural equation modelling (SEM), selecting between covariance-based (CB-SEM) and variance-based partial least squares (PLS-SEM) can be challenging. This paper applies the same theoretical measurement and structural models and dataset to conduct a direct comparison. The findings reveal that when using CB-SEM, many indicators are removed to achieve acceptable goodness-of-fit, when compared to PLS-SEM. Also, composite reliability and convergent validity were typically higher using PLS-SEM, but other metrics such as discriminant validity and beta coefficients are comparable. Finally, when comparing variance explained in the dependent variable indicators, PLS-SEM was substantially better than CB-SEM. Updated guidelines assist researchers in determining whether CB-SEM or PLS-SEM is the most appropriate method to use. }
}

@article{doi:10.1080/00273171.2019.1602503,
author = {Herbert W. Marsh and Jiesi Guo and Theresa Dicke and Philip D. Parker and Rhonda G. Craven},
title = {Confirmatory Factor Analysis (CFA), Exploratory Structural Equation Modeling (ESEM), and Set-ESEM: Optimal Balance Between Goodness of Fit and Parsimony},
journal = {Multivariate Behavioral Research},
volume = {55},
number = {1},
pages = {102-119},
year  = {2020},
publisher = {Routledge},
doi = {10.1080/00273171.2019.1602503}
}

@article{ZHOU2010760,
title = {Integrating TTF and UTAUT to explain mobile banking user adoption},
journal = {Computers in Human Behavior},
volume = {26},
number = {4},
pages = {760-767},
year = {2010},
note = {Emerging and Scripted Roles in Computer-supported Collaborative Learning},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2010.01.013},
author = {Tao Zhou and Yaobin Lu and Bin Wang},
keywords = {Task technology fit (TTF), Unified theory of acceptance and usage of technology (UTAUT), Mobile banking, User adoption},
abstract = {Due to its advantages such as ubiquity and immediacy, mobile banking has attracted traditional banks’ interests. However, a survey report showed that user adoption of mobile banking was much lower than that of other mobile services. The extant research focuses on explaining user adoption from technology perceptions such as perceived usefulness, perceived ease of use, interactivity, and relative advantage. However, users’ adoption is determined not only by their perception of the technology but also by the task technology fit. In other words, even though a technology may be perceived as being advanced, if it does not fit users’ task requirements, they may not adopt it. By integrating the task technology fit (TTF) model and the unified theory of acceptance and usage of technology (UTAUT), this research proposes a mobile banking user adoption model. We found that performance expectancy, task technology fit, social influence, and facilitating conditions have significant effects on user adoption. In addition, we also found a significant effect of task technology fit on performance expectancy.}
}

@article{doi:10.1080/10705511.2017.1401932,
author = {Elena Martynova and Stephen G. West and Yu Liu},
title = {Review of Principles and Practice of Structural Equation Modeling},
journal = {Structural Equation Modeling: A Multidisciplinary Journal},
volume = {25},
number = {2},
pages = {325-329},
year  = {2018},
publisher = {Routledge},
doi = {10.1080/10705511.2017.1401932}

}

@article{LI2021106929,
title = {Designing medical artificial intelligence for in- and out-groups},
journal = {Computers in Human Behavior},
volume = {124},
pages = {106929},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106929},
author = {Wanyue Li and Xinyue Zhou and Qian Yang},
keywords = {Medical artificial intelligence design, Out-group homogeneity effect, Health inequity, Experiment},
abstract = {Medical artificial intelligence (AI) is expected to deliver worldwide access to healthcare. Through three experimental studies with Chinese and American participants, we tested how the design of medical AI varies between in- and out-groups. Participants adopted the role of a medical AI designer and decided how to develop medical AI for in- or out-groups based on their experimental condition. Studies 1 (pre-registered: N = 191) revealed that Chinese participants were less likely to adopt human doctors' assistance in medical AI system when targeting patients from US (i.e., out-groups) than for patients from China (i.e., in-groups). Study 2 (N = 190) revealed that US participants were less likely to adopt human doctors' assistance in medical AI system when targeting patients from China (i.e., out-groups) than for patients from US (i.e., in-groups). Study 3 revealed that Chinese medical students (N = 160) selected a smaller training database for AI when diagnosing diabetic retinopathy among US patients (i.e., out-groups) than for Chinese patients (i.e., in-groups), and this effect was stronger among medical students from higher (vs. lower) socioeconomic backgrounds. This AI design inequity was mediated by individuals’ underestimation of out-group heterogeneity. Overall, our evidence suggests that out-group stereotype shapes the design of medical AI, unwittingly undermining healthcare quality. The current findings underline the need for more robust data on medical AI development and intervention research addressing healthcare inequity.}
}

@article{LI2021106581,
title = {Adoption of online follow-up service by patients: An empirical study based on the elaboration likelihood model},
journal = {Computers in Human Behavior},
volume = {114},
pages = {106581},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106581},
author = {Chao-Ran Li and E. Zhang and Jing-Ti Han},
keywords = {E-health, Online health community, Elaboration likelihood model, Service quality, Electronic word-of-mouth, Disease type},
abstract = {The rapid development of Web 2.0 technologies has made it possible for online health communities to provide convenient platforms that enable doctors to provide medical services and enable patients to consult the doctors online. When patients finish medical treatment in offline hospitals, they can find the doctor for online follow-up service at the post-diagnosis step. To understand which factors can affect patients’ decisions on adopting an online follow-up service, this paper drew on the Elaboration Likelihood Model as the theoretical base to study patients’ decision process. We regarded the technical quality and interpersonal quality of doctors’ medical service as central cues and considered electronic word-of-mouth (eWOM) as a peripheral cue. By analyzing the data from a popular online health community in China, the results show that the technical quality, interpersonal quality, and eWOM of doctors’ medical services positively impacted patients’ online follow-up intention. Moreover, we also found that high-privacy disease and private doctor service significantly moderate the relationship between technical quality or eWOM of doctors’ medical services and patients’ online follow-up intention. Our study sheds some light on profoundly understanding the decision process of patients in using online follow-up services and contributes to the research of online healthcare services.}
}

@article{LIU2022107026,
title = {The roles of trust, personalization, loss of privacy, and anthropomorphism in public acceptance of smart healthcare services},
journal = {Computers in Human Behavior},
volume = {127},
pages = {107026},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107026},
author = {Kaifeng Liu and Da Tao},
keywords = {Smart healthcare, Trust, Personalization, Privacy, Anthropomorphism, Technology acceptance},
abstract = {AI-based smart healthcare services are emerging as promising tools to improve efficiency and effectiveness of healthcare service delivery. This study aimed to examine the roles of trust and three AI-specific characteristics (i.e., personalization, loss of privacy, anthropomorphism) in public acceptance of smart healthcare services based on an extended Technology Acceptance Model. The model's validity was confirmed using a partial least squares structural equation modeling technique based on data collected from 769 survey samples. Multigroup analyses were conducted to determine whether the path coefficients differed by gender, age, and usage experience. The results showed that perceived usefulness, perceived ease of use, and the three AI-specific characteristics were important determinants of public acceptance of smart healthcare services, whose roles were fully or partially mediated by trust. Trust, perceived usefulness, and personalization directly determined behavioral intention to use smart healthcare services. The relationships among antecedent factors and behavioral intention to use smart healthcare services were also moderated by gender, age, and usage experience. The study demonstrated the critical roles of personalization, loss of privacy, and anthropomorphism in shaping public trust and acceptance of smart healthcare services. The results offer important theoretical and practical implications for the design and implementation of such services.}
}

@article{SIGERSON201887,
title = {Scales for measuring user engagement with social network sites: A systematic review of psychometric properties},
journal = {Computers in Human Behavior},
volume = {83},
pages = {87-105},
year = {2018},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2018.01.023},
url = {https://www.sciencedirect.com/science/article/pii/S0747563218300293},
author = {Leif Sigerson and Cecilia Cheng},
keywords = {Social network site, Social networking site, Social media, Psychometrics, Validation, Facebook},
abstract = {In the past decade, various scales have been developed for measuring engagement with social network sites (SNS), but validity concerns have recently been raised about some of them. The present study thus provides a systematic review of the psychometric properties of these scales. This review included articles that aimed at either developing an SNS engagement scale or providing a systematic test of the psychometric properties of the scale. We conducted keyword-based searches of several broad multidisciplinary databases, along with reference list searches and article citation searches. These search strategies yielded a total of 14 reports, revealing validation evidence for 12 SNS engagement scales among 13,861 participants from 11 countries. There was mixed evidence for the various types of validity tests, with some scales having been validated more rigorously with multiple studies and samples while others having not yet been systematically validated. Sampling and acquiescence biases were also present for some scales. The present review provides recommendations for researchers intending to study SNS engagement. Although the literature search was multi-faceted, it may conceivably have missed studies that provided less rigorous validity evidence. Overall, this study contributes to evaluating and strengthening the methodological foundations of SNS research.}
}

@Article{info:doi/10.2196/27122,
author="Zhai, Huiwen
and Yang, Xin
and Xue, Jiaolong
and Lavender, Christopher
and Ye, Tiantian
and Li, Ji-Bin
and Xu, Lanyang
and Lin, Li
and Cao, Weiwei
and Sun, Ying",
title="Radiation Oncologists' Perceptions of Adopting an Artificial Intelligence--Assisted Contouring Technology: Model Development and Questionnaire Study",
journal="J Med Internet Res",
year="2021",
month="Sep",
day="30",
volume="23",
number="9",
pages="e27122",
keywords="artificial intelligence; technology acceptance model; intension; resistance",
abstract="Background: An artificial intelligence (AI)--assisted contouring system benefits radiation oncologists by saving time and improving treatment accuracy. Yet, there is much hope and fear surrounding such technologies, and this fear can manifest as resistance from health care professionals, which can lead to the failure of AI projects. Objective: The objective of this study was to develop and test a model for investigating the factors that drive radiation oncologists' acceptance of AI contouring technology in a Chinese context. Methods: A model of AI-assisted contouring technology acceptance was developed based on the Unified Theory of Acceptance and Use of Technology (UTAUT) model by adding the variables of perceived risk and resistance that were proposed in this study. The model included 8 constructs with 29 questionnaire items. A total of 307 respondents completed the questionnaires. Structural equation modeling was conducted to evaluate the model's path effects, significance, and fitness. Results: The overall fitness indices for the model were evaluated and showed that the model was a good fit to the data. Behavioral intention was significantly affected by performance expectancy ($\beta$=.155; P=.01), social influence ($\beta$=.365; P<.001), and facilitating conditions ($\beta$=.459; P<.001). Effort expectancy ($\beta$=.055; P=.45), perceived risk ($\beta$=−.048; P=.35), and resistance bias ($\beta$=−.020; P=.63) did not significantly affect behavioral intention. Conclusions: The physicians' overall perceptions of an AI-assisted technology for radiation contouring were high. Technology resistance among Chinese radiation oncologists was low and not related to behavioral intention. Not all of the factors in the Venkatesh UTAUT model applied to AI technology adoption among physicians in a Chinese context. ",
issn="1438-8871",
doi="10.2196/27122",
url="https://doi.org/10.2196/27122",
}

@Article{Belanche2019,
author={Belanche, Daniel
and Casal{\'o}, Luis V.
and Flavi{\'a}n, Carlos},
title={Artificial Intelligence in FinTech: understanding robo-advisors adoption among customers},
journal={Industrial Management {\&} Data Systems},
year={2019},
month={Jan},
day={01},
publisher={Emerald Publishing Limited},
volume={119},
number={7},
pages={1411-1430},
abstract={Purpose Considering the increasing impact of Artificial Intelligence (AI) on financial technology (FinTech), the purpose of this paper is to propose a research framework to better understand robo-advisor adoption by a wide range of potential customers. It also predicts that personal and sociodemographic variables (familiarity with robots, age, gender and country) moderate the main relationships. Design/methodology/approach Data from a web survey of 765 North American, British and Portuguese potential users of robo-advisor services confirm the validity of the measurement scales and provide the input for structural equation modeling and multisample analyses of the hypotheses. Findings Consumers' attitudes toward robo-advisors, together with mass media and interpersonal subjective norms, are found to be the key determinants of adoption. The influences of perceived usefulness and attitude are slightly higher for users with a higher level of familiarity with robots; in turn, subjective norms are significantly more relevant for users with a lower familiarity and for customers from Anglo-Saxon countries. Practical implications Banks and other firms in the finance industry should design robo-advisors to be used by a wide spectrum of consumers. Marketing tactics applied should consider the customer's level of familiarity with robots. Originality/value This research identifies the key drivers of robo-advisor adoption and the moderating effect of personal and sociodemographic variables. It contributes to understanding consumers' perceptions regarding the introduction of AI in FinTech.},
issn={0263-5577},
doi={10.1108/IMDS-08-2018-0368},
url={https://doi.org/10.1108/IMDS-08-2018-0368}
}

@article{DWIVEDI2016174,
title = {A generalised adoption model for services: A cross-country comparison of mobile health (m-health)},
journal = {Government Information Quarterly},
volume = {33},
number = {1},
pages = {174-187},
year = {2016},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2015.06.003},
author = {Yogesh K. Dwivedi and Mahmud Akhter Shareef and Antonis C. Simintiras and Banita Lal and Vishanth Weerakkody},
keywords = {Mobile health (m-health), Adoption behaviour, Consumer preference, Consumer behaviour, UTAUT model, Cultural effect},
abstract = {Which antecedents affect the adoption by users is still often a puzzle for policy-makers. Antecedents examined in this research include technological artefacts from the Unified Theory of Acceptance and Use of Technology (UTAUT), consumer context from UTAUT2 and psychological behaviour concepts such as citizens' channel preference and product selection criteria. This research also investigated cultural domination on citizens' behavioural perception. The data for this study was collected among citizens from three countries: USA, Canada, and Bangladesh. The findings suggest that the UTAUT model could partially shape technology artefact behaviour and the extended UTAUT must consider specific determinants relevant to cognitive, affective, and conative or behavioural aspects of citizens. The model helps policy-makers to develop mobile healthcare service system that will be better accepted. The finding also suggests that this mobile service system should reflect a country's cultural traits. These findings basically extend the theoretical concept of UTAUT model to articulate adoption behaviour of any complex and sensitive ICT related issues like mobile healthcare system.}
}

@article{WU2021106840,
title = {Perceived city smartness level and technical information transparency: The acceptance intention of health information technology during a lockdown},
journal = {Computers in Human Behavior},
volume = {122},
pages = {106840},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106840},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221001631},
author = {Wenqing Wu and Yenchun Jim Wu and Hongxin Wang},
keywords = {City smartness level, Perceived risk, Smart city, Technical information transparency, UTAUT model},
abstract = {With the acceleration of urbanization, effective smart city programs need to consider both daily management and crisis management. In this process, to enable health information technology to better contribute to the construction of smart cities, the government and firms need to pay attention to the public's intention to adopt technology. Based on the context of China's response to the COVID-19 pandemic in smart cities, we analyze the influencing factors of the behavioral intention to use health information technology using an extended unified theory of acceptance and use of technology model. Data for this study were collected from 721 inhabitants of 290 smart cities in China. The empirical results showed that performance expectations, effort expectations, social influence, and facilitating conditions positively affected their behavioral intention to use health information technology, whereas perceived risk had the opposite effect. This study found that the positive effects of social influence and effort expectations on the behavioral intention to use health information technology increased with improvement in the perceived level of city smartness and technical information transparency. Finally, we discuss theoretical and practical implications.}
}

@Article{Liang2019,
author={Liang, Huiying
and Tsui, Brian Y.
and Ni, Hao
and Valentim, Carolina C. S.
and Baxter, Sally L.
and Liu, Guangjian
and Cai, Wenjia
and Kermany, Daniel S.
and Sun, Xin
and Chen, Jiancong
and He, Liya
and Zhu, Jie
and Tian, Pin
and Shao, Hua
and Zheng, Lianghong
and Hou, Rui
and Hewett, Sierra
and Li, Gen
and Liang, Ping
and Zang, Xuan
and Zhang, Zhiqi
and Pan, Liyan
and Cai, Huimin
and Ling, Rujuan
and Li, Shuhua
and Cui, Yongwang
and Tang, Shusheng
and Ye, Hong
and Huang, Xiaoyan
and He, Waner
and Liang, Wenqing
and Zhang, Qing
and Jiang, Jianmin
and Yu, Wei
and Gao, Jianqun
and Ou, Wanxing
and Deng, Yingmin
and Hou, Qiaozhen
and Wang, Bei
and Yao, Cuichan
and Liang, Yan
and Zhang, Shu
and Duan, Yaou
and Zhang, Runze
and Gibson, Sarah
and Zhang, Charlotte L.
and Li, Oulan
and Zhang, Edward D.
and Karin, Gabriel
and Nguyen, Nathan
and Wu, Xiaokang
and Wen, Cindy
and Xu, Jie
and Xu, Wenqin
and Wang, Bochu
and Wang, Winston
and Li, Jing
and Pizzato, Bianca
and Bao, Caroline
and Xiang, Daoman
and He, Wanting
and He, Suiqin
and Zhou, Yugui
and Haw, Weldon
and Goldbaum, Michael
and Tremoulet, Adriana
and Hsu, Chun-Nan
and Carter, Hannah
and Zhu, Long
and Zhang, Kang
and Xia, Huimin},
title={Evaluation and accurate diagnoses of pediatric diseases using artificial intelligence},
journal={Nature Medicine},
year={2019},
month={Mar},
day={01},
volume={25},
number={3},
pages={433-438},
abstract={Artificial intelligence (AI)-based methods have emerged as powerful tools to transform medical care. Although machine learning classifiers (MLCs) have already demonstrated strong performance in image-based diagnoses, analysis of diverse and massive electronic health record (EHR) data remains challenging. Here, we show that MLCs can query EHRs in a manner similar to the hypothetico-deductive reasoning used by physicians and unearth associations that previous statistical methods have not found. Our model applies an automated natural language processing system using deep learning techniques to extract clinically relevant information from EHRs. In total, 101.6 million data points from 1,362,559 pediatric patient visits presenting to a major referral center were analyzed to train and validate the framework. Our model demonstrates high diagnostic accuracy across multiple organ systems and is comparable to experienced pediatricians in diagnosing common childhood diseases. Our study provides a proof of concept for implementing an AI-based system as a means to aid physicians in tackling large amounts of data, augmenting diagnostic evaluations, and to provide clinical decision support in cases of diagnostic uncertainty or complexity. Although this impact may be most evident in areas where healthcare providers are in relative shortage, the benefits of such an AI system are likely to be universal.},
issn={1546-170X},
doi={10.1038/s41591-018-0335-9},
}

@article{LIN2021e486,
title = {Application of Comprehensive Artificial intelligence Retinal Expert (CARE) system: a national real-world evidence study},
journal = {The Lancet Digital Health},
volume = {3},
number = {8},
pages = {e486-e495},
year = {2021},
issn = {2589-7500},
doi = {https://doi.org/10.1016/S2589-7500(21)00086-8},
author = {Duoru Lin and Jianhao Xiong and Congxin Liu and Lanqin Zhao and Zhongwen Li and Shanshan Yu and Xiaohang Wu and Zongyuan Ge and Xinyue Hu and Bin Wang and Meng Fu and Xin Zhao and Xin Wang and Yi Zhu and Chuan Chen and Tao Li and Yonghao Li and Wenbin Wei and Mingwei Zhao and Jianqiao Li and Fan Xu and Lin Ding and Gang Tan and Yi Xiang and Yongcheng Hu and Ping Zhang and Yu Han and Ji-Peng Olivia Li and Lai Wei and Pengzhi Zhu and Yizhi Liu and Weirong Chen and Daniel S W Ting and Tien Y Wong and Yuzhong Chen and Haotian Lin},
abstract = {Summary
Background
Medical artificial intelligence (AI) has entered the clinical implementation phase, although real-world performance of deep-learning systems (DLSs) for screening fundus disease remains unsatisfactory. Our study aimed to train a clinically applicable DLS for fundus diseases using data derived from the real world, and externally test the model using fundus photographs collected prospectively from the settings in which the model would most likely be adopted.
Methods
In this national real-world evidence study, we trained a DLS, the Comprehensive AI Retinal Expert (CARE) system, to identify the 14 most common retinal abnormalities using 207 228 colour fundus photographs derived from 16 clinical settings with different disease distributions. CARE was internally validated using 21 867 photographs and externally tested using 18 136 photographs prospectively collected from 35 real-world settings across China where CARE might be adopted, including eight tertiary hospitals, six community hospitals, and 21 physical examination centres. The performance of CARE was further compared with that of 16 ophthalmologists and tested using datasets with non-Chinese ethnicities and previously unused camera types. This study was registered with ClinicalTrials.gov, NCT04213430, and is currently closed.
Findings
The area under the receiver operating characteristic curve (AUC) in the internal validation set was 0·955 (SD 0·046). AUC values in the external test set were 0·965 (0·035) in tertiary hospitals, 0·983 (0·031) in community hospitals, and 0·953 (0·042) in physical examination centres. The performance of CARE was similar to that of ophthalmologists. Large variations in sensitivity were observed among the ophthalmologists in different regions and with varying experience. The system retained strong identification performance when tested using the non-Chinese dataset (AUC 0·960, 95% CI 0·957–0·964 in referable diabetic retinopathy).
Interpretation
Our DLS (CARE) showed satisfactory performance for screening multiple retinal abnormalities in real-world settings using prospectively collected fundus photographs, and so could allow the system to be implemented and adopted for clinical care.
Funding
This study was funded by the National Key R&D Programme of China, the Science and Technology Planning Projects of Guangdong Province, the National Natural Science Foundation of China, the Natural Science Foundation of Guangdong Province, and the Fundamental Research Funds for the Central Universities.
Translation
For the Chinese translation of the abstract see Supplementary Materials section.}
}

@article{LV2022106993,
title = {Artificial intelligence service recovery: The role of empathic response in hospitality customers’ continuous usage intention},
journal = {Computers in Human Behavior},
volume = {126},
pages = {106993},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106993},
author = {Xingyang Lv and Yufan Yang and Dazhi Qin and Xingping Cao and Hong Xu},
keywords = {Artificial intelligence (AI), Emotional intelligence, Service recovery, Empathy, Continuous usage intention},
abstract = {Artificial intelligence (AI) service failures are inevitable in hospitality companies; thus, how AI service recovery retains customers is an issue that cannot be ignored. This article focuses on AI service recovery, abandoning the traditional “intelligence quotient” thinking and exploring the recovery effect of empathy response from the perspective of emotional intelligence. Using four experimental scenarios, the results indicate that, in service recovery, a high-empathy AI response can increase customers’ continuous usage intention, and psychological distance and trust are sequential mediators in this process. Compared with mono-sensory stimulus interactions (text only), a high-empathy response that adopts multisensory stimulus interactions (text and voice) could strengthen the recovery effect of empathy responses. This paper extends the field of AI service research from a focus on time and phase to the continuing use of AI after service failure. It also moves beyond the traditional intelligence quotient improvement thinking and reveals the importance of using AI emotional intelligence to activate customer emotional response in AI service recovery. Finally, it provides a useful tool for resolving AI service failure problems autonomously in the service process, which is of great value to research and development and hospitality operators in the promotion and application of AI services.}
}

@article{DEANGELI2020102412,
title = {Desires for active ageing technology},
journal = {International Journal of Human-Computer Studies},
volume = {138},
pages = {102412},
year = {2020},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102412},
author = {Antonella {De Angeli} and Mlađan Jovanović and Andrew McNeill and Lynne Coventry},
keywords = {Older adults, Active ageing technology, User requirements, User desires, Design guidelines},
abstract = {Several technological devices have been developed over the last decade to support an active lifestyle as people age. Despite substantial investment, they have failed to reach widespread acceptance. Limited adoption can be linked to little involvement of prospective users in the design process and overreliance on deficit models of ageing that portray people in decline. The paper proposes a structured methodology to collect user requirements based on the Integrated Behavioural Model. The methodology was applied in an interview study investigating behavioural intentions of preferred activities in a sample of 18 older users. Results have been elaborated as desires for actions in a model which puts the person (described in terms of attitudes, perceived norms and personal agency) to the forefront of the designer's attention. The model is contrasted with related work on technology adoption and used to define trajectories for active ageing technology as design for pleasurable and resourceful ageing.}
}

@article{BOOTSMAN201999,
title = {Wearable technology for posture monitoring at the workplace},
journal = {International Journal of Human-Computer Studies},
volume = {132},
pages = {99-111},
year = {2019},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2019.08.003},
author = {Rik Bootsman and Panos Markopoulos and Qi Qi and Qi Wang and Annick AA Timmermans},
keywords = {Smart garments, Interactive clothing, Posture correction, Low back pain, Persuasive technology, Nurse, User test, Awareness},
abstract = {Prolonged strenuous postures in occupational context may lead to low back pain. Avoiding such occurrences is known to help prevent low back pain episodes or may contribute to recovery. This research concerns wearable sensing technology to support posture monitoring for the prevention of occupational low back pain and, more specifically, how smart garments can help nurses avoid prolonged strenuous postures at work. We introduce BackUp, a system comprising of a smart shirt connected to a smartphone application that provides feedback and advice on low back posture, and we describe its design and implementation. We report on a series of studies that contributed to its development: an anthropometric study (N = 60) to decide on the placement of sensors on the lower spine; a brief field study aimed at evaluating user experience and attitudes towards the shirt (N = 17), and a second field study intended to assess its effectiveness in helping nurses avoid prolonged strenuous postures at work (N = 13). These studies demonstrate how smart clothing can support posture feedback in real life conditions. While the results from the field studies are encouraging regarding the potential of this technology, further research is needed to establish the durability of the behaviour modification achieved through smart garments.}
}

@article{HART201993,
title = {Is it all about the Apps or the Device?: User experience and technology acceptance among iPad users},
journal = {International Journal of Human-Computer Studies},
volume = {130},
pages = {93-112},
year = {2019},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2019.05.002},
author = {Jennefer Hart and Alistair Sutcliffe},
keywords = {User experience, Longitudinal study, iPad, Applications, Technology adoption},
abstract = {A longitudinal study of user experience and technology adoption was conducted with medical students using iPads for work and leisure over a six-month period. Measures of usability, ease of use, utility and hedonic qualities were taken for the iPad and downloaded applications. Usability and ease of use increased over the six months but hedonic quality did not. Quantitative and qualitative measures of utility, user experience and effectiveness were compared for the iPad and applications. Applications scored better on utility but not usability. All users continued to use their iPads and apps for learning and leisure. A follow-up study was carried out to compare medical students who had stopped using their iPads after the initial study period. Pre-use measures showed no differences between the adopter and non-adopter cohorts, but measures during use were significantly worse on all measures for non-adopters. The main reasons for rejections were lack of training, prior predisposition not to adopt new technology, and lack of motivation. Differences between the cohorts were more marked for applications than for the iPad measures, suggesting that application functionality was the key influence on technology adoption.}
}

@article{MCGLYNN201733,
title = {Understanding the potential of PARO for healthy older adults},
journal = {International Journal of Human-Computer Studies},
volume = {100},
pages = {33-47},
year = {2017},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.12.004},
author = {Sean A. McGlynn and Shawn Kemple and Tracy L. Mitzner and Chih-Hung Aaron King and Wendy A. Rogers},
keywords = {Aging, Active Engagement, Emotions, Human-Robot Interaction, PARO, Technology Acceptance},
abstract = {As the population ages, there is an increasing need for socio-emotional support for older adults. A potential way to meet this need is through interacting with pet-type robots such as the seal robot, PARO. There was a need to extend research on PARO's potential benefits beyond cognitively impaired and dependently living older adults. Because independently living, cognitively intact older adults may also have socio-emotional needs, the primary goal of this study was to investigate their attitudes, emotions, and engagement with PARO to identify its potential applicability to this demographic. Thirty older adults participated in an interaction period with PARO, and their attitudes and emotions toward PARO were assessed before and after using a multi-method approach. Video of the interaction was coded to determine the types and frequency of engagements participants initiated with PARO. Overall, there were no pre-post interaction differences on these measures. However, semi-structured interviews suggested that these older adults had positive attitudes towards PARO's attributes, thought it would be easy to use, and perceived potential uses for both themselves and others. Participants varied in their frequency of engagement with PARO. A novel finding is that this active engagement frequency uniquely predicted post-interaction period positive affect. This study advances understanding of healthy older adults’ attitudes, emotions, and engagement with PARO and of possible ways in which PARO could provide social and emotional support to healthy older adults. The results are informative for future research and design of pet-type robots.}
}

@article{MOORE2022102784,
title = {The impact of the physical and social embodiment of voice user interfaces on user distraction},
journal = {International Journal of Human-Computer Studies},
volume = {161},
pages = {102784},
year = {2022},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2022.102784},
author = {Billie Akwa Moore and Jacqueline Urakami},
keywords = {Speech technology, Distraction, Serious games, Embodiment, Anthropomorphism, Calm technology},
abstract = {The concept of calm technology envisions that interaction with technology should consume minimal resources and cause as few distractions as possible. The main goal of our study was to compare different forms of embodiment of Voice User Interfaces (VUI) in terms of how much they distract a user from a cognitive task. We used a voice-only system without physical embodiment (voice-only), a physical embodied system without anthropomorphic features (physical embodied), and a social embodied VUI with social cues such as eye movements (social embodied). In addition, we explored the relationship between design features of the VUI and perceived distraction, social presence, and perceived calm. Twenty-four participants carried out four different cognitive tasks with the three different VUI and one round of cognitive tasks without any VUI present. The cognitive tasks were chosen from a serious game (BrainTagger Suit) and included measurements of cognitive speed, working memory, visual memory, and process inhibition. Overall, results indicated the voice-only VUI caused the least distraction, especially for cognitive speed, while slightly showing impairment for visual memory. Social embodied VUI appeared to cause the most distraction across the four cognitive tasks with physical embodied VUI falling in between. Surprisingly, social presence was perceived as highest for the voice-only system which at the same time received the lowest scores for perceived calm. The advantages and disadvantages of each VUI are discussed.}
}

@article{HOEHLE201635,
title = {Leveraging Microsoft's mobile usability guidelines: Conceptualizing and developing scales for mobile application usability},
journal = {International Journal of Human-Computer Studies},
volume = {89},
pages = {35-53},
year = {2016},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.02.001},
author = {Hartmut Hoehle and Ruba Aljafari and Viswanath Venkatesh},
keywords = {Mobile application usability, Mobile human–computer interaction, Mobility, Continued use, Survey},
abstract = {This research conceptualizes mobile application usability and develops and validates an instrument to measure the same. Mobile application usability has attracted widespread attention in the field of human–computer interaction because well-designed applications can enhance user experiences. To conceptualize mobile application usability, we analyzed Microsoft’s mobile usability guidelines and defined 10 constructs representing mobile application usability. Next, we conducted a pilot study followed by a quantitative assessment of the content validity of the scales. We then sequentially applied exploratory factor analysis and confirmatory factor analysis to two samples (n=404; n=501) consisting of German consumers using mobile social media applications on their smartphones. To evaluate the confirmatory factor model, we followed a step-by-step process assessing unidimensionality, discriminant validity and reliability. To assess the nomological validity of our instrument, we examined the impact of mobile application usability on two outcomes: continued intention to use and brand loyalty. The results confirmed that mobile application usability was a good predictor of both outcomes. The constructs and scales associated with mobile application usability validated in this paper can be used to guide future research in human–computer interaction and aid in the effective design of mobile applications.}
}

@ARTICLE{9473208,
author = {H. Muller and M. Mayrhofer and E. Van Veen and A. Holzinger},
journal = {Computer},
title = {The Ten Commandments of Ethical Medical AI},
year = {2021},
volume = {54},
number = {07},
issn = {1558-0814},
pages = {119-123},
abstract = {We propose ten commandments as practical guidelines for those applying artificial intelligence to provide a concise checklist to a wide group of stakeholders. },
keywords = {artificial intelligence;medical services;medical diagnostic imaging;ethics;stakeholders},
doi = {10.1109/MC.2021.3074263},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month = {jul}
}

@article{EVANS2022281,
title = {The explainability paradox: Challenges for xAI in digital pathology},
journal = {Future Generation Computer Systems},
volume = {133},
pages = {281-296},
year = {2022},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.03.009},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22000838},
author = {Theodore Evans and Carl Orge Retzlaff and Christian Geißler and Michaela Kargl and Markus Plass and Heimo Müller and Tim-Rasmus Kiehl and Norman Zerbe and Andreas Holzinger},
keywords = {Explainable AI, Digital pathology, Usability, Trust, Artificial intelligence},
abstract = {The increasing prevalence of digitised workflows in diagnostic pathology opens the door to life-saving applications of artificial intelligence (AI). Explainability is identified as a critical component for the safety, approval and acceptance of AI systems for clinical use. Despite the cross-disciplinary challenge of building explainable AI (xAI), very few application- and user-centric studies in this domain have been carried out. We conducted the first mixed-methods study of user interaction with samples of state-of-the-art AI explainability techniques for digital pathology. This study reveals challenging dilemmas faced by developers of xAI solutions for medicine and proposes empirically-backed principles for their safer and more effective design.}
}

@article{MULLER202267,
title = {Explainability and causability for artificial intelligence-supported medical image analysis in the context of the European In Vitro Diagnostic Regulation},
journal = {New Biotechnology},
volume = {70},
pages = {67-72},
year = {2022},
issn = {1871-6784},
doi = {https://doi.org/10.1016/j.nbt.2022.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S1871678422000334},
author = {Heimo Müller and Andreas Holzinger and Markus Plass and Luka Brcic and Cornelia Stumptner and Kurt Zatloukal},
keywords = {Medical AI, Retractability, Causability, Explainability, Scientific validity, Regulatory requirements, IVDR, In vitro diagnostic device regulation},
abstract = {Artificial Intelligence (AI) for the biomedical domain is gaining significant interest and holds considerable potential for the future of healthcare, particularly also in the context of in vitro diagnostics. The European In Vitro Diagnostic Medical Device Regulation (IVDR) explicitly includes software in its requirements. This poses major challenges for In Vitro Diagnostic devices (IVDs) that involve Machine Learning (ML) algorithms for data analysis and decision support. This can increase the difficulty of applying some of the most successful ML and Deep Learning (DL) methods to the biomedical domain, just by missing the required explanatory components from the manufacturers. In this context, trustworthy AI has to empower biomedical professionals to take responsibility for their decision-making, which clearly raises the need for explainable AI methods. Explainable AI, such as layer-wise relevance propagation, can help in highlighting the relevant parts of inputs to, and representations in, a neural network that caused a result and visualize these relevant parts. In the same way that usability encompasses measurements for the quality of use, the concept of causability encompasses measurements for the quality of explanations produced by explainable AI methods. This paper describes both concepts and gives examples of how explainability and causability are essential in order to demonstrate scientific validity as well as analytical and clinical performance for future AI-based IVDs.}
}

@Article{Alharbi2016,
author={Alharbi, Fawaz
and Atkins, Anthony
and Stanier, Clare},
title={Understanding the determinants of Cloud Computing adoption in Saudi healthcare organisations},
journal={Complex {\&} Intelligent Systems},
year={2016},
month={Oct},
day={01},
volume={2},
number={3},
pages={155-171},
abstract={Cloud Computing is an evolving information technology paradigm that impacts many sectors in many countries. Although Cloud Computing is an emerging technology there is little in the literature concerning its application in the Saudi healthcare sector. This paper examines and identifies the factors that will influence the adoption of Cloud Computing in Saudi healthcare organisations. The study integrates the TOE (Technology--Organization--Environment) framework with the Information System Strategic Triangle (IS Triangle) and the HOT-fit (Human--Organization--Technology) model to provide a holistic evaluation of the determinants of Cloud Computing adoption in healthcare organisations. Of the five perspectives examined in this study, the Business perspective was found to be the most important followed by the Technology, Organisational and Environmental perspectives and finally the Human perspective. The findings of the study showed that the five most important factors influencing the adoption of Cloud Computing in this context are soft financial analysis, relative advantage, hard financial analysis, attitude toward change and pressure from partners in the business ecosystem. This study identifies the critical factors for both practitioners and academics that influence Cloud Computing adoption decision-making in Saudi healthcare.},
issn={2198-6053},
doi={10.1007/s40747-016-0021-9},
url={https://doi.org/10.1007/s40747-016-0021-9}
}

@article{doi:10.1080/10705511.2019.1615835,
author = {Lan Luo and Cara Arizmendi and Kathleen M. Gates},
title = {Exploratory Factor Analysis (EFA) Programs in R},
journal = {Structural Equation Modeling: A Multidisciplinary Journal},
volume = {26},
number = {5},
pages = {819-826},
year  = {2019},
publisher = {Routledge},
doi = {10.1080/10705511.2019.1615835},

URL = { 
        https://doi.org/10.1080/10705511.2019.1615835
    
},
eprint = { 
        https://doi.org/10.1080/10705511.2019.1615835
    
}

}

@article{wallis2019artificial,
  title={How artificial intelligence will change medicine},
  author={Wallis, Claudia},
  journal={Nature},
  volume={576},
  number={7787},
  pages={S48--S48},
  year={2019},
  publisher={Nature Publishing Group}
}

@article {Buch143,
	author = {Buch, Varun H and Ahmed, Irfan and Maruthappu, Mahiben},
	title = {Artificial intelligence in medicine: current trends and future possibilities},
	volume = {68},
	number = {668},
	pages = {143--144},
	year = {2018},
	doi = {10.3399/bjgp18X695213},
	publisher = {Royal College of General Practitioners},
	issn = {0960-1643},
	journal = {British Journal of General Practice}
}

@article{PELAU2021106855,
title = {What makes an AI device human-like? The role of interaction quality, empathy and perceived psychological anthropomorphic characteristics in the acceptance of artificial intelligence in the service industry},
journal = {Computers in Human Behavior},
volume = {122},
pages = {106855},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.106855},
author = {Corina Pelau and Dan-Cristian Dabija and Irina Ene},
keywords = {Artificial intelligence, Consumer behaviour, AI device, Anthropomorphism, Human-AI interaction, Computers as social actors, Human-computer interaction, Robots},
abstract = {Intelligent AI devices have become a common presence in the business landscape, offering a wide range of services, from the medical sector to the hospitality industry. From an organizational perspective, AI devices have several advantages, by performing certain tasks quicker and more accurately in comparison to humans while at the same time being more cost-efficient. However, in order to maintain the high standards of a brand, they have to be accepted by consumers and deliver socially adequate performance. Therefore, it is important to determine the characteristics of AI devices which make them accepted and trusted by consumers. Based on the Computers as Social Actors (CASA) Theory, we have researched on the role of psychological anthropomorphic characteristics, perceived empathy, and interaction quality in the acceptance of AI devices in the service industry. The results show that anthropomorphic characteristics alone do not influence acceptance and trust towards AI devices. However, both perceived empathy and interaction quality mediate the relation between anthropomorphic characteristics and acceptance. A human-like AI device has higher acceptance when it has the ability to show empathy and interaction in relation to the human consumer. This result reveals the importance of developing forms of strong intelligence and empathetic behaviour in service robots and AI devices.}
}

@article{STADIN2021106486,
title = {Technostress operationalised as information and communication technology (ICT) demands among managers and other occupational groups – Results from the Swedish Longitudinal Occupational Survey of Health (SLOSH)},
journal = {Computers in Human Behavior},
volume = {114},
pages = {106486},
year = {2021},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2020.106486},
url = {https://www.sciencedirect.com/science/article/pii/S0747563220302387},
author = {Magdalena Stadin and Maria Nordin and Anders Broström and Linda L. {Magnusson Hanson} and Hugo Westerlund and Eleonor I. Fransson},
abstract = {Exposure to technostress operationalised as ICT demands is more prevalent in higher socioeconomic groups, but little is known about the exposure in different occupational groups considering industry and position. The aim of the present study was to explore the exposure to ICT demands in managers and other occupational groups. Cross-sectional self-reported data from the Swedish Longitudinal Occupational Survey of Health (SLOSH), collected in 2016 was used, including 13 572 respondents (1 241 ‘managers’, 12 331 ‘non-managers’). ICT demands based on a six-item Likert scale were analysed as the main measure. ‘Managers’ (varying industries and positions) in comparison with ‘non-managers’, including nine occupational groups separated by industry and education level, showed the highest prevalence (74.7\%) of ICT demands. ‘Managers in health care, other community services and education’ showed the highest odds ratio (OR) with 95\% Confidence Intervals (CI) of ICT demands, in comparison with ‘non-managers’ (OR 4.64 [CI 3.26–6.61], and with ‘all other managers’ (OR 1.55 [CI 1.01–2.38]), after adjustment for sex, age, job strain, and social support. In conclusion, managers have increased odds of exposure to ICT demands, especially managers in health care, other community services and education. Targeted actions to improve the digitalised work environment among managers are warranted.}
}

@article{doi:10.1148/radiol.2020190283,
author = {Rauschecker, Andreas                            M. and Rudie, Jeffrey                            D. and Xie, Long and Wang, Jiancong and Duong, Michael                            Tran and Botzolakis, Emmanuel                            J. and Kovalovich, Asha                            M. and Egan, John and Cook, Tessa                        C. and Bryan, R.                        Nick and Nasrallah, Ilya                            M. and Mohan, Suyash and Gee, James                        C.},
title = {Artificial Intelligence System Approaching Neuroradiologist-level                    Differential Diagnosis Accuracy at Brain MRI},
journal = {Radiology},
volume = {295},
number = {3},
pages = {626-637},
year = {2020},
doi = {10.1148/radiol.2020190283},
abstract = { Background Although artificial intelligence (AI) shows promise across many aspects of radiology, the use of AI to create differential diagnoses for rare and common diseases at brain MRI has not been demonstrated. Purpose To evaluate an AI system for generation of differential diagnoses at brain MRI compared with radiologists. Materials and Methods This retrospective study tested performance of an AI system for probabilistic diagnosis in patients with 19 common and rare diagnoses at brain MRI acquired between January 2008 and January 2018. The AI system combines data-driven and domain-expertise methodologies, including deep learning and Bayesian networks. First, lesions were detected by using deep learning. Then, 18 quantitative imaging features were extracted by using atlas-based coregistration and segmentation. Third, these image features were combined with five clinical features by using Bayesian inference to develop probability-ranked differential diagnoses. Quantitative feature extraction algorithms and conditional probabilities were fine-tuned on a training set of 86 patients (mean age, 49 years ± 16 [standard deviation]; 53 women). Accuracy was compared with radiology residents, general radiologists, neuroradiology fellows, and academic neuroradiologists by using accuracy of top one, top two, and top three differential diagnoses in 92 independent test set patients (mean age, 47 years ± 18; 52 women). Results For accuracy of top three differential diagnoses, the AI system (91\% correct) performed similarly to academic neuroradiologists (86\% correct; P = .20), and better than radiology residents (56\%; P < .001), general radiologists (57\%; P < .001), and neuroradiology fellows (77\%; P = .003). The performance of the AI system was not affected by disease prevalence (93\% accuracy for common vs 85\% for rare diseases; P = .26). Radiologists were more accurate at diagnosing common versus rare diagnoses (78\% vs 47\% across all radiologists; P < .001). Conclusion An artificial intelligence system for brain MRI approached overall top one, top two, and top three differential diagnoses accuracy of neuroradiologists and exceeded that of less-specialized radiologists. © RSNA, 2020 Online supplemental material is available for this article. See also the editorial by Zaharchuk in this issue. }
}

@article{doi:10.1148/radiol.2020201874,
author = {Murphy, Keelin and Smits, Henk and Knoops, Arnoud J.                             G. and Korst, Michael B. J.                             M. and Samson, Tijs and Scholten, Ernst                             T. and Schalekamp, Steven and Schaefer-Prokop, Cornelia                             M. and Philipsen, Rick H. H.                             M. and Meijers, Annet and Melendez, Jaime and van                             Ginneken, Bram and Rutten, Matthieu},
title = {COVID-19 on Chest Radiographs: A Multireader Evaluation of an                     Artificial Intelligence System},
journal = {Radiology},
volume = {296},
number = {3},
pages = {E166-E172},
year = {2020},
doi = {10.1148/radiol.2020201874},
abstract = { Background Chest radiography may play an important role in triage for coronavirus disease 2019 (COVID-19), particularly in low-resource settings. Purpose To evaluate the performance of an artificial intelligence (AI) system for detection of COVID-19 pneumonia on chest radiographs. Materials and Methods An AI system (CAD4COVID-XRay) was trained on 24 678 chest radiographs, including 1540 used only for validation while training. The test set consisted of a set of continuously acquired chest radiographs (n = 454) obtained in patients suspected of having COVID-19 pneumonia between March 4 and April 6, 2020, at one center (223 patients with positive reverse transcription polymerase chain reaction [RT-PCR] results, 231 with negative RT-PCR results). Radiographs were independently analyzed by six readers and by the AI system. Diagnostic performance was analyzed with the receiver operating characteristic curve. Results For the test set, the mean age of patients was 67 years ± 14.4 (standard deviation) (56\% male). With RT-PCR test results as the reference standard, the AI system correctly classified chest radiographs as COVID-19 pneumonia with an area under the receiver operating characteristic curve of 0.81. The system significantly outperformed each reader (P < .001 using the McNemar test) at their highest possible sensitivities. At their lowest sensitivities, only one reader significantly outperformed the AI system (P = .04). Conclusion The performance of an artificial intelligence system in the detection of coronavirus disease 2019 on chest radiographs was comparable with that of six independent readers. © RSNA, 2020 }
}

@article{JUNGMANN2021834,
title = {Attitudes Toward Artificial Intelligence Among Radiologists, IT Specialists, and Industry},
journal = {Academic Radiology},
volume = {28},
number = {6},
pages = {834-840},
year = {2021},
issn = {1076-6332},
doi = {https://doi.org/10.1016/j.acra.2020.04.011},
author = {Florian Jungmann and Tobias Jorg and Felix Hahn and Daniel {Pinto dos Santos} and Stefanie Maria Jungmann and Christoph Düber and Peter Mildenberger and Roman Kloeckner},
keywords = {Artificial intelligence, Radiology, Surveys and questionnaires},
abstract = {Objectives
We investigated the attitudes of radiologists, information technology (IT) specialists, and industry representatives on artificial intelligence (AI) and its future impact on radiological work.
Materials and Methods
During a national meeting for AI, eHealth, and IT infrastructure in 2019, we conducted a survey to obtain participants’ attitudes. A total of 123 participants completed 28 items exploring AI usage in medicine. The Kruskal-Wallis test was used to identify differences between radiologists, IT specialists, and industry representatives.
Results
The strongest agreement between all respondents occurred with the following: plausibility checks are important to understand the decisions of the AI (93\% agreement), validation of AI algorithms is mandatory (91\%), and medicine becomes more efficient in the age of AI (86\%). In contrast, only 25\% of the respondents had confidence in the AI results, and only 17\% believed that medicine will become more human through the use of AI. The answers were significantly different between the three professions for four items: relevance for protocol selection in cross-sectional imaging (p = 0.034), medical societies should be involved in validation (p = 0.028), patients should be informed about the use of AI (p = 0.047), and AI should be part of medical education (p = 0.026).
Conclusion
Currently, a discrepancy exists between high expectations for the future role of AI and low confidence in the results. This attitude was similar across all three groups. The demand for plausibility checks and the need to prove the usefulness in randomized controlled studies indicate what is needed in future research.}
}

@article{eslami2012effects,
title = {Effects of two different levels of computerized decision support on blood glucose regulation in critically ill patients},
journal = {International Journal of Medical Informatics},
volume = {81},
number = {1},
pages = {53-60},
year = {2012},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2011.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S1386505611002140},
author = {Saeid Eslami and Nicolette F. {de Keizer} and Dave A. Dongelmans and Evert {de Jonge} and Marcus J. Schultz and Ameen Abu-Hanna},
keywords = {Computerized decision support system, Evaluation, Safety statistical process control, Glucose regulation},
abstract = {Introduction
Although the use of computerized decision support systems (CDSS) in glucose control in the ICU has been reported, little is known about the effect of the systems’ operating modes on the quality of glucose control. The objective of this study was to evaluate the effect of providing patient-specific and patient non-specific computerized advice on timing of blood glucose level (BGL) measurements. Our hypothesis was that both levels of support would be effective for improving the quality of glucose regulation and safety, with patient specific advice being the most effective strategy.
Patients and methods
A prospective study was performed in a 30-bed mixed medical-surgical intensive care unit (ICU) of a university hospital. In phase 1 the CDSS provided non-specific advice and thereafter, in phase 2, the system provided specific advice on timing of BGL measurements. The primary outcome measure was delay in BGL measurements before and after the two levels of support. Secondary endpoints were sampling frequency, mean BGL, BGL within pre-defined targets, time to capture target, incidences of severe hypoglycemia and hyperglycemia. These indicators were analyzed over the course of time using Statistical Control Charts. The analysis was restricted to patients with at least two blood glucose measurements.
Results
Data of 3934 patient admissions were evaluated, which corresponded to 119,116 BGL measurements. The BGL sampling interval, delays in BG sampling, and percentage of hypoglycemia all decreased after introducing either of the two levels of decision support. The effect was however larger for the patient specific CDSS. Mean BGL, time to capture target, hyperglycemia index, percentage of hyperglycemia events and “in range” measurements remained unchanged and stable after introducing both patient non-specific and patient specific decision support.
Conclusion
Adherence to protocol sampling rules increased by using decision support with a larger effect at the patient specific level. This led to a decrease in the percentage of hypoglycemia events and improved safety. The use of the CDSS at both levels, however, did not improve the quality of glucose control as measured by our indicators. More research is needed to investigate whether other socio-technical factors are in play.}
}

@article{jia2016effects,
  title={The effects of clinical decision support systems on medication safety: an overview},
  author={Jia, Pengli and Zhang, Longhao and Chen, Jingjing and Zhao, Pujing and Zhang, Mingming},
  journal={PloS one},
  volume={11},
  number={12},
  pages={e0167683},
  year={2016},
  publisher={Public Library of Science San Francisco, CA USA}
}

@article{https://doi.org/10.3322/caac.21754,
author = {Giaquinto, Angela N. and Sung, Hyuna and Miller, Kimberly D. and Kramer, Joan L. and Newman, Lisa A. and Minihan, Adair and Jemal, Ahmedin and Siegel, Rebecca L.},
title = {Breast Cancer Statistics, 2022},
journal = {CA: A Cancer Journal for Clinicians},
volume = {72},
number = {6},
pages = {524-541},
keywords = {breast neoplasms, epidemiology, health disparities, incidence, molecular subtype},
doi = {https://doi.org/10.3322/caac.21754},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.3322/caac.21754},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21754},
abstract = {Abstract This article is the American Cancer Society’s update on female breast cancer statistics in the United States, including population-based data on incidence, mortality, survival, and mammography screening. Breast cancer incidence rates have risen in most of the past four decades; during the most recent data years (2010–2019), the rate increased by 0.5\% annually, largely driven by localized-stage and hormone receptor-positive disease. In contrast, breast cancer mortality rates have declined steadily since their peak in 1989, albeit at a slower pace in recent years (1.3\% annually from 2011 to 2020) than in the previous decade (1.9\% annually from 2002 to 2011). In total, the death rate dropped by 43\% during 1989–2020, translating to 460,000 fewer breast cancer deaths during that time. The death rate declined similarly for women of all racial/ethnic groups except American Indians/Alaska Natives, among whom the rates were stable. However, despite a lower incidence rate in Black versus White women (127.8 vs. 133.7 per 100,000), the racial disparity in breast cancer mortality remained unwavering, with the death rate 40\% higher in Black women overall (27.6 vs. 19.7 deaths per 100,000 in 2016–2020) and two-fold higher among adult women younger than 50 years (12.1 vs. 6.5 deaths per 100,000). Black women have the lowest 5-year relative survival of any racial/ethnic group for every molecular subtype and stage of disease (except stage I), with the largest Black–White gaps in absolute terms for hormone receptor-positive/human epidermal growth factor receptor 2-negative disease (88\% vs. 96\%), hormone receptor-negative/human epidermal growth factor receptor 2-positive disease (78\% vs. 86\%), and stage III disease (64\% vs. 77\%). Progress against breast cancer mortality could be accelerated by mitigating racial disparities through increased access to high-quality screening and treatment via nationwide Medicaid expansion and partnerships between community stakeholders, advocacy organizations, and health systems.},
year = {2022}
}

@article{SADEGHI2022105554,
title = {An overview of artificial intelligence techniques for diagnosis of Schizophrenia based on magnetic resonance imaging modalities: Methods, challenges, and future works},
journal = {Computers in Biology and Medicine},
volume = {146},
pages = {105554},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.105554},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522003468},
author = {Delaram Sadeghi and Afshin Shoeibi and Navid Ghassemi and Parisa Moridian and Ali Khadem and Roohallah Alizadehsani and Mohammad Teshnehlab and Juan M. Gorriz and Fahime Khozeimeh and Yu-Dong Zhang and Saeid Nahavandi and U Rajendra Acharya},
keywords = {Schizophrenia, Diagnosis, MRI, Conventional machine learning, Deep learning, Neuroscience},
abstract = {Schizophrenia (SZ) is a mental disorder that typically emerges in late adolescence or early adulthood. It reduces the life expectancy of patients by 15 years. Abnormal behavior, perception of emotions, social relationships, and reality perception are among its most significant symptoms. Past studies have revealed that SZ affects the temporal and anterior lobes of hippocampus regions of the brain. Also, increased volume of cerebrospinal fluid (CSF) and decreased volume of white and gray matter can be observed due to this disease. Magnetic resonance imaging (MRI) is the popular neuroimaging technique used to explore structural/functional brain abnormalities in SZ disorder, owing to its high spatial resolution. Various artificial intelligence (AI) techniques have been employed with advanced image/signal processing methods to accurately diagnose SZ. This paper presents a comprehensive overview of studies conducted on the automated diagnosis of SZ using MRI modalities. First, an AI-based computer aided-diagnosis system (CADS) for SZ diagnosis and its relevant sections are presented. Then, this section introduces the most important conventional machine learning (ML) and deep learning (DL) techniques in the diagnosis of diagnosing SZ. A comprehensive comparison is also made between ML and DL studies in the discussion section. In the following, the most important challenges in diagnosing SZ are addressed. Future works in diagnosing SZ using AI techniques and MRI modalities are recommended in another section. Results, conclusion, and research findings are also presented at the end.}
}

@article{Yigit_Mendes_2018, title={Which Effect Size Measure is Appropriate for One-Way and Two-Way ANOVA Models? : A Monte Carlo Simulation Study}, volume={16}, url={https://revstat.ine.pt/index.php/REVSTAT/article/view/244}, DOI={10.57805/revstat.v16i3.244}, number={3}, journal={REVSTAT-Statistical Journal}, author={Yigit , Soner and Mendes , Mehmet}, year={2018}, month={Jul.}, pages={295–313} }

@inproceedings{10.1145/3180155.3182556,
author = {Madeyski, Lech and Kitchenham, Barbara},
title = {Effect Sizes and Their Variance for AB/BA Crossover Design Studies},
year = {2018},
isbn = {9781450356381},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3180155.3182556},
doi = {10.1145/3180155.3182556},
abstract = {We addressed the issues related to repeated measures experimental design such as an AB/BA crossover design that have been neither discussed nor addressed in the software engineering literature.Firstly, there are potentially two different standardized mean difference effect sizes that can be calculated, depending on whether the mean difference is standardized by the pooled within groups variance or the within-participants variance. Hence, we provided equations for non-standardized and standardized effect sizes and explained the need for two different types of standardized effect size, one for the repeated measures and one that would be equivalent to an independent groups design.Secondly, as for any estimated parameters and also for the purposes of undertaking meta-analysis, it is necessary to calculate the variance of the standardized mean difference effect sizes (which is not the same as the variance of the study). Hence, we provided formulas for the small sample size effect size variance and the medium sample size approximation to the effect size variance, for both types of standardized effect size.We also presented the model underlying the AB/BA crossover design and provided two examples (an empirical analysis of the real data set by Scanniello, as well as simulated data) to demonstrate how to construct the two standardized mean difference effect sizes and their variances, both from standard descriptive statistics and from the outputs provided by the linear mixed model package lme4 in R.A conclusion is that crossover designs should be considered (instead of between groups design) only if:• previous research has suggested that ρ is greater than zero and preferably greater than 0.25;• there is either strong theoretical argument, or empirical evidence from a well-powered study, that the period by technique interaction is negligible.Summarizing, our journal first paper [3]:(1) Presents the formulas needed to calculate both non-standardized and standardized mean difference effect sizes for AB/BA crossover designs (see Section 4 and 5 of our paper [3]).(2) Presents the formulas needed to estimate the variances of the non-standardized and standardized effect sizes which in the later cases need to be appropriate for the small to medium sample sizes commonly used in software engineering crossover designs (see Section 5 of our paper [3]).(3) Explains how to calculate the effect sizes and their variances both from the descriptive statistics that should be reported and from the raw data (see Section 6 of our paper [3]).It is worth mentioning that we based our formulas on our own corrections to the formulas presented earlier by Curtin et al. [1]. Our corrections for the variances of standardized weighted mean difference of an AB/BA cross-over trial were accepted by the author of the original formulas (Curtin), submitted jointly as a letter to Editor of Statistics in Medicine to assure the widespread (also beyond the software engineering domain) adoption of the corrected formulas, and accepted [2]. We proposed an alternative formulation of the standardized effect size for individual difference effects that is comparable with the standardized effect size commonly used for pretest/posttest studies. We also corrected the small sample size and moderate sample size variances reported by Curtin et al. for both the individual difference effect size and the standardized effect size comparable to independent groups trials, showing the derivation of the formulas from the variance of a t-variable. Using these results, researchers can now correctly calculate standardized effect size variances, allowing the calculation of confidence intervals for AB/BA cross-over trials, which in turn provides a direct link to null hypothesis testing and supports meta-analysis. Meta-analysts can now validly aggregate together results from independent groups, pretest/posttest and AB/BA cross-over trials. Last but not least, the presented contributions allow corrections of previously reported results.},
booktitle = {Proceedings of the 40th International Conference on Software Engineering},
pages = {420},
numpages = {1},
keywords = {empirical software engineering, meta-analysis, effect size},
location = {Gothenburg, Sweden},
series = {ICSE '18}
}

@article{CASALE2022107302,
title = {A meta-analysis on the association between self-esteem and problematic smartphone use},
journal = {Computers in Human Behavior},
volume = {134},
pages = {107302},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2022.107302},
url = {https://www.sciencedirect.com/science/article/pii/S0747563222001248},
author = {Silvia Casale and Giulia Fioravanti and Sara {Bocci Benucci} and Andrea Falone and Valdo Ricca and Francesco Rotella},
keywords = {Meta-analysis, Mobile addiction, Mobile problematic use, Problematic smartphone use, Self-esteem, Systematic review, Smartphone addiction},
abstract = {Addictive behaviors have traditionally been associated with low self-esteem, and Problematic Smartphone Use (PSU) has recently received increasing scientific attention as a potential behavioral addiction. The present meta-analysis aims to examine the strength of the relationship between PSU symptoms and global self-esteem. A keyword-based systematic literature search was performed to identify studies in which PSU symptoms and global self-esteem were assessed. Thirty-one independent studies with a total of 27.004 participants (F \% = 54.21\%; mean age = 17.37 ± 4.97; range: 12.10–34.39 years old) were included. Meta-analytic results of the random effects model applied to a total of 31 independent samples show a negative correlation between self-esteem and PSU (Fisher's Z = −0.25; CI -0.28, −0.21; Z = −14.63; p < 0.001). Age, gender and geographical area did not moderate the association. The magnitude of the effect size can be considered small according to Cohen's criteria (1992), and medium according to Hemphill's criteria (2003). The sensitivity analysis and analyses of publication bias confirm that these results are robust. The findings show that low self-esteem is an important hallmark of PSU. Overall, our findings emphasize the importance of addressing self-esteem and corresponding core beliefs in the prevention and treatment of PSU.}
}

@article{DEUTSCH2019122,
title = {Home robotic devices for older adults: Opportunities and concerns},
journal = {Computers in Human Behavior},
volume = {98},
pages = {122-133},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219301426},
author = {Inbal Deutsch and Hadas Erel and Michal Paz and Guy Hoffman and Oren Zuckerman},
keywords = {Older adults, Robots, Attitudes, Aging, Design guidelines, Human-robot interaction},
abstract = {Robotic devices for older adults are becoming a reality. New robots are being introduced for the growing subpopulation of healthy older adults, with an emphasis on supporting the positive aspects of aging. In order to inform the design and implementation of such robots, the relevant needs and concerns of this population should be studied, mapped, and translated into recommendations. We present a qualitative study of thirty cognitively-intact older adults, evaluating their attitudes and emotional reactions towards different types of home robotic devices. Interview analysis of participants reactions to videos of six devices uncovered four user needs that can be threatened by the introduction of home robots: the need for independence, the need for control, the fear of being replaced, and the need for authenticity. Furthermore, results reveal that cognitively-intact older adults are willing to adopt robotic devices into their homes, contingent upon their preferences and concerns being addressed. We provide recommendations regarding how researchers and designers of home robots can better address the user needs of healthy older adults by leveraging aspects of the robot's function, speech, appearance, size, proactivity, and mobility.}
}

@article{SHIBUYA2022107131,
title = {Mapping HCI research methods for studying social media interaction: A systematic literature review},
journal = {Computers in Human Behavior},
volume = {129},
pages = {107131},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107131},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221004544},
author = {Yuya Shibuya and Andrea Hamm and Teresa {Cerratto Pargman}},
keywords = {Social computing, Systematic literature review, Social media interaction, Methodology},
abstract = {In the last decades, researchers in Human-computer interaction (HCI) took numerous efforts to investigate people's social media interaction. To understand how researchers in HCI have studied social media interaction, we examined 149 peer-reviewed articles published between 2008 and 2020 in major HCI conference proceedings and journals. We systematically reviewed the methodologies HCI researchers applied, the research topics these methods covered, and the types of data collected. Through the analysis, we make three contributions: We (1) pinpoint the topic trends by identifying three phases in the study of social media interaction in HCI. Namely, the early phase (2008–2012) focused on user behavior, the growing phase (2013–2016), focused on privacy and health, and the latest phase (2017–2020) focused on design. (2) We map methodological trends in the study of social media interaction in HCI. We also illustrate the trends in relation to the types of data collected in the selected works and, (3) identify underexplored study areas.}
}

@article{BIEG2022107249,
title = {Evaluating Active and Assisted Living technologies: Critical methodological reflections based on a longitudinal randomized controlled trial},
journal = {Computers in Human Behavior},
volume = {133},
pages = {107249},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2022.107249},
url = {https://www.sciencedirect.com/science/article/pii/S0747563222000711},
author = {Till Bieg and Cornelia Gerdenitsch and Isabel Schwaninger and Bettina Manuela Johanna Kern and Christopher Frauenberger},
keywords = {Active and assisted living, Randomized controlled trial, Older adults, Mixed methods},
abstract = {In the light of demographic change, Active and Assisted Living (AAL) technologies promise to support older adults in their everyday lives and promote a self-determined lifestyle. However, empirical evidence for their effectiveness is fragmented and mixed. Thus, literature has called for more rigorous studies – including randomized controlled trials (RCTs) – to investigate the effectiveness of AAL technologies. In this paper, we present findings from a longitudinal RCT over 12 months (N = 150) evaluating an AAL technology that aims to support older adults’ self-determination, social participation, and perceived safety. Results do not indicate significant effects on the measured outcomes. Based on complementary methods employed in the study (tracking of usage behavior, quantitative self-reports on user experience, qualitative interviews) and our practical experiences with the implementation of the WAALTeR project we critically reflect on this finding and explore possible explanations. This reflection reveals systematic challenges that exist not only in relation to the present study but also in relation to the evaluation of AAL technologies more generally. Based on these insights, we offer implications and directions for future research that aim to better understand and overcome challenges in evaluating the effectiveness of AAL technologies.}
}

@inproceedings{10.1145/3491101.3519863,
author = {Goldman, Ariel and Espinosa, Cindy and Patel, Shivani and Cavuoti, Francesca and Chen, Jade and Cheng, Alexandra and Meng, Sabrina and Patil, Aditi and Chilton, Lydia B and Morrison-Smith, Sarah},
title = {QuAD: Deep-Learning Assisted Qualitative Data Analysis with Affinity Diagrams},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3519863},
doi = {10.1145/3491101.3519863},
abstract = {Affinity diagramming is an effective and efficient method for forming nuanced interpretations of wide-ranging, unstructured qualitative data; however, this method does not scale well to large data sets. We propose a novel affinity diagramming system, called Qualitative Affinity Diagrammer (QuAD) that leverages computer-generated suggestions using deep learning to address the scalability of the diagramming process. QuAD features automatic grouping suggestions to jump-start the affinity diagramming process and provides grouping suggestions throughout the diagramming process to reduce sifting through notes. In this paper, we present a prototype of QuAD that uses Bidirectional Encoder Representations from Transformers (BERT) and Girvan-Newman to generate grouping suggestions. This work is the first step towards creating a powerful tool for assisting in the analysis of large qualitative data sets in a variety of contexts, including human-computer interaction.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {419},
numpages = {7},
keywords = {Qualitative data, affinity digramming, deep learning, natural language processing},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@inproceedings{10.1145/3411764.3445464,
author = {Reichherzer, Carolin and Cunningham, Andrew and Coleman, Tracey and Cao, Ruochen and McManus, Kurt and Sheppard, Dion and Kohler, Mark and Billinghurst, Mark and Thomas, Bruce H},
title = {Bringing the Jury to the Scene of the Crime: Memory and Decision-Making in a Simulated Crime Scene},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445464},
doi = {10.1145/3411764.3445464},
abstract = {This paper investigates the use of immersive virtual reconstructions as an aid for jurors during a courtroom trial. The findings of a between-participant user study on memory and decision-making are presented in the context of viewing a simulated hit-run-death scenario. Participants listened to the opening statement of a prosecutor and a defence attorney before viewing the crime scene in Virtual Reality (VR) or as still images. We compare the effects on cognition and usability of using VR over images presented on a screen. We found several significant improvements, including that VR led to more consistent decision-making among participants. This shows that VR could provide a promising solution for the court to present crime scenes when site visitations are not possible.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {709},
numpages = {12},
keywords = {jury, Virtual Reality, spatial memory, interactive virtual environment, 3D Reconstruction, crime scene},
location = {Yokohama, Japan},
series = {CHI '21}
}

@article{doi:10.1148/ryai.210299,
author = {Luo, Luyang and Chen, Hao and Xiao, Yongjie and Zhou, Yanning and Wang, Xi and Vardhanabhuti, Varut and Wu, Mingxiang and Han, Chu and Liu, Zaiyi and Fang, Xin Hao Benjamin and Tsougenis, Efstratios and Lin, Huangjing and Heng, Pheng-Ann},
title = {Rethinking Annotation Granularity for Overcoming Shortcuts in Deep                     Learning–based Radiograph Diagnosis: A Multicenter Study},
journal = {Radiology: Artificial Intelligence},
volume = {4},
number = {5},
pages = {e210299},
year = {2022},
doi = {10.1148/ryai.210299},
    note ={PMID: 35146431},

URL = { 
        https://doi.org/10.1148/ryai.210299
    
},
eprint = { 
        https://doi.org/10.1148/ryai.210299
    
}
,
    abstract = { Purpose To evaluate the ability of fine-grained annotations to overcome shortcut learning in deep learning (DL)–based diagnosis using chest radiographs. Materials and Methods Two DL models were developed using radiograph-level annotations (disease present: yes or no) and fine-grained lesion-level annotations (lesion bounding boxes), respectively named CheXNet and CheXDet. A total of 34 501 chest radiographs obtained from January 2005 to September 2019 were retrospectively collected and annotated regarding cardiomegaly, pleural effusion, mass, nodule, pneumonia, pneumothorax, tuberculosis, fracture, and aortic calcification. The internal classification performance and lesion localization performance of the models were compared on a testing set (n = 2922); external classification performance was compared on National Institutes of Health (NIH) Google (n = 4376) and PadChest (n = 24 536) datasets; and external lesion localization performance was compared on the NIH ChestX-ray14 dataset (n = 880). The models were also compared with radiologist performance on a subset of the internal testing set (n = 496). Performance was evaluated using receiver operating characteristic (ROC) curve analysis. Results Given sufficient training data, both models performed similarly to radiologists. CheXDet achieved significant improvement for external classification, such as classifying fracture on NIH Google (CheXDet area under the ROC curve [AUC], 0.67; CheXNet AUC, 0.51; P < .001) and PadChest (CheXDet AUC, 0.78; CheXNet AUC, 0.55; P < .001). CheXDet achieved higher lesion detection performance than CheXNet for most abnormalities on all datasets, such as detecting pneumothorax on the internal set (CheXDet jackknife alternative free-response ROC [JAFROC] figure of merit [FOM], 0.87; CheXNet JAFROC FOM, 0.13; P < .001) and NIH ChestX-ray14 (CheXDet JAFROC FOM, 0.55; CheXNet JAFROC FOM, 0.04; P < .001). Conclusion Fine-grained annotations overcame shortcut learning and enabled DL models to identify correct lesion patterns, improving the generalizability of the models. Keywords: Computer-aided Diagnosis, Conventional Radiography, Convolutional Neural Network (CNN), Deep Learning Algorithms, Machine Learning Algorithms, Localization Supplemental material is available for this article © RSNA, 2022 }
}

@inproceedings{10.1145/3411764.3445432,
author = {Wang, Dakuo and Wang, Liuping and Zhang, Zhan and Wang, Ding and Zhu, Haiyi and Gao, Yvonne and Fan, Xiangmin and Tian, Feng},
title = {``Brilliant AI Doctor'' in Rural Clinics: Challenges in AI-Powered Clinical Decision Support System Deployment},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445432},
doi = {10.1145/3411764.3445432},
abstract = {Artificial intelligence (AI) technology has been increasingly used in the implementation of advanced Clinical Decision Support Systems (CDSS). Research demonstrated the potential usefulness of AI-powered CDSS (AI-CDSS) in clinical decision making scenarios. However, post-adoption user perception and experience remain understudied, especially in developing countries. Through observations and interviews with 22 clinicians from 6 rural clinics in China, this paper reports the various tensions between the design of an AI-CDSS system (“Brilliant Doctor”) and the rural clinical context, such as the misalignment with local context and workflow, the technical limitations and usability barriers, as well as issues related to transparency and trustworthiness of AI-CDSS. Despite these tensions, all participants expressed positive attitudes toward the future of AI-CDSS, especially acting as “a doctor’s AI assistant” to realize a Human-AI Collaboration future in clinical settings. Finally we draw on our findings to discuss implications for designing AI-CDSS interventions for rural clinical contexts in developing countries.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {697},
numpages = {18},
keywords = {Healthcare, Human AI Collaboration, Developing Country, Trust AI, Future of Work, AI, Collaborative AI, Implementation, AI Deployment, Workflow, Decision Making, Clinical Decision Making, Rural Clinic, CDSS, China, Human AI Interaction},
location = {Yokohama, Japan},
series = {CHI '21}
}

@article{10.1093/jamia/ocab291,
    author = {Sittig, Dean F and Lakhani, Priti and Singh, Hardeep},
    title = "{Applying requisite imagination to safeguard electronic health record transitions}",
    journal = {Journal of the American Medical Informatics Association},
    volume = {29},
    number = {5},
    pages = {1014-1018},
    year = {2022},
    month = {01},
    abstract = "{Over the next decade, many health care organizations (HCOs) will transition from one electronic health record (EHR) to another; some forced by hospital acquisition and others by choice in search of better EHRs. Herein, we apply principles of Requisite Imagination, or the ability to imagine key aspects of the future one is planning, to offer 6 recommendations on how to proactively safeguard these transitions. First, HCOs should implement a proactive leadership structure that values communication. Second, HCOs should implement proactive risk assessment and testing processes. Third, HCOs should anticipate and reduce unwarranted variation in their EHR and clinical processes. Fourth, HCOs should establish a culture of conscious inquiry with routine system monitoring. Fifth, HCOs should foresee and reduce information access problems. Sixth, HCOs should support their workforce through difficult EHR transitions. Proactive approaches using Requisite Imagination principles outlined here can help ensure safe, effective, and economically sound EHR transitions.}",
    issn = {1527-974X},
    doi = {10.1093/jamia/ocab291},
    url = {https://doi.org/10.1093/jamia/ocab291},
    eprint = {https://academic.oup.com/jamia/article-pdf/29/5/1014/43372323/ocab291.pdf},
}

@inproceedings{10.1117/12.2613082,
author = {Manish Sharma and Madhuri Madasu and Sree Sudha Kota and Surabhi Bajpai and Yibin Shao and Srinivas Pasupuleti and Michael O’Connor},
title = {{Using reader disagreement index as a tool for monitoring impact on read quality due to reader fatigue in central reviewers}},
volume = {12035},
booktitle = {Medical Imaging 2022: Image Perception, Observer Performance, and Technology Assessment},
editor = {Claudia R. Mello-Thoms and Sian Taylor-Phillips},
organization = {International Society for Optics and Photonics},
publisher = {SPIE},
pages = {120350J},
location={San Diego, California, United States},
abstract = {<p> <strong>Purpose:</strong> Fatigue may lead to high medical errors by the radiologists. Fatigue is often described as feelings of weakness, lack of energy, and a desire to rest, and is associated with impairments in the ability to function. Visual fatigue has importance in medical imaging as errors (false-negatives) are relatively common. Blinded independent central review (BICR) is a well-used method employed in many oncology registration trials. Ongoing monitoring of radiologist “reviewer” performance is both good clinical trial practice and a requirement by regulatory authorities. We use reader disagreement index (RDI) as a potential tool to identify reader fatigue and compare reader fatigue in reviewers performing single versus multiple types of study. </p> <p> <strong>Methods: </strong>A retrospective analysis of reviewers’ RDI in four different clinical trials were performed. Fourteen reviewers’ performance was analyzed with data for 3750 subjects having a total of 15105 timepoints across all clinical trials. These individual trial reviews were conducted by 14 board-certified radiologist reviewers using several established imaging assessment trial criteria. The objective of the study was to establish RDI as an effective tool to analyze if it could be a good surrogate marker for quality impacted by reader fatigue. </p> <p> <strong>Results:</strong> The results indicate the RDI can be used as a tool to track reader quality which in turn may be able to predict reader fatigue. In the random pool of readers and studies analyzed, we did not notice any major trend or impact on read quality given that these trials were anyway actively monitored for read volume distribution and quality. </p> <strong>Conclusions:</strong> Fatigue may lead to high medical errors by the radiologists. RDI can be used as a good surrogate for read quality to monitor reader fatigue. Based on the results, it can be said that it is better to undertake more cases in a single study than undertake less number of cases in different types of studies to prevent reader fatigue. },
keywords = {Observer Performance Evaluation, Human Factors, Image Perception},
year = {2022},
doi = {10.1117/12.2613082},
URL = {https://doi.org/10.1117/12.2613082}
}

@article{doi:10.1148/radiol.212631,
author = {Alexander, Robert and Waite, Stephen and Bruno, Michael A. and Krupinski, Elizabeth A. and Berlin, Leonard and Macknik, Stephen and Martinez-Conde, Susana},
title = {Mandating Limits on Workload, Duty, and Speed in                     Radiology},
journal = {Radiology},
volume = {304},
number = {2},
pages = {274-282},
year = {2022},
doi = {10.1148/radiol.212631},
    note ={PMID: 35699581},

URL = { 
    
        https://doi.org/10.1148/radiol.212631
    
    

},
eprint = { 
    
        https://doi.org/10.1148/radiol.212631
    
    

}
,
    abstract = { Research has not yet quantified the effects of workload or duty hours on the accuracy of radiologists. With the exception of a brief reduction in imaging studies during the 2020 peak of the COVID-19 pandemic, the workload of radiologists in the United States has seen relentless growth in recent years. One concern is that this increased demand could lead to reduced accuracy. Behavioral studies in species ranging from insects to humans have shown that decision speed is inversely correlated to decision accuracy. A potential solution is to institute workload and duty limits to optimize radiologist performance and patient safety. The concern, however, is that any prescribed mandated limits would be arbitrary and thus no more advantageous than allowing radiologists to self-regulate. Specific studies have been proposed to determine whether limits reduce error, and if so, to provide a principled basis for such limits. This could determine the precise susceptibility of individual radiologists to medical error as a function of speed during image viewing, the maximum number of studies that could be read during a work shift, and the appropriate shift duration as a function of time of day. Before principled recommendations for restrictions are made, however, it is important to understand how radiologists function both optimally and at the margins of adequate performance. This study examines the relationship between interpretation speed and error rates in radiology, the potential influence of artificial intelligence on reading speed and error rates, and the possible outcomes of imposed limits on both caseload and duty hours. This review concludes that the scientific evidence needed to make meaningful rules is lacking and notes that regulating workloads without scientific principles can be more harmful than not regulating at all. © RSNA, 2022 }
}

@article{10.1145/3555157,
author = {Su, Zhaoyuan and He, Lu and Jariwala, Sunit P and Zheng, Kai and Chen, Yunan},
title = {"What is Your Envisioned Future?": Toward Human-AI Enrichment in Data Work of Asthma Care},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555157},
doi = {10.1145/3555157},
abstract = {Patient-generated health data (PGHD) is crucial for healthcare providers' decision making, as it complements clinical data by providing a more holistic view of patients' daily conditions. We interviewed 20 healthcare providers in asthma care to envision future technologies to support their PGHD use. We found that healthcare providers want future artificial intelligence (AI) systems to enhance their ability to treat patients by analyzing PGHD for profiling risk and predicting deterioration. Despite the potential benefits of AI, providers perceived various challenges of AI use with PGHD, including AI-driven data inequity, added burden, lack of trust toward AI, and fear of being replaced by AI. Clinicians wished for a future of co-dependent human-AI collaboration, where AI will help them to improve their clinical practice. In turn, healthcare providers can improve AI systems by making AI outputs more trustworthy and humane. Through the lens of data feminism, we discuss the importance of considering context and aligning the complex human infrastructure before designing or deploying PGHD-based AI systems in clinical settings. We highlight the opportunity to design for human-AI enrichment, where humans and AI not only partner with each other for improved performance, but also enrich each other to enhance each other's work overtime.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {267},
numpages = {28},
keywords = {human-AI interaction, human-AI collaboration, future of work, health datafication, healthcare, data work, patient-generated health data}
}

@article{JARRAHI2018577,
title = {Artificial intelligence and the future of work: Human-AI symbiosis in organizational decision making},
journal = {Business Horizons},
volume = {61},
number = {4},
pages = {577-586},
year = {2018},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2018.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S0007681318300387},
author = {Mohammad Hossein Jarrahi},
keywords = {Artificial intelligence, Organizational decision making, Human-machine symbiosis, Human augmentation, Analytical and intuitive decision making},
abstract = {Artificial intelligence (AI) has penetrated many organizational processes, resulting in a growing fear that smart machines will soon replace many humans in decision making. To provide a more proactive and pragmatic perspective, this article highlights the complementarity of humans and AI and examines how each can bring their own strength in organizational decision-making processes typically characterized by uncertainty, complexity, and equivocality. With a greater computational information processing capacity and an analytical approach, AI can extend humans’ cognition when addressing complexity, whereas humans can still offer a more holistic, intuitive approach in dealing with uncertainty and equivocality in organizational decision making. This premise mirrors the idea of intelligence augmentation, which states that AI systems should be designed with the intention of augmenting, not replacing, human contributions.}
}

@inproceedings{10.1145/3397481.3450668,
author = {van der Stappen, Almar and Funk, Mathias},
title = {Towards Guidelines for Designing Human-in-the-Loop Machine Training Interfaces},
year = {2021},
isbn = {9781450380171},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3397481.3450668},
doi = {10.1145/3397481.3450668},
abstract = {Supervised machine learning approaches commonly require good availability and quality of training data. In applications that depend on human-labeled data, especially from experts, or that depend on contextual knowledge for training data sets, the human-in-the-loop presents a serious bottleneck to the scalability of training efforts. Even if human labeling is generally feasible, sustained human performance and high-quality labels in larger quantities are challenging. Interactive Machine Learning can help solve usability problems in traditional machine learning by giving users agency in deciding how systems learn from data. Yet, the field lacks clear design guidelines for such interfaces, specifically regarding the scaling of training processes. In this paper, we present results from a pilot study in which participants interacted with several interface variants of a recommender engine and evaluated them on interaction and efficiency parameters. Based on the performance of these different learning system implementations we propose design guidelines for the design of such systems and a score for comparative evaluation, in which we combine interaction experience and system learning efficiency into one relative scoring unit.},
booktitle = {26th International Conference on Intelligent User Interfaces},
pages = {514–519},
numpages = {6},
keywords = {Labeling Data, Algorithmic Training, UX Metric, Machine Learning, User Interface, Interaction},
location = {College Station, TX, USA},
series = {IUI '21}
}

@Article{Edgar2022,
author={Edgar, Amanda K.
and Ainge, Lucinda
and Backhouse, Simon
and Armitage, James A.},
title={A cohort study for the development and validation of a reflective inventory to quantify diagnostic reasoning skills in optometry practice},
journal={BMC Medical Education},
year={2022},
month={Jul},
day={11},
volume={22},
number={1},
pages={536},
abstract={Diagnostic reasoning is an essential skill for optometry practice and a vital part of the curriculum for optometry trainees but there is limited understanding of how diagnostic reasoning is performed in optometry or how this skill is best developed. A validated and reliable self-reflective inventory for diagnostic reasoning in optometry, would enable trainees and registered practitioners to benchmark their diagnostic reasoning skills, identify areas of strength and areas for improvement.},
issn={1472-6920},
doi={10.1186/s12909-022-03493-6},
url={https://doi.org/10.1186/s12909-022-03493-6}
}

@article{doi:10.1073/pnas.1618211113,
author = {Ben Shneiderman },
title = {The dangers of faulty, biased, or malicious algorithms requires independent oversight},
journal = {Proceedings of the National Academy of Sciences},
volume = {113},
number = {48},
pages = {13538-13540},
year = {2016},
doi = {10.1073/pnas.1618211113},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1618211113},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1618211113}}

@inproceedings{10.1145/3313831.3376545,
author = {Dourish, Paul and Lawrence, Christopher and Leong, Tuck Wah and Wadley, Greg},
title = {On Being Iterated: The Affective Demands of Design Participation},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376545},
doi = {10.1145/3313831.3376545},
abstract = {Iteration is a central feature of most HCI design methods, creating as it does opportunities for engagements with stakeholder groups. But what does iteration demand of those groups? Under what conditions do iterative engagements arise, and with what stakes? Building on experiences with Aboriginal Australian communities, and drawing on feminist and decolonial thinking, we examine the nature of iteration for HCI and how it frames encounters between design and use, with a focus on the affective dimension of engagement in iterative design processes.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–11},
numpages = {11},
keywords = {postcolonial theory, participation, feminist theory, user-centered design, decolonial theory, iteration, cultural computing},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{https://doi.org/10.3322/caac.21552,
author = {Bi, Wenya Linda and Hosny, Ahmed and Schabath, Matthew B. and Giger, Maryellen L. and Birkbak, Nicolai J. and Mehrtash, Alireza and Allison, Tavis and Arnaout, Omar and Abbosh, Christopher and Dunn, Ian F. and Mak, Raymond H. and Tamimi, Rulla M. and Tempany, Clare M. and Swanton, Charles and Hoffmann, Udo and Schwartz, Lawrence H. and Gillies, Robert J. and Huang, Raymond Y. and Aerts, Hugo J. W. L.},
title = {Artificial intelligence in cancer imaging: Clinical challenges and applications},
journal = {CA: A Cancer Journal for Clinicians},
volume = {69},
number = {2},
pages = {127-157},
keywords = {artificial intelligence, cancer imaging, clinical challenges, deep learning, radiomics},
doi = {https://doi.org/10.3322/caac.21552},
url = {https://acsjournals.onlinelibrary.wiley.com/doi/abs/10.3322/caac.21552},
eprint = {https://acsjournals.onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21552},
abstract = {Abstract Judgement, as one of the core tenets of medicine, relies upon the integration of multilayered data with nuanced decision making. Cancer offers a unique context for medical decisions given not only its variegated forms with evolution of disease but also the need to take into account the individual condition of patients, their ability to receive treatment, and their responses to treatment. Challenges remain in the accurate detection, characterization, and monitoring of cancers despite improved technologies. Radiographic assessment of disease most commonly relies upon visual evaluations, the interpretations of which may be augmented by advanced computational analyses. In particular, artificial intelligence (AI) promises to make great strides in the qualitative interpretation of cancer imaging by expert clinicians, including volumetric delineation of tumors over time, extrapolation of the tumor genotype and biological course from its radiographic phenotype, prediction of clinical outcome, and assessment of the impact of disease and treatment on adjacent organs. AI may automate processes in the initial interpretation of images and shift the clinical workflow of radiographic detection, management decisions on whether or not to administer an intervention, and subsequent observation to a yet to be envisioned paradigm. Here, the authors review the current state of AI as applied to medical imaging of cancer and describe advances in 4 tumor types (lung, brain, breast, and prostate) to illustrate how common clinical problems are being addressed. Although most studies evaluating AI applications in oncology to date have not been vigorously validated for reproducibility and generalizability, the results do highlight increasingly concerted efforts in pushing AI technology to clinical use and to impact future directions in cancer care.},
year = {2019}
}

@inproceedings{10.1145/3313831.3376718,
author = {Beede, Emma and Baylor, Elizabeth and Hersch, Fred and Iurchenko, Anna and Wilcox, Lauren and Ruamviboonsuk, Paisan and Vardoulakis, Laura M.},
title = {A Human-Centered Evaluation of a Deep Learning System Deployed in Clinics for the Detection of Diabetic Retinopathy},
year = {2020},
isbn = {9781450367080},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3313831.3376718},
doi = {10.1145/3313831.3376718},
abstract = {Deep learning algorithms promise to improve clinician workflows and patient outcomes. However, these gains have yet to be fully demonstrated in real world clinical settings. In this paper, we describe a human-centered study of a deep learning system used in clinics for the detection of diabetic eye disease. From interviews and observation across eleven clinics in Thailand, we characterize current eye-screening workflows, user expectations for an AI-assisted screening process, and post-deployment experiences. Our findings indicate that several socio-environmental factors impact model performance, nursing workflows, and the patient experience. We draw on these findings to reflect on the value of conducting human-centered evaluative research alongside prospective evaluations of model accuracy.},
booktitle = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–12},
numpages = {12},
keywords = {health, human-centered ai, deep learning, diabetes},
location = {Honolulu, HI, USA},
series = {CHI '20}
}

@article{KOHLI2018535,
title = {Why CAD Failed in Mammography},
journal = {Journal of the American College of Radiology},
volume = {15},
number = {3, Part B},
pages = {535-537},
year = {2018},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2017.12.029},
url = {https://doi.org/10.1016/j.jacr.2017.12.029},
author = {Ajay Kohli and Saurabh Jha}
}

@inproceedings{10.1145/3311957.3359433,
author = {Park, Sun Young and Kuo, Pei-Yi and Barbarin, Andrea and Kaziunas, Elizabeth and Chow, Astrid and Singh, Karandeep and Wilcox, Lauren and Lasecki, Walter S.},
title = {Identifying Challenges and Opportunities in Human-AI Collaboration in Healthcare},
year = {2019},
isbn = {9781450366922},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3311957.3359433},
doi = {10.1145/3311957.3359433},
abstract = {The proposed workshop will identify research questions that will enable the field to uncover the types of work, labor relations, and social impacts that should be considered when designing AI-based healthcare technology. The workshop aims to outline key challenges, guidelines, and future agendas for the field, and provide collaboration opportunities for CSCW researchers, social scientists, AI researchers, clinicians, and relevant stakeholders in healthcare, to share their perspectives and co-create sociotechnical approaches to tackle timely issues related to AI and automation in healthcare work.},
booktitle = {Conference Companion Publication of the 2019 on Computer Supported Cooperative Work and Social Computing},
pages = {506–510},
numpages = {5},
keywords = {machine learning, healthcare, algorithms, ai fairness, ai transparency, artificial intelligence, automation, explainable ai, sociotechnical systems},
location = {Austin, TX, USA},
series = {CSCW '19}
}

@Article{Rajpurkar2022,
author={Rajpurkar, Pranav
and Chen, Emma
and Banerjee, Oishi
and Topol, Eric J.},
title={AI in health and medicine},
journal={Nature Medicine},
year={2022},
month={Jan},
day={01},
volume={28},
number={1},
pages={31-38},
abstract={Artificial intelligence (AI) is poised to broadly reshape medicine, potentially improving the experiences of both clinicians and patients. We discuss key findings from a 2-year weekly effort to track and share key developments in medical AI. We cover prospective studies and advances in medical image analysis, which have reduced the gap between research and deployment. We also address several promising avenues for novel medical AI research, including non-image data sources, unconventional problem formulations and human--AI collaboration. Finally, we consider serious technical and ethical challenges in issues spanning from data scarcity to racial bias. As these challenges are addressed, AI's potential may be realized, making healthcare more accurate, efficient and accessible for patients worldwide.},
issn={1546-170X},
doi={10.1038/s41591-021-01614-0}
}

@article{DIN2022106073,
title = {Breast cancer detection using deep learning: Datasets, methods, and challenges ahead},
journal = {Computers in Biology and Medicine},
volume = {149},
pages = {106073},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106073},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522007818},
author = {Nusrat Mohi ud din and Rayees Ahmad Dar and Muzafar Rasool and Assif Assad},
keywords = {Breast Cancer, Convolution neural networks, Deep learning, Mammography, Histopathology, MRI, Ultrasound, Thermography},
abstract = {Breast Cancer (BC) is the most commonly diagnosed cancer and second leading cause of mortality among women. About 1 in 8 US women (about 13\%) will develop invasive BC throughout their lifetime. Early detection of this life-threatening disease not only increases the survival rate but also reduces the treatment cost. Fortunately, advancements in radiographic imaging like “Mammograms”, “Computed Tomography (CT)”, “Magnetic Resonance Imaging (MRI)”, “3D Mammography”, and “Histopathological Imaging (HI)” have made it feasible to diagnose this life-taking disease at an early stage. However, the analysis of radiographic images and Histopathological images is done by experienced radiologists and pathologists, respectively. The process is not only costly but also error-prone. Over the last ten years, Computer Vision and Machine Learning (ML) have transformed the world in every way possible. Deep learning (DL), a subfield of ML has shown outstanding results in a variety of fields, particularly in the biomedical industry, because of its ability to handle large amounts of data. DL techniques automatically extract the features by analyzing the high dimensional and correlated data efficiently. The potential and ability of DL models have also been utilized and evaluated in the identification and prognosis of BC, utilizing radiographic and Histopathological images, and have performed admirably. However, AI has shown good claims in retrospective studies only. External validations are needed for translating these cutting-edge AI tools as a clinical decision maker. The main aim of this research work is to present the critical analysis of the research and findings already done to detect and classify BC using various imaging modalities including “Mammography”, “Histopathology”, “Ultrasound”, “PET/CT”, “MRI”, and “Thermography”. At first, a detailed review of the past research papers using Machine Learning, Deep Learning and Deep Reinforcement Learning for BC classification and detection is carried out. We also review the publicly available datasets for the above-mentioned imaging modalities to make future research more accessible. Finally, a critical discussion section has been included to elaborate open research difficulties and prospects for future study in this emerging area, demonstrating the limitations of Deep Learning approaches.}
}

@Article{Lundberg2020,
author={Lundberg, Scott M.
and Erion, Gabriel
and Chen, Hugh
and DeGrave, Alex
and Prutkin, Jordan M.
and Nair, Bala
and Katz, Ronit
and Himmelfarb, Jonathan
and Bansal, Nisha
and Lee, Su-In},
title={From local explanations to global understanding with explainable AI for trees},
journal={Nature Machine Intelligence},
year={2020},
month={Jan},
day={01},
volume={2},
number={1},
pages={56-67},
abstract={Tree-based machine learning models such as random forests, decision trees and gradient boosted trees are popular nonlinear predictive models, yet comparatively little attention has been paid to explaining their predictions. Here we improve the interpretability of tree-based models through three main contributions. (1) A polynomial time algorithm to compute optimal explanations based on game theory. (2) A new type of explanation that directly measures local feature interaction effects. (3) A new set of tools for understanding global model structure based on combining many local explanations of each prediction. We apply these tools to three medical machine learning problems and show how combining many high-quality local explanations allows us to represent global structure while retaining local faithfulness to the original model. These tools enable us to (1) identify high-magnitude but low-frequency nonlinear mortality risk factors in the US population, (2) highlight distinct population subgroups with shared risk characteristics, (3) identify nonlinear interaction effects among risk factors for chronic kidney disease and (4) monitor a machine learning model deployed in a hospital by identifying which features are degrading the model's performance over time. Given the popularity of tree-based machine learning models, these improvements to their interpretability have implications across a broad set of domains.},
issn={2522-5839},
doi={10.1038/s42256-019-0138-9}
}

@inproceedings{10.1145/3411764.3445717,
author = {Bansal, Gagan and Wu, Tongshuang and Zhou, Joyce and Fok, Raymond and Nushi, Besmira and Kamar, Ece and Ribeiro, Marco Tulio and Weld, Daniel},
title = {Does the Whole Exceed Its Parts? The Effect of AI Explanations on Complementary Team Performance},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445717},
doi = {10.1145/3411764.3445717},
abstract = {Many researchers motivate explainable AI with studies showing that human-AI team performance on decision-making tasks improves when the AI explains its recommendations. However, prior studies observed improvements from explanations only when the AI, alone, outperformed both the human and the best team. Can explanations help lead to complementary performance, where team accuracy is higher than either the human or the AI working solo? We conduct mixed-method user studies on three datasets, where an AI with accuracy comparable to humans helps participants solve a task (explaining itself in some conditions). While we observed complementary improvements from AI augmentation, they were not increased by explanations. Rather, explanations increased the chance that humans will accept the AI’s recommendation, regardless of its correctness. Our result poses new challenges for human-centered AI: Can we develop explanatory approaches that encourage appropriate trust in AI, and therefore help generate (or improve) complementary performance?},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {81},
numpages = {16},
keywords = {Human-AI teams, Augmented intelligence, Explainable AI},
location = {Yokohama, Japan},
series = {CHI '21}
}

@Article{Rudin2022,
author={Rudin, Cynthia},
title={Why black box machine learning should be avoided for high-stakes decisions, in brief},
journal={Nature Reviews Methods Primers},
year={2022},
month={Oct},
day={27},
volume={2},
number={1},
pages={81},
abstract={Black box machine learning models can be dangerous for high-stakes decisions. They rely on untrustworthy databases, and their predictions are difficult to troubleshoot, explain and error check for real-time predictions. Their use leads to serious ethics and accountability issues.},
issn={2662-8449},
doi={10.1038/s43586-022-00172-0},
url={https://doi.org/10.1038/s43586-022-00172-0}
}

@Article{Kawamleh2022,
author={Kawamleh, Suzanne},
title={Against explainability requirements for ethical artificial intelligence in health care},
journal={AI and Ethics},
year={2022},
month={Aug},
day={29},
number={1},
volume={1},
pages={1--16},
numpages={16},
abstract={It is widely accepted that explainability is a requirement for the ethical use of artificial intelligence (AI) in health care. I challenge this Explainability Imperative (EI) by considering the following question: does the use of epistemically opaque medical AI systems violate existing legal standards for informed consent? If yes, and if the failure to meet such standards can be attributed to epistemic opacity, then explainability is a requirement for AI in healthcare. If not, then based on at least one metric of ethical medical practice (informed consent), explainability is not required for the ethical use of AI in healthcare. First, I show that the use of epistemically opaque AI applications is compatible with meeting accepted legal criteria for informed consent. Second, I argue that human experts are also black boxes with respect to the criteria by which they arrive at a diagnosis. Human experts can nonetheless meet established requirements for informed consent. I conclude that the use of black-box AI systems does not violate patients' rights to informed consent, and thus, with respect to informed consent, explainability is not required for medical AI.},
issn={2730-5961},
doi={10.1007/s43681-022-00212-1},
url={https://doi.org/10.1007/s43681-022-00212-1}
}

@article{https://doi.org/10.1111/nuf.12430,
author = {Abdelaziz, Enas Mahrous and Diab, Iman Abdelmotelb and Ouda, Marwa Mohamed Ahmed and Elsharkawy, Nadia Bassiouni and Abdelkader, Fadia Ahmed},
title = {The effectiveness of assertiveness training program on psychological wellbeing and work engagement among novice psychiatric nurses},
journal = {Nursing Forum},
volume = {55},
number = {3},
pages = {309-319},
keywords = {assertiveness, novice nurses, psychological well-being, training program, work engagement},
doi = {https://doi.org/10.1111/nuf.12430},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/nuf.12430},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/nuf.12430},
abstract = {Abstract Aim The study aimed to assess the effectiveness of an assertiveness training program on psychological wellbeing and work engagement among novice psychiatric nurses. Design A quasi-experimental design was utilized (one group pre/post assessment). Setting The study was conducted at The Abbasia hospital for mental health in Cairo, Egypt. Subjects The subjects of the study were 36 novice nurses who were starting their careers the hospital during 2017/2018. Tools The current study used four tools for collecting the data: socio-demographic data sheet, Rathus Assertiveness Schedule, Riff's Psychological Well-Being Scale, and Utrecht Work Engagement Scale. Results The study results revealed a statistically significant difference between measure one and measure two intervention program regarding assertiveness skills, psychological well-being, and work engagement. Also, there was a significant positive correlation between the total mean scores of assertiveness skills and total mean scores of psychological well-being. Conclusions This single-group feasibility study demonstrated that assertiveness training for novice nurses seems feasible. It may achieve a favorable outcome in developing assertiveness skills and improving psychological wellbeing. Recommendations Further randomized controlled trials with more extended follow-up periods are required.},
year = {2020}
}

@Article{Seidel2021,
author={Seidel, Tina
and Schnitzler, Katharina
and Kosel, Christian
and St{\"u}rmer, Kathleen
and Holzberger, Doris},
title={Student Characteristics in the Eyes of Teachers: Differences Between Novice and Expert Teachers in Judgment Accuracy, Observed Behavioral Cues, and Gaze},
journal={Educational Psychology Review},
year={2021},
month={Mar},
day={01},
volume={33},
number={1},
pages={69-89},
abstract={The present study investigates teacher diagnostic skills when observing student engagement and inferring to underlying student characteristic profiles. Five student profiles as empirically determined in previous studies are selected: three incoherent (overestimating, uninterested, and underestimating) and two coherent (strong and struggling) profiles. Teacher professional vision and underlying assumptions about processes of noticing and reasoning about the chosen diagnostic situation serve as a conceptual basis. In the empirical study (N{\thinspace}={\thinspace}41 participants), it is investigated to what extent expert and novice teachers differ with regard to judgment accuracy of underlying student profiles, observed student cues used for judgment, and teacher gaze as perceptual indicator. The study task involved observing a video clip and diagnosing five marked students based on their underlying profiles. First, findings of the study suggest that expert teachers are more accurate in judging incoherent profiles compared to novices. Second, both novices as well as experts state valid behavioral cues when inferring from student engagement to underlying student profile. Third, experts spend more teacher gaze on student profiles which might need adaptive pedagogical action (struggling, underestimating, uninterested student). The study provides first evidence on teacher gaze during the professional task of diagnosing individual students in the process of teaching. Regarding the conceptual model of teacher professional vision teacher gaze can serve as an additional operationalization of the noticing component of teacher professional vision.},
issn={1573-336X},
doi={10.1007/s10648-020-09532-2},
url={https://doi.org/10.1007/s10648-020-09532-2}
}

@article{HOHENSTEIN2020106190,
title = {AI as a moral crumple zone: The effects of AI-mediated communication on attribution and trust},
journal = {Computers in Human Behavior},
volume = {106},
pages = {106190},
year = {2020},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2019.106190},
url = {https://www.sciencedirect.com/science/article/pii/S0747563219304029},
author = {Jess Hohenstein and Malte Jung},
keywords = {Artificial intelligence (AI), Communication, AI-Mediated Communication (AI-MC), Computer-Mediated Communication (CMC), Trust, Attribution},
abstract = {AI-mediated communication (AI-MC) represents a new paradigm where communication is augmented or generated by an intelligent system. As AI-MC becomes more prevalent, it is important to understand the effects that it has on human interactions and interpersonal relationships. Previous work tells us that in human interactions with intelligent systems, misattribution is common and trust is developed and handled differently than in interactions between humans. This study uses a 2 (successful vs. unsuccessful conversation) x 2 (standard vs. AI-mediated messaging app) between subjects design to explore whether AI mediation has any effects on attribution and trust. We show that the presence of AI-generated smart replies serves to increase perceived trust between human communicators and that, when things go awry, the AI seems to be perceived as a coercive agent, allowing it to function like a moral crumple zone and lessen the responsibility assigned to the other human communicator. These findings suggest that smart replies could be used to improve relationships and perceptions of conversational outcomes between interlocutors. Our findings also add to existing literature regarding perceived agency in smart agents by illustrating that in this type of AI-MC, the AI is considered to have agency only when communication goes awry.}
}

@article{10.1145/3479587,
author = {Zagalsky, Alexey and Te'eni, Dov and Yahav, Inbal and Schwartz, David G. and Silverman, Gahl and Cohen, Daniel and Mann, Yossi and Lewinsky, Dafna},
title = {The Design of Reciprocal Learning Between Human and Artificial Intelligence},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479587},
doi = {10.1145/3479587},
abstract = {The need for advanced automation and artificial intelligence (AI) in various fields, including text classification, has dramatically increased in the last decade, leaving us critically dependent on their performance and reliability. Yet, as we increasingly rely more on AI applications, their algorithms are becoming more nuanced, more complex, and less understandable precisely at a time we need to understand them better and trust them to perform as expected. Text classification in the medical and cybersecurity domains is a good example of a task where we may wish to keep the human in the loop. Human experts lack the capacity to deal with the high volume and velocity of data that needs to be classified, and ML techniques are often unexplainable and lack the ability to capture the required context needed to make the right decision and take action. We propose a new abstract configuration of Human-Machine Learning (HML) that focuses on reciprocal learning, where the human and the AI are collaborating partners. We employ design-science research (DSR) to learn and design an application of the HML configuration, which incorporates software to support combining human and artificial intelligences. We define the HML configuration by its conceptual components and their function. We then describe the development of a system called Fusion that supports human-machine reciprocal learning. Using two case studies of text classification from the cyber domain, we evaluate Fusion and the proposed HML approach, demonstrating benefits and challenges. Our results show a clear ability of domain experts to improve the ML classification performance over time, while both human and machine, collaboratively, develop their conceptualization, i.e., their knowledge of classification. We generalize our insights from the DSR process as actionable principles for researchers and designers of 'human in the learning loop' systems. We conclude the paper by discussing HML configurations and the challenge of capturing and representing knowledge gained jointly by human and machine, an area we feel has great potential.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {443},
numpages = {36},
keywords = {human intelligence, AI, cyber-security, feedback, context, explainabilitiy, text classification, accuracy}
}

@inproceedings{10.1145/3334480.3375147,
author = {Li, Yang and Kumar, Ranjitha and Lasecki, Walter S. and Hilliges, Otmar},
title = {Artificial Intelligence for HCI: A Modern Approach},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3375147},
doi = {10.1145/3334480.3375147},
abstract = {Artificial intelligence (AI) and Human Computer Interaction (HCI) share common roots and early work on conversational agents has laid the foundation for both fields. However, in subsequent decades the initial tight connection between the fields has become less pronounced. The recent rise of deep learning has revolutionized AI and has led to a raft of practical methods and tools that significantly impact areas outside of core-AI. In particular, modern AI techniques now power new ways for machines and humans to interact. Thus it is timely to investigate how modern AI can propel HCI research in new ways and how HCI research can help direct AI developments. This workshop offers a forum for researchers to discuss new opportunities that lie in bringing modern AI methods into HCI research, identifying important problems to investigate, showcasing computational and scientific methods that can be applied, and sharing datasets and tools that are already available or proposing those that should be further developed. The topics we are interested in including deep learning methods for understanding and modeling human behaviors and enabling new interaction modalities, hybrid intelligence that combine human and machine intelligence to solve difficult tasks, and tools and methods for interaction data curation and large-scale data-driven design. At the core of these topics, we want to start the conversation on how data-driven and data-centric approaches of modern AI can impact HCI.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {design guidelines, data-driven design and modeling, crowdsourcing, artificial intelligence, sensing, human computer interaction, algorithms and tools, deep learning},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@inproceedings{10.1145/3334480.3382842,
author = {Bruzzese, Tommy and Gao, Irena and Dietz, Griffin and Ding, Christina and Romanos, Alyssa},
title = {Effect of Confidence Indicators on Trust in AI-Generated Profiles},
year = {2020},
isbn = {9781450368193},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3334480.3382842},
doi = {10.1145/3334480.3382842},
abstract = {Artificial Intelligence (AI) is increasingly augmenting and generating online content, but research suggests that users distrust content which they believe to be AI-generated. In this paper, we study whether introducing a confidence indicator, a text rating of an algorithm's confidence in its source data alongside rationale for why the data is more or less trustworthy, affects this distrust in Airbnb host profiles believed to be computer-generated. Our results indicate that a low-confidence indicator decreases participant trust in the rental host, but high-confidence indicators have no significant impact on trust. These findings suggest that user trust of AI-generated content can be negatively, but not positively, affected by a confidence indicator.},
booktitle = {Extended Abstracts of the 2020 CHI Conference on Human Factors in Computing Systems},
pages = {1–8},
numpages = {8},
keywords = {trust, artificial intelligence, computer-mediated communication (CMC), artificial intelligence-mediated communication (AI-MC)},
location = {Honolulu, HI, USA},
series = {CHI EA '20}
}

@article{NAISEH2023102941,
title = {How the different explanation classes impact trust calibration: The case of clinical decision support systems},
journal = {International Journal of Human-Computer Studies},
volume = {169},
pages = {102941},
year = {2023},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2022.102941},
url = {https://www.sciencedirect.com/science/article/pii/S1071581922001616},
author = {Mohammad Naiseh and Dena Al-Thani and Nan Jiang and Raian Ali},
keywords = {Explainable AI, Clinical decision support systems, Human-AI Interaction, Trust Calibration},
abstract = {Machine learning has made rapid advances in safety-critical applications, such as traffic control, finance, and healthcare. With the criticality of decisions they support and the potential consequences of following their recommendations, it also became critical to provide users with explanations to interpret machine learning models in general, and black-box models in particular. However, despite the agreement on explainability as a necessity, there is little evidence on how recent advances in eXplainable Artificial Intelligence literature (XAI) can be applied in collaborative decision-making tasks, i.e., human decision-maker and an AI system working together, to contribute to the process of trust calibration effectively. This research conducts an empirical study to evaluate four XAI classes for their impact on trust calibration. We take clinical decision support systems as a case study and adopt a within-subject design followed by semi-structured interviews. We gave participants clinical scenarios and XAI interfaces as a basis for decision-making and rating tasks. Our study involved 41 medical practitioners who use clinical decision support systems frequently. We found that users perceive the contribution of explanations to trust calibration differently according to the XAI class and to whether XAI interface design fits their job constraints and scope. We revealed additional requirements on how explanations shall be instantiated and designed to help a better trust calibration. Finally, we build on our findings and present guidelines for designing XAI interfaces.}
}

@inproceedings{10.1145/3531146.3533193,
author = {Fogliato, Riccardo and Chappidi, Shreya and Lungren, Matthew and Fisher, Paul and Wilson, Diane and Fitzke, Michael and Parkinson, Mark and Horvitz, Eric and Inkpen, Kori and Nushi, Besmira},
title = {Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533193},
doi = {10.1145/3531146.3533193},
abstract = {Details of the designs and mechanisms in support of human-AI collaboration must be considered in the real-world fielding of AI technologies. A critical aspect of interaction design for AI-assisted human decision making are policies about the display and sequencing of AI inferences within larger decision-making workflows. We have a poor understanding of the influences of making AI inferences available before versus after human review of a diagnostic task at hand. We explore the effects of providing AI assistance at the start of a diagnostic session in radiology versus after the radiologist has made a provisional decision. We conducted a user study where 19 veterinary radiologists identified radiographic findings present in patients’ X-ray images, with the aid of an AI tool. We employed two workflow configurations to analyze (i) anchoring effects, (ii) human-AI team diagnostic performance and agreement, (iii) time spent and confidence in decision making, and (iv) perceived usefulness of the AI. We found that participants who are asked to register provisional responses in advance of reviewing AI inferences are less likely to agree with the AI regardless of whether the advice is accurate and, in instances of disagreement with the AI, are less likely to seek the second opinion of a colleague. These participants also reported that the AI advice to be less useful. Surprisingly, requiring provisional decisions on cases in advance of the display of AI inferences did not lengthen the time participants spent on the task. The study provides generalizable and actionable insights for the deployment of clinical AI tools in human-in-the-loop systems and introduces a methodology for studying alternative designs for human-AI collaboration. We make our experimental platform available as open source to facilitate future research on the influence of alternate designs on human-AI workflows.},
booktitle = {2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1362–1374},
numpages = {13},
keywords = {decision making, clinical imaging, human-AI collaboration, anchoring bias},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@article{SU202328,
title = {Cloud–edge collaboration-based bi-level optimal scheduling for intelligent healthcare systems},
journal = {Future Generation Computer Systems},
volume = {141},
pages = {28-39},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22003661},
author = {Xin Su and Li An and Zhen Cheng and Yajuan Weng},
keywords = {Cloud–edge collaboration, Optimal scheduling, Healthcare system, Bi-level model},
abstract = {The development of intelligent healthcare systems (IHS) has raised the added value of digital medical data. With an efficient exploitation of digital medical data for diagnosis assistance, federated learning (FL) is promising in future digital health care. However, in multiple task performances, federated nodes deployed at the edge of IHS are constrained by computing and storage resources, as well as increased privacy breach risks. On account of these challenges, this paper proposes a more elaborated cloud–edge collaboration (CEC) framework of IHS combining FL and blockchain. Thus, a bi-level optimization scheduling IHS model is proposed, considering the large-scale access requirement of distributed generation (DG), energy storage (ES) and controllable load (CL) access to the IHS. Simulation results confirm an effective reduction of execution delay and power consumption, and a better interest coordination among multi-stakeholders.}
}

@article{ZAPPATORE20231,
title = {Semantic models for IoT sensing to infer environment–wellness relationships},
journal = {Future Generation Computer Systems},
volume = {140},
pages = {1-17},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2022.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X22003211},
author = {Marco Zappatore and Antonella Longo and Angelo Martella and Beniamino {Di Martino} and Antonio Esposito and Serena Angela Gracco},
keywords = {IoT interoperability, Semantic API, Environmental sensing, Mobile Crowd Sensing, Ontology patterns},
abstract = {Every time an Internet of Things (IoT) solution is deployed, every time a smartphone owner connects her/his wireless device to a wearable activity-tracker, every time groups of citizens use geo-mapping applications to move around the city, choosing the least crowded path, data are produced and information have to be exchanged appropriately via APIs. Even if novel added-value IoT-based applications appear on the market with increasing speed, true semantic interoperability is far from being achieved, thus limiting the large-scale exploitation, the scalability and the time-to-market of novel apps. Currently, connecting different data prosumers with multiple data sources is still hampered by the lack of standardized and sustainable solutions, especially due to the significant heterogeneity of IoT platforms. In such a landscape, ontologies come to the rescue, thanks to their formal semantics, knowledge representation formats, and shared vocabularies. In this paper we examine, from an ontological perspective, how to describe environmental sensing and wellness monitoring, two of the most popular application cases of Mobile Crowd Sensing (MCS) and IoT, respectively. To this purpose, an ontology of sensor-agnostic APIs is proposed, along with a set of MCS-dedicated ontology modules (and the supporting platform), leveraging on standard and reusable domain ontologies. Moreover, it will be shown how to properly combine the proposed ontologies in order to support complex functionalities based on inference rules addressing the environment–wellness relationships. Finally, specific semantic modeling patterns suitable for typical IoT and MCS scenarios will be discussed.}
}

@article{10.1001/jama.2018.17163,
    author = {Shortliffe, Edward H. and Sepúlveda, Martin J.},
    title = "{Clinical Decision Support in the Era of Artificial Intelligence}",
    journal = {JAMA},
    volume = {320},
    number = {21},
    pages = {2199-2200},
    year = {2018},
    month = {12},
    abstract = "{Clinicians and researchers have long envisioned the day when computers could assist with difficult decisions in complex clinical situations. The first article on this subject appeared in the scientific literature about 60 years ago, and the notion of computer-based clinical decision support has subsequently been a dominant topic for informatics research. Two recent Viewpoints in JAMA highlighted the promise of deep learning in medicine. Such new data analytic methods have much to offer in interpreting large and complex data sets. This Viewpoint is focused on the subset of decision support systems that are designed to be used interactively by clinicians as they seek to reach decisions, regardless of the underlying analytic methodology that they incorporate.}",
    issn = {0098-7484},
    doi = {10.1001/jama.2018.17163},
    url = {https://doi.org/10.1001/jama.2018.17163},
}

@inproceedings{10.1145/3491102.3517789,
author = {Zimmerman, John and Steinfeld, Aaron and Tomasic, Anthony and J. Romero, Oscar},
title = {Recentering Reframing as an RtD Contribution: The Case of Pivoting from Accessible Web Tables to a Conversational Internet},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517789},
doi = {10.1145/3491102.3517789},
abstract = {Design produces valuable knowledge by offering new perspectives that reframe problematic situations. Research through Design (RtD) contributes new frames along with design work demonstrating a frame's value. Interestingly, RtD papers rarely describe how reframing happens. This gap in documentation unintentionally implies a romantic account of design, it implies that the first step of an RtD project is to have a brilliant idea. This is especially problematic in cases where the reframing causes a pivot that leads to a new research program. To help address this gap, we describe a case where through a series of three design experiments we experienced a research pivot. We describe how our work to improve web-table navigation for screen-reader users broke our frame. The break led to a new research program focused on constructing a conversational internet. This paper offers our case along with reflection on reporting design work that drives reframing.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {541},
numpages = {14},
keywords = {accessibility, design experiment, design research program, drifting with intention, visually impaired, Research through Design, reframe},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3538882.3542790,
author = {Shneiderman, Ben},
title = {Human-Centered AI: Ensuring Human Control While Increasing Automation},
year = {2022},
isbn = {9781450394017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3538882.3542790},
doi = {10.1145/3538882.3542790},
abstract = {A new synthesis is emerging that integrates Artificial Intelligence (AI) technologies with Human-Computer Interaction to produce Human-Centered AI (HCAI). Advocates of this new synthesis seek to amplify, augment, and enhance human abilities, so as to empower people, build their self-efficacy, support creativity, recognize responsibility, and promote social connections.Researchers, developers, business leaders, policy makers and others are expanding the technology-centered scope of AI to include HCAI ways of thinking. This expansion from an algorithm-focused view to embrace a human-centered perspective, can shape the future of technology so as to better serve human needs. Educators, designers, software engineers, product managers, evaluators, and government agency staffers can build on AI-driven technologies to design products and services that make life better for the users. These human-centered products and services will enable people to better care for each other, build sustainable communities, and restore the environment. The passionate advocates of HCAI are devoted to furthering human values, rights, justice, and dignity, by building reliable, safe, and trustworthy systems.Early hypertext systems required user assigned links for text files, giving full control to users, while providing readers with an understandable and predictable design. However, innovators quickly realized that there were many strategies to improve hypertext designs by giving users spatial presentations of the related documents, recommendations for links, ways to collaborate, and interactive animated graphical presentations. Other features supported history-keeping, note-taking, and audio for all users, but especially for users with visual disabilities.Over time improved hypertext systems incorporated machine learning and other artificial intelligence techniques that provided automation of features, but sometimes produced unexpected and incomprehensible results. Current strategies are to give users more control by providing previews of potential traversals, reminders, alerts, and suggestions that guide human reflection about their goals and methods. Atzenbeck et al. suggest that hypertext is a method of inquiry, opening the door to creativity support tools that accelerate exploration and discovery, amplified by the Al-infused supertools of Human-Centered AI [1].A medical hypertext scenario could enable a physician to provide a patient history, lab tests, and current symptoms as a starting point. The hypertext system could respond with a set of possible diagnoses, which could be selected by the physician, leading to a refined analysis, links to recent clinical trial results, suggestions of consulting specialists, and recommendations for leading treatment centers. The physician could share the analysis with teammates or specialists to get feedback. The physician's exploration records could be saved to the patient's history, so that the treatment plan could be formulated based on reliable resources and then refined by discussions with patients, who would be given links to patient-centered descriptions of the diagnosis and treatment plan. The physician is responsible for what happens, but this scenario provides a strong history for retrospective analyzes of the choices that were made and the outcomes.If human-centered AI design scenarios like this one are oriented to amplifying, augmenting, empowering and enhancing human performance, then the chance of successful outcomes will increase. The passionate advocates of HCAI are devoted to furthering human values, rights, justice, and dignity, by building reliable, safe, and trustworthy systems.The talk will include examples, references to further work, and discussion time for questions. These ideas are drawn from Ben Shneiderman's new book Human-Centered AI [6]. Further information at: https://hcil.umd.edu/human-centered-ai},
booktitle = {Proceedings of the 5th Workshop on Human Factors in Hypertext},
articleno = {1},
numpages = {2},
keywords = {human-centered AI, augmentation, interactive visual explanations, user interface design, human performance},
location = {Barcelona, Spain},
series = {HUMAN '22}
}

@Article{Wetzstein2020,
author={Wetzstein, Gordon
and Ozcan, Aydogan
and Gigan, Sylvain
and Fan, Shanhui
and Englund, Dirk
and Solja{\v{c}}i{\'{c}}, Marin
and Denz, Cornelia
and Miller, David A. B.
and Psaltis, Demetri},
title={Inference in artificial intelligence with deep optics and photonics},
journal={Nature},
year={2020},
month={Dec},
day={01},
volume={588},
number={7836},
pages={39-47},
abstract={Artificial intelligence tasks across numerous applications require accelerators for fast and low-power execution. Optical computing systems may be able to meet these domain-specific needs but, despite half a century of research, general-purpose optical computing systems have yet to mature into a practical technology. Artificial intelligence inference, however, especially for visual computing applications, may offer opportunities for inference based on optical and photonic systems. In this Perspective, we review recent work on optical computing for artificial intelligence applications and discuss its promise and challenges.},
issn={1476-4687},
doi={10.1038/s41586-020-2973-6},
url={https://doi.org/10.1038/s41586-020-2973-6}
}

@Article{Hannun2019,
author={Hannun, Awni Y.
and Rajpurkar, Pranav
and Haghpanahi, Masoumeh
and Tison, Geoffrey H.
and Bourn, Codie
and Turakhia, Mintu P.
and Ng, Andrew Y.},
title={Cardiologist-level arrhythmia detection and classification in ambulatory electrocardiograms using a deep neural network},
journal={Nature Medicine},
year={2019},
month={Jan},
day={01},
volume={25},
number={1},
pages={65-69},
abstract={Computerized electrocardiogram (ECG) interpretation plays a critical role in the clinical ECG workflow1. Widely available digital ECG data and the algorithmic paradigm of deep learning2 present an opportunity to substantially improve the accuracy and scalability of automated ECG analysis. However, a comprehensive evaluation of an end-to-end deep learning approach for ECG analysis across a wide variety of diagnostic classes has not been previously reported. Here, we develop a deep neural network (DNN) to classify 12 rhythm classes using 91,232 single-lead ECGs from 53,549 patients who used a single-lead ambulatory ECG monitoring device. When validated against an independent test dataset annotated by a consensus committee of board-certified practicing cardiologists, the DNN achieved an average area under the receiver operating characteristic curve (ROC) of 0.97. The average F1 score, which is the harmonic mean of the positive predictive value and sensitivity, for the DNN (0.837) exceeded that of average cardiologists (0.780). With specificity fixed at the average specificity achieved by cardiologists, the sensitivity of the DNN exceeded the average cardiologist sensitivity for all rhythm classes. These findings demonstrate that an end-to-end deep learning approach can classify a broad range of distinct arrhythmias from single-lead ECGs with high diagnostic performance similar to that of cardiologists. If confirmed in clinical settings, this approach could reduce the rate of misdiagnosed computerized ECG interpretations and improve the efficiency of expert human ECG interpretation by accurately triaging or prioritizing the most urgent conditions.},
issn={1546-170X},
doi={10.1038/s41591-018-0268-3},
url={https://doi.org/10.1038/s41591-018-0268-3}
}

@Article{Ruamviboonsuk2019,
author={Ruamviboonsuk, Paisan
and Krause, Jonathan
and Chotcomwongse, Peranut
and Sayres, Rory
and Raman, Rajiv
and Widner, Kasumi
and Campana, Bilson J. L.
and Phene, Sonia
and Hemarat, Kornwipa
and Tadarati, Mongkol
and Silpa-Archa, Sukhum
and Limwattanayingyong, Jirawut
and Rao, Chetan
and Kuruvilla, Oscar
and Jung, Jesse
and Tan, Jeffrey
and Orprayoon, Surapong
and Kangwanwongpaisan, Chawawat
and Sukumalpaiboon, Ramase
and Luengchaichawang, Chainarong
and Fuangkaew, Jitumporn
and Kongsap, Pipat
and Chualinpha, Lamyong
and Saree, Sarawuth
and Kawinpanitan, Srirut
and Mitvongsa, Korntip
and Lawanasakol, Siriporn
and Thepchatri, Chaiyasit
and Wongpichedchai, Lalita
and Corrado, Greg S.
and Peng, Lily
and Webster, Dale R.},
title={Deep learning versus human graders for classifying diabetic retinopathy severity in a nationwide screening program},
journal={npj Digital Medicine},
year={2019},
month={Apr},
day={10},
volume={2},
number={1},
pages={25},
abstract={Deep learning algorithms have been used to detect diabetic retinopathy (DR) with specialist-level accuracy. This study aims to validate one such algorithm on a large-scale clinical population, and compare the algorithm performance with that of human graders. A total of 25,326 gradable retinal images of patients with diabetes from the community-based, nationwide screening program of DR in Thailand were analyzed for DR severity and referable diabetic macular edema (DME). Grades adjudicated by a panel of international retinal specialists served as the reference standard. Relative to human graders, for detecting referable DR (moderate NPDR or worse), the deep learning algorithm had significantly higher sensitivity (0.97 vs. 0.74, p{\thinspace}<{\thinspace}0.001), and a slightly lower specificity (0.96 vs. 0.98, p{\thinspace}<{\thinspace}0.001). Higher sensitivity of the algorithm was also observed for each of the categories of severe or worse NPDR, PDR, and DME (p{\thinspace}<{\thinspace}0.001 for all comparisons). The quadratic-weighted kappa for determination of DR severity levels by the algorithm and human graders was 0.85 and 0.78 respectively (p{\thinspace}<{\thinspace}0.001 for the difference). Across different severity levels of DR for determining referable disease, deep learning significantly reduced the false negative rate (by 23{\%}) at the cost of slightly higher false positive rates (2{\%}). Deep learning algorithms may serve as a valuable tool for DR screening.},
issn={2398-6352},
doi={10.1038/s41746-019-0099-8},
url={https://doi.org/10.1038/s41746-019-0099-8}
}

@Article{Uddin2019,
author={Uddin, Mohammed
and Wang, Yujiang
and Woodbury-Smith, Marc},
title={Artificial intelligence for precision medicine in neurodevelopmental disorders},
journal={npj Digital Medicine},
year={2019},
month={Nov},
day={21},
volume={2},
number={1},
pages={112},
abstract={The ambition of precision medicine is to design and optimize the pathway for diagnosis, therapeutic intervention, and prognosis by using large multidimensional biological datasets that capture individual variability in genes, function and environment. This offers clinicians the opportunity to more carefully tailor early interventions--- whether treatment or preventative in nature---to each individual patient. Taking advantage of high performance computer capabilities, artificial intelligence (AI) algorithms can now achieve reasonable success in predicting risk in certain cancers and cardiovascular disease from available multidimensional clinical and biological data. In contrast, less progress has been made with the neurodevelopmental disorders, which include intellectual disability (ID), autism spectrum disorder (ASD), epilepsy and broader neurodevelopmental disorders. Much hope is pinned on the opportunity to quantify risk from patterns of genomic variation, including the functional characterization of genes and variants, but this ambition is confounded by phenotypic and etiologic heterogeneity, along with the rare and variable penetrant nature of the underlying risk variants identified so far. Structural and functional brain imaging and neuropsychological and neurophysiological markers may provide further dimensionality, but often require more development to achieve sensitivity for diagnosis. Herein, therefore, lies a precision medicine conundrum: can artificial intelligence offer a breakthrough in predicting risks and prognosis for neurodevelopmental disorders? In this review we will examine these complexities, and consider some of the strategies whereby artificial intelligence may overcome them.},
issn={2398-6352},
doi={10.1038/s41746-019-0191-0},
url={https://doi.org/10.1038/s41746-019-0191-0}
}

@article{HO2020497,
title = {Enabling Technologies for Personalized and Precision Medicine},
journal = {Trends in Biotechnology},
volume = {38},
number = {5},
pages = {497-518},
year = {2020},
issn = {0167-7799},
doi = {https://doi.org/10.1016/j.tibtech.2019.12.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167779919303166},
author = {Dean Ho and Stephen R. Quake and Edward R.B. McCabe and Wee Joo Chng and Edward K. Chow and Xianting Ding and Bruce D. Gelb and Geoffrey S. Ginsburg and Jason Hassenstab and Chih-Ming Ho and William C. Mobley and Garry P. Nolan and Steven T. Rosen and Patrick Tan and Yun Yen and Ali Zarrinpar},
keywords = {personalized medicine, precision medicine, therapeutics, diagnostics, artificial intelligence, clinical trials},
abstract = {Individualizing patient treatment is a core objective of the medical field. Reaching this objective has been elusive owing to the complex set of factors contributing to both disease and health; many factors, from genes to proteins, remain unknown in their role in human physiology. Accurately diagnosing, monitoring, and treating disorders requires advances in biomarker discovery, the subsequent development of accurate signatures that correspond with dynamic disease states, as well as therapeutic interventions that can be continuously optimized and modulated for dose and drug selection. This work highlights key breakthroughs in the development of enabling technologies that further the goal of personalized and precision medicine, and remaining challenges that, when addressed, may forge unprecedented capabilities in realizing truly individualized patient care.}
}

@inproceedings{10.1145/3491102.3517791,
author = {Zhang, Qiaoning and Lee, Matthew L and Carter, Scott},
title = {You Complete Me: Human-AI Teams and Complementary Expertise},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3517791},
doi = {10.1145/3491102.3517791},
abstract = {People consider recommendations from AI systems in diverse domains ranging from recognizing tumors in medical images to deciding which shoes look cute with an outfit. Implicit in the decision process is the perceived expertise of the AI system. In this paper, we investigate how people trust and rely on an AI assistant that performs with different levels of expertise relative to the person, ranging from completely overlapping expertise to perfectly complementary expertise. Through a series of controlled online lab studies where participants identified objects with the help of an AI assistant, we demonstrate that participants were able to perceive when the assistant was an expert or non-expert within the same task and calibrate their reliance on the AI to improve team performance. We also demonstrate that communicating expertise through the linguistic properties of the explanation text was effective, where embracing language increased reliance and distancing language reduced reliance on AI.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {114},
numpages = {28},
keywords = {trust, explainable AI, complementary expertise, human-AI teams},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@inproceedings{10.1145/3301275.3302289,
author = {Cai, Carrie J. and Jongejan, Jonas and Holbrook, Jess},
title = {The Effects of Example-Based Explanations in a Machine Learning Interface},
year = {2019},
isbn = {9781450362726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3301275.3302289},
doi = {10.1145/3301275.3302289},
abstract = {The black-box nature of machine learning algorithms can make their predictions difficult to understand and explain to end-users. In this paper, we propose and evaluate two kinds of example-based explanations in the visual domain, normative explanations and comparative explanations (Figure 1), which automatically surface examples from the training set of a deep neural net sketch-recognition algorithm. To investigate their effects, we deployed these explanations to 1150 users on QuickDraw, an online platform where users draw images and see whether a recognizer has correctly guessed the intended drawing. When the algorithm failed to recognize the drawing, those who received normative explanations felt they had a better understanding of the system, and perceived the system to have higher capability. However, comparative explanations did not always improve perceptions of the algorithm, possibly because they sometimes exposed limitations of the algorithm and may have led to surprise. These findings suggest that examples can serve as a vehicle for explaining algorithmic behavior, but point to relative advantages and disadvantages of using different kinds of examples, depending on the goal.},
booktitle = {Proceedings of the 24th International Conference on Intelligent User Interfaces},
pages = {258–262},
numpages = {5},
keywords = {machine learning, example-based explanations, explainable AI, human-AI interaction},
location = {Marina del Ray, California},
series = {IUI '19}
}

@inproceedings{10.1145/3290605.3300234,
author = {Cai, Carrie J. and Reif, Emily and Hegde, Narayan and Hipp, Jason and Kim, Been and Smilkov, Daniel and Wattenberg, Martin and Viegas, Fernanda and Corrado, Greg S. and Stumpe, Martin C. and Terry, Michael},
title = {Human-Centered Tools for Coping with Imperfect Algorithms During Medical Decision-Making},
year = {2019},
isbn = {9781450359702},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3290605.3300234},
doi = {10.1145/3290605.3300234},
abstract = {Machine learning (ML) is increasingly being used in image retrieval systems for medical decision making. One application of ML is to retrieve visually similar medical images from past patients (e.g. tissue from biopsies) to reference when making a medical decision with a new patient. However, no algorithm can perfectly capture an expert's ideal notion of similarity for every case: an image that is algorithmically determined to be similar may not be medically relevant to a doctor's specific diagnostic needs. In this paper, we identified the needs of pathologists when searching for similar images retrieved using a deep learning algorithm, and developed tools that empower users to cope with the search algorithm on-the-fly, communicating what types of similarity are most important at different moments in time. In two evaluations with pathologists, we found that these tools increased the diagnostic utility of images found and increased user trust in the algorithm. The tools were preferred over a traditional interface, without a loss in diagnostic accuracy. We also observed that users adopted new strategies when using refinement tools, re-purposing them to test and understand the underlying algorithm and to disambiguate ML errors from their own errors. Taken together, these findings inform future human-ML collaborative systems for expert decision-making.},
booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
pages = {1–14},
numpages = {14},
keywords = {machine learning, clinical health, human-ai interaction},
location = {Glasgow, Scotland Uk},
series = {CHI '19}
}

@inproceedings{10.1145/3491102.3502104,
author = {Panigutti, Cecilia and Beretta, Andrea and Giannotti, Fosca and Pedreschi, Dino},
title = {Understanding the Impact of Explanations on Advice-Taking: A User Study for AI-Based Clinical Decision Support Systems},
year = {2022},
isbn = {9781450391573},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491102.3502104},
doi = {10.1145/3491102.3502104},
abstract = {The field of eXplainable Artificial Intelligence (XAI) focuses on providing explanations for AI systems’ decisions. XAI applications to AI-based Clinical Decision Support Systems (DSS) should increase trust in the DSS by allowing clinicians to investigate the reasons behind its suggestions. In this paper, we present the results of a user study on the impact of advice from a clinical DSS on healthcare providers’ judgment in two different cases: the case where the clinical DSS explains its suggestion and the case it does not. We examined the weight of advice, the behavioral intention to use the system, and the perceptions with quantitative and qualitative measures. Our results indicate a more significant impact of advice when an explanation for the DSS decision is provided. Additionally, through the open-ended questions, we provide some insights on how to improve the explanations in the diagnosis forecasts for healthcare assistants, nurses, and doctors.},
booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {568},
numpages = {9},
keywords = {Trust, Behavioral intention, HCI, XAI, User Study, Advice-taking, eXplainable AI, Clinical Decision Support System},
location = {New Orleans, LA, USA},
series = {CHI '22}
}

@article{ALANTARI201844,
title = {A fully integrated computer-aided diagnosis system for digital X-ray mammograms via deep learning detection, segmentation, and classification},
journal = {International Journal of Medical Informatics},
volume = {117},
pages = {44-54},
year = {2018},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2018.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S1386505618302880},
author = {Mugahed A. Al-antari and Mohammed A. Al-masni and Mun-Taek Choi and Seung-Moo Han and Tae-Seong Kim},
keywords = {Computer-aided diagnosis (CAD), Mass detection, You-only-look-once (YOLO), Mass segmentation, Full resolution convolutional network (FrCN), Deep learning},
abstract = {A computer-aided diagnosis (CAD) system requires detection, segmentation, and classification in one framework to assist radiologists efficiently in an accurate diagnosis. In this paper, a completely integrated CAD system is proposed to screen digital X-ray mammograms involving detection, segmentation, and classification of breast masses via deep learning methodologies. In this work, to detect breast mass from entire mammograms, You-Only-Look-Once (YOLO), a regional deep learning approach, is used. To segment the mass, full resolution convolutional network (FrCN), a new deep network model, is proposed and utilized. Finally, a deep convolutional neural network (CNN) is used to recognize the mass and classify it as either benign or malignant. To evaluate the proposed integrated CAD system in terms of the accuracies of detection, segmentation, and classification, the publicly available and annotated INbreast database was utilized. The evaluation results of the proposed CAD system via four-fold cross-validation tests show that a mass detection accuracy of 98.96\%, Matthews correlation coefficient (MCC) of 97.62\%, and F1-score of 99.24\% are achieved with the INbreast dataset. Moreover, the mass segmentation results via FrCN produced an overall accuracy of 92.97\%, MCC of 85.93\%, and Dice (F1-score) of 92.69\% and Jaccard similarity coefficient metrics of 86.37\%, respectively. The detected and segmented masses were classified via CNN and achieved an overall accuracy of 95.64\%, AUC of 94.78\%, MCC of 89.91\%, and F1-score of 96.84\%, respectively. Our results demonstrate that the proposed CAD system, through all stages of detection, segmentation, and classification, outperforms the latest conventional deep learning methodologies. Our proposed CAD system could be used to assist radiologists in all stages of detection, segmentation, and classification of breast masses.}
}

@article{STAHNKE2021103243,
title = {Novice and expert teachers’ situation-specific skills regarding classroom management: What do they perceive, interpret and suggest?},
journal = {Teaching and Teacher Education},
volume = {98},
pages = {103243},
year = {2021},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2020.103243},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X20314347},
author = {Rebekka Stahnke and Sigrid Blömeke},
keywords = {Teacher expertise, Classroom management, Situation-specific skills, Expert-novice teachers, Verbal data analysis},
abstract = {The study investigates 39 novice and expert teachers’ perception, interpretation and decision-making skills with respect to classroom management events which they observed in two video clips. Their retrospective comments were analyzed with a multi-category coding scheme. Experts interpreted more and suggested more alternative courses of action than novices. They also focused more on student learning and the context of instruction. Concerning the relation of skills and focus, experts perceived and interpreted more than novices when talking about students while making more suggestions when addressing the teacher or the context. Experts spoke more often about preventive classroom management. Conclusions for developing expertise are drawn.}
}

@article{LANDRO2020102897,
title = {Avalanche decision-making frameworks: Factors and methods used by experts},
journal = {Cold Regions Science and Technology},
volume = {170},
pages = {102897},
year = {2020},
issn = {0165-232X},
doi = {https://doi.org/10.1016/j.coldregions.2019.102897},
url = {https://www.sciencedirect.com/science/article/pii/S0165232X19301818},
author = {Markus Landrø and Audun Hetland and Rune Verpe Engeset and Gerit Pfuhl},
keywords = {Avalanche, Decision-making, Risk management, Avalanche assessment, Expert decision, Analytical processing},
abstract = {The snowy mountains of the world attract more and more backcountry recreationalists. Besides beauty and joy, traveling in avalanche terrain can involve risk of injury and even death. A correct assessment of avalanche danger and following a correct decision is crucial. This requires a thorough evaluation of a range of factors. To aid these decisions several decision-making frameworks (DMF) have been put forward. However, actual use of these frameworks and their underlying factors can be questioned. We asked 100 experts about their familiarity and usage of the DMFs and their underlying factors. We found a large discrepancy between familiarity with and actual use of the most commonly used DMFs. In contrast to most frameworks that have a probabilistic approach, experts primarily use an analytical one. We also found that experts use more factors and emphasize other factors than most DMFs do. Indeed, the factors the experts use do not match any of the DMFs well, with the agreement ranging from 56\% to 73\%. Factors seen as core in many frameworks, such as the combination of danger level and slope inclination, are by a large margin the least used of all the terrain factors among the experts. We found a void between the existing frameworks and how – and on what basis – experts make their decisions. Our findings raise a fundamental question: How, when and where do the transition from novice to expert occur? Future initiatives to revise or develop new decision-making frameworks should take into account what experts use.}
}

@article{doi:10.1080/21642850.2020.1741372,
author = {Gabor Ruzsa and Csenge Szeverenyi and Katalin Varga},
title = {Person- and job-specific factors of intuitive decision-making in clinical practice: results of a sample survey among Hungarian physicians and nurses},
journal = {Health Psychology and Behavioral Medicine},
volume = {8},
number = {1},
pages = {152-184},
year  = {2020},
publisher = {Routledge},
doi = {10.1080/21642850.2020.1741372},

URL = { 
        https://doi.org/10.1080/21642850.2020.1741372
    
},
eprint = { 
        https://doi.org/10.1080/21642850.2020.1741372
    
}

}

@InProceedings{10.1007/978-3-030-87199-4_52,
author="Barata, Catarina
and Santiago, Carlos",
editor="de Bruijne, Marleen
and Cattin, Philippe C.
and Cotin, St{\'e}phane
and Padoy, Nicolas
and Speidel, Stefanie
and Zheng, Yefeng
and Essert, Caroline",
title="Improving the Explainability of Skin Cancer Diagnosis Using CBIR",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2021",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="550--559",
abstract="Explainability is a key feature for computer-aided diagnosis systems. This property not only helps doctors understand their decisions, but also allows less experienced practitioners to improve their knowledge. Skin cancer diagnosis is a field where explainability is of critical importance, as lesions of different classes often exhibit confounding characteristics. This work proposes a deep neural network (DNN) for skin cancer diagnosis that provides explainability through content-based image retrieval. We explore several state-of-the-art approaches to improve the feature space learned by the DNN, namely contrastive, distillation, and triplet losses. We demonstrate that the combination of these regularization losses with the categorical cross-entropy leads to the best performances on melanoma classification, and results in a hybrid DNN that simultaneously: i) classifies the images; and ii) retrieves similar images justifying the diagnosis. The code is available at https://github.com/catarina-barata/CBIR{\_}Explainability{\_}Skin{\_}Cancer.",
isbn="978-3-030-87199-4"
}

@Article{Esteva2017,
author={Esteva, Andre
and Kuprel, Brett
and Novoa, Roberto A.
and Ko, Justin
and Swetter, Susan M.
and Blau, Helen M.
and Thrun, Sebastian},
title={Dermatologist-level Classification of Skin Cancer with Deep Neural Networks},
journal={Nature},
year={2017},
month={Jun},
day={01},
volume={546},
number={7660},
pages={686-686},
abstract={Nature 542, 115--118 (2017); doi:10.1038/nature21056 In the Acknowledgements section of this Letter, the sentence: ``This study was supported by the Baxter Foundation, California Institute for Regenerative Medicine (CIRM) grants TT3-05501 and RB5-07469 and US National Institutes of Health (NIH) grantsAG044815, AG009521, NS089533, AR063963 and AG020961 (H.M.B.)'' should have read: ``This study was supported by funding from the Baxter Foundation to H.M.B.'' Furthermore, the last line of the Acknowledgements section should have read: ``In addition, this work was supported by a National Institutes of Health (NIH) National Center for Advancing Translational Science Clinical and Translational Science Award (UL1 TR001085). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH.'' The original Letter has been corrected online.},
issn={1476-4687},
doi={10.1038/nature22985},
url={https://doi.org/10.1038/nature22985}
}

@Article{Sollini2020,
author={Sollini, Martina
and Bartoli, Francesco
and Marciano, Andrea
and Zanca, Roberta
and Slart, Riemer H. J. A.
and Erba, Paola A.},
title={Artificial intelligence and hybrid imaging: the best match for personalized medicine in oncology},
journal={European Journal of Hybrid Imaging},
year={2020},
month={Dec},
day={09},
volume={4},
number={1},
pages={24},
abstract={Artificial intelligence (AI) refers to a field of computer science aimed to perform tasks typically requiring human intelligence. Currently, AI is recognized in the broader technology radar within the five key technologies which emerge for their wide-ranging applications and impact in communities, companies, business, and value chain framework alike. However, AI in medical imaging is at an early phase of development, and there are still hurdles to take related to reliability, user confidence, and adoption. The present narrative review aimed to provide an overview on AI-based approaches (distributed learning, statistical learning, computer-aided diagnosis and detection systems, fully automated image analysis tool, natural language processing) in oncological hybrid medical imaging with respect to clinical tasks (detection, contouring and segmentation, prediction of histology and tumor stage, prediction of mutational status and molecular therapies targets, prediction of treatment response, and outcome). Particularly, AI-based approaches have been briefly described according to their purpose and, finally lung cancer---being one of the most extensively malignancy studied by hybrid medical imaging---has been used as illustrative scenario. Finally, we discussed clinical challenges and open issues including ethics, validation strategies, effective data-sharing methods, regulatory hurdles, educational resources, and strategy to facilitate the interaction among different stakeholders. Some of the major changes in medical imaging will come from the application of AI to workflow and protocols, eventually resulting in improved patient management and quality of life. Overall, several time-consuming tasks could be automatized. Machine learning algorithms and neural networks will permit sophisticated analysis resulting not only in major improvements in disease characterization through imaging, but also in the integration of multiple-omics data (i.e., derived from pathology, genomic, proteomics, and demographics) for multi-dimensional disease featuring. Nevertheless, to accelerate the transition of the theory to practice a sustainable development plan considering the multi-dimensional interactions between professionals, technology, industry, markets, policy, culture, and civil society directed by a mindset which will allow talents to thrive is necessary.},
issn={2510-3636},
doi={10.1186/s41824-020-00094-8},
url={https://doi.org/10.1186/s41824-020-00094-8}
}

@Article{Aerts2016,
author={Aerts, Hugo J. W. L.
and Grossmann, Patrick
and Tan, Yongqiang
and Oxnard, Geoffrey R.
and Rizvi, Naiyer
and Schwartz, Lawrence H.
and Zhao, Binsheng},
title={Defining a Radiomic Response Phenotype: A Pilot Study using targeted therapy in NSCLC},
journal={Scientific Reports},
year={2016},
month={Sep},
day={20},
volume={6},
number={1},
pages={33860},
abstract={Medical imaging plays a fundamental role in oncology and drug development, by providing a non-invasive method to visualize tumor phenotype. Radiomics can quantify this phenotype comprehensively by applying image-characterization algorithms, and may provide important information beyond tumor size or burden. In this study, we investigated if radiomics can identify a gefitinib response-phenotype, studying high-resolution computed-tomography (CT) imaging of forty-seven patients with early-stage non-small cell lung cancer before and after three weeks of therapy. On the baseline-scan, radiomic-feature Laws-Energy was significantly predictive for EGFR-mutation status (AUC{\thinspace}={\thinspace}0.67, p{\thinspace}={\thinspace}0.03), while volume (AUC{\thinspace}={\thinspace}0.59, p{\thinspace}={\thinspace}0.27) and diameter (AUC{\thinspace}={\thinspace}0.56, p{\thinspace}={\thinspace}0.46) were not. Although no features were predictive on the post-treatment scan (p{\thinspace}>{\thinspace}0.08), the change in features between the two scans was strongly predictive (significant feature AUC-range{\thinspace}={\thinspace}0.74--0.91). A technical validation revealed that the associated features were also highly stable for test-retest (mean{\thinspace}{\textpm}{\thinspace}std: ICC{\thinspace}={\thinspace}0.96{\thinspace}{\textpm}{\thinspace}0.06). This pilot study shows that radiomic data before treatment is able to predict mutation status and associated gefitinib response non-invasively, demonstrating the potential of radiomics-based phenotyping to improve the stratification and response assessment between tyrosine kinase inhibitors (TKIs) sensitive and resistant patient populations.},
issn={2045-2322},
doi={10.1038/srep33860},
url={https://doi.org/10.1038/srep33860}
}

@article{10.1145/3479549,
author = {Namara, Moses and Knijnenburg, Bart P.},
title = {The Differential Effect of Privacy-Related Trust on Groupware Application Adoption and Use during the COVID-19 Pandemic},
year = {2021},
issue_date = {October 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW2},
url = {https://doi.org/10.1145/3479549},
doi = {10.1145/3479549},
abstract = {The COVID-19 pandemic lockdown lead to the rapid adoption and use of various groupware applications ("apps'') for remote connection with colleagues, friends, and family. Different factors such as user experiences, trust, and social influences ("user-situational motivations'') were instrumental in determining how and what apps people adopted and used, especially at the onset of the COVID-19 pandemic. In this empirical study, we examine how these factors and four predominant user-situational motivations (i.e., the mandated use of an app by an employer/institution, recommended use of an app by an employer/institution, recommended use of an app by a peer(s), and self-selection of an app) influenced the rapid adoption and use of groupware applications. Specifically, we develop an "emergency adoption model" of groupware applications using 195 valid survey responses to highlight the factors that motivated these apps' use at the onset of COVID-19 pandemic lockdown. We leverage the Technology Adoption Model (TAM) and integrate it with the users' past use of the application before the COVID-19 lockdown, user-situational motivation, and their privacy-related trust in the application provider to develop a more comprehensive model. Using confirmatory factor analysis (CFA) and structural equation modeling (SEM), we find that the users who used a groupware app in the past continued to use it, and in line with TAM, users' intention to adopt and use a groupware application was largely driven by the ease-of-use and usefulness of the app. Furthermore, while not a part of the traditional TAM model, we find that privacy-related trust in the application provider plays an important role in emergency adoption. However, unlike typical adoption models, the nature of all these effects---most prominently those related to privacy-related trust---depend on the underlying situational motivation. We discuss the implications of these findings and suggest ways to improve the adoption and use of groupware applications, especially during crises like the COVID-19 pandemic.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {oct},
articleno = {405},
numpages = {34},
keywords = {privacy-related trust, TAM, trust, privacy, COVID-19, pandemic, user experience, technology adoption, groupware applications}
}

@Article{Sturesdotter2020,
author={Sturesdotter, Li
and Sandsveden, Malte
and Johnson, Kristin
and Larsson, Anna-Maria
and Zackrisson, Sophia
and Sartor, Hanna},
title={Mammographic tumour appearance is related to clinicopathological factors and surrogate molecular breast cancer subtype},
journal={Scientific Reports},
year={2020},
month={Nov},
day={30},
volume={10},
number={1},
pages={20814},
abstract={Mammographic tumour appearance may provide prognostic useful information. For example, spiculation indicates invasiveness, but also better survival compared to tumours with other appearances. We aimed to study the relationship between mammographic tumour appearance and established clinicopathological factors, including surrogate molecular breast cancer subtypes, in the large Malm{\"o} Diet and Cancer Study. A total of 1116 women with invasive breast cancer, diagnosed between 1991 and 2014, were included. Mammographic tumour appearance in relation to status for oestrogen receptor (ER), progesterone receptor (PR), human epidermal growth factor receptor 2, histological grade, Ki67 and molecular subtype was analysed using various regression models. All models were adjusted for relevant confounders, including breast density, which can affect mammographic appearance. The results consistently showed that spiculated tumours are indicative of favourable characteristics, as they are more likely to be ER and PR positive, and more often exhibit lower histological grade and lower Ki67 expression. Furthermore, spiculated tumours tend to be of luminal A-like subtype, which is associated with a good prognosis. The establishment of associations between mammographic tumour appearance and clinico­pathological factors may aid in characterizing breast cancer at an earlier stage. This could contribute to more individualized breast cancer treatment in the future.},
issn={2045-2322},
doi={10.1038/s41598-020-77053-7},
url={https://doi.org/10.1038/s41598-020-77053-7}
}

@article{SPAK2017179,
title = {BI-RADS® fifth edition: A summary of changes},
journal = {Diagnostic and Interventional Imaging},
volume = {98},
number = {3},
pages = {179-190},
year = {2017},
issn = {2211-5684},
doi = {https://doi.org/10.1016/j.diii.2017.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2211568417300013},
author = {D.A. Spak and J.S. Plaxco and L. Santiago and M.J. Dryden and B.E. Dogan},
keywords = {Breast imaging, BI-RADS, Lexicon, Mammography, Magnetic resonance imaging (MRI)},
abstract = {The Breast Imaging Reporting and Data System (BI-RADS®) is a standardized system of reporting breast pathology as seen on mammogram, ultrasound, and magnetic resonance imaging. It encourages consistency between reports and facilitates clear communication between the radiologist and other physicians by providing a lexicon of descriptors, a reporting structure that relates assessment categories to management recommendations, and a framework for data collection and auditing. This article highlights the changes made to the BI-RADS® atlas 5th edition by comparison with its predecessor, provide a useful resource for a radiologist attempting to review the recent changes to the new edition, and serve as a quick reference to those who have previously become familiar with the material.}
}

@ARTICLE{8721151,
  author={Huang, Gao and Liu, Zhuang and Pleiss, Geoff and Van Der Maaten, Laurens and Weinberger, Kilian},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Convolutional Networks with Dense Connectivity}, 
  year={2019},
  volume={1},
  number={1},
  pages={1-1},
  doi={10.1109/TPAMI.2019.2918284}
}

@Article{Aldoj2020,
author={Aldoj, Nader
and Lukas, Steffen
and Dewey, Marc
and Penzkofer, Tobias},
title={Semi-automatic classification of prostate cancer on multi-parametric MR imaging using a multi-channel 3D convolutional neural network},
journal={European Radiology},
year={2020},
month={Feb},
day={01},
volume={30},
number={2},
pages={1243-1253},
abstract={To present a deep learning--based approach for semi-automatic prostate cancer classification based on multi-parametric magnetic resonance (MR) imaging using a 3D convolutional neural network (CNN).},
issn={1432-1084},
doi={10.1007/s00330-019-06417-z},
url={https://doi.org/10.1007/s00330-019-06417-z}
}

@InProceedings{10.1007/978-3-030-22871-2_67,
author="Meacham, Sofia
and Isaac, Georgia
and Nauck, Detlef
and Virginas, Botond",
editor="Arai, Kohei
and Bhatia, Rahul
and Kapoor, Supriya",
title="Towards Explainable AI: Design and Development for Explanation of Machine Learning Predictions for a Patient Readmittance Medical Application",
booktitle="Intelligent Computing",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="939--955",
abstract="The need for explainability of AI algorithms has been identified in the literature for some time now. However, recently became even more important due to new data protection act rules (GDPR 2018) and due to the requirements for wider applicability of AI to several application areas. BT's autonomics team has recognized this through several sources and identified the vitality of AI algorithms explainability to ensure their adoption and commercialization. In this paper, we designed and developed a system providing explanations for a prediction of patient readmittance using machine learning. The requirements and the evaluation were set by BT through their projects with real-customers in the medical domain. A logistic regression machine learning algorithm was implemented with explainability ``hooks'' embedded in its code and the corresponding interfaces to the users of the system were implemented through a web interface. Python-based technologies were utilized for the implementation of the algorithm (Scikit-learn) and the web interface (web2py), and the system was evaluated through thorough testing and feedback. Initial trade-off analysis of such an approach that presents the overhead introduced by adding explainability versus the benefits was performed. Lastly, conclusions and future work are presented, considering experimentation with more algorithms and application of software engineering methods such as abstraction to the aid of explainable AI, leading further along to ``explainability by design''.",
isbn="978-3-030-22871-2"
}

@article{doi:10.1148/radiol.2020192534,
author = {Chang, Jung                        Min and Leung, Jessica W.                            T. and Moy, Linda and Ha, Su                        Min and Moon, Woo                        Kyung},
title = {Axillary Nodal Evaluation in Breast Cancer: State of the                    Art},
journal = {Radiology},
volume = {295},
number = {3},
pages = {500-515},
year = {2020},
doi = {10.1148/radiol.2020192534},
    note ={PMID: 32315268},

URL = { 
        https://doi.org/10.1148/radiol.2020192534
    
},
eprint = { 
        https://doi.org/10.1148/radiol.2020192534
    
}
,
    abstract = { Axillary lymph node (LN) metastasis is the most important predictor of overall recurrence and survival in patients with breast cancer, and accurate assessment of axillary LN involvement is an essential component in staging breast cancer. Axillary management in patients with breast cancer has become much less invasive and individualized with the introduction of sentinel LN biopsy (SLNB). Emerging evidence indicates that axillary LN dissection may be avoided in selected patients with node-positive as well as node-negative cancer. Thus, assessment of nodal disease burden to guide multidisciplinary treatment decision making is now considered to be a critical role of axillary imaging and can be achieved with axillary US, MRI, and US-guided biopsy. For the node-positive patients treated with neoadjuvant chemotherapy, restaging of the axilla with US and MRI and targeted axillary dissection in addition to SLNB is highly recommended to minimize the false-negative rate of SLNB. Efforts continue to develop prediction models that incorporate imaging features to predict nodal disease burden and to select proper candidates for SLNB. As methods of axillary nodal evaluation evolve, breast radiologists and surgeons must work closely to maximize the potential role of imaging and to provide the most optimized treatment for patients. © RSNA, 2020 Online supplemental material is available for this article. }
}

@article{RIASATIAN2021102032,
title = {Fine-Tuning and training of densenet for histopathology image representation using TCGA diagnostic slides},
journal = {Medical Image Analysis},
volume = {70},
pages = {102032},
year = {2021},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2021.102032},
author = {Abtin Riasatian and Morteza Babaie and Danial Maleki and Shivam Kalra and Mojtaba Valipour and Sobhan Hemati and Manit Zaveri and Amir Safarpoor and Sobhan Shafiei and Mehdi Afshari and Maral Rasoolijaberi and Milad Sikaroudi and Mohd Adnan and Sultaan Shah and Charles Choi and Savvas Damaskinos and Clinton JV Campbell and Phedias Diamandis and Liron Pantanowitz and Hany Kashani and Ali Ghodsi and H.R. Tizhoosh},
keywords = {Histopathology, Deep learning, Transfer learning, Image search, Image classification, Deep features, Image representation, TCGA},
abstract = {Feature vectors provided by pre-trained deep artificial neural networks have become a dominant source for image representation in recent literature. Their contribution to the performance of image analysis can be improved through fine-tuning. As an ultimate solution, one might even train a deep network from scratch with the domain-relevant images, a highly desirable option which is generally impeded in pathology by lack of labeled images and the computational expense. In this study, we propose a new network, namely KimiaNet, that employs the topology of the DenseNet with four dense blocks, fine-tuned and trained with histopathology images in different configurations. We used more than 240,000 image patches with 1000×1000 pixels acquired at 20× magnification through our proposed “high-cellularity mosaic” approach to enable the usage of weak labels of 7126 whole slide images of formalin-fixed paraffin-embedded human pathology samples publicly available through The Cancer Genome Atlas (TCGA) repository. We tested KimiaNet using three public datasets, namely TCGA, endometrial cancer images, and colorectal cancer images by evaluating the performance of search and classification when corresponding features of different networks are used for image representation. As well, we designed and trained multiple convolutional batch-normalized ReLU (CBR) networks. The results show that KimiaNet provides superior results compared to the original DenseNet and smaller CBR networks when used as feature extractor to represent histopathology images.}
}

@Article{Cadario2021,
author={Cadario, Romain
and Longoni, Chiara
and Morewedge, Carey K.},
title={Understanding, explaining, and utilizing medical artificial intelligence},
journal={Nature Human Behaviour},
year={2021},
month={Dec},
day={01},
volume={5},
number={12},
pages={1636-1642},
abstract={Medical artificial intelligence is cost-effective and scalable and often outperforms human providers, yet people are reluctant to use it. We show that resistance to the utilization of medical artificial intelligence is driven by both the subjective difficulty of understanding algorithms (the perception that they are a `black box') and by an illusory subjective understanding of human medical decision-making. In five pre-registered experiments (1--3B: N{\thinspace}={\thinspace}2,699), we find that people exhibit an illusory understanding of human medical decision-making (study 1). This leads people to believe they better understand decisions made by human than algorithmic healthcare providers (studies 2A,B), which makes them more reluctant to utilize algorithmic than human providers (studies 3A,B). Fortunately, brief interventions that increase subjective understanding of algorithmic decision processes increase willingness to utilize algorithmic healthcare providers (studies 3A,B). A sixth study on Google Ads for an algorithmic skin cancer detection app finds that the effectiveness of such interventions generalizes to field settings (study 4: N{\thinspace}={\thinspace}14,013).},
issn={2397-3374},
doi={10.1038/s41562-021-01146-0},
url={https://doi.org/10.1038/s41562-021-01146-0}
}

@article{10.1145/274430.274436,
author = {Myers, Brad A.},
title = {A Brief History of Human-Computer Interaction Technology},
year = {1998},
issue_date = {March/April 1998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {2},
issn = {1072-5520},
url = {https://doi.org/10.1145/274430.274436},
doi = {10.1145/274430.274436},
journal = {Interactions},
month = {mar},
pages = {44–54},
numpages = {11}
}

@InProceedings{10.1007/978-3-319-99740-7_1,
author="Holzinger, Andreas
and Kieseberg, Peter
and Weippl, Edgar
and Tjoa, A. Min",
editor="Holzinger, Andreas
and Kieseberg, Peter
and Tjoa, A Min
and Weippl, Edgar",
title="Current Advances, Trends and Challenges of Machine Learning and Knowledge Extraction: From Machine Learning to Explainable AI",
booktitle="Machine Learning and Knowledge Extraction",
year="2018",
publisher="Springer International Publishing",
address="Cham",
pages="1--8",
abstract="In this short editorial we present some thoughts on present and future trends in Artificial Intelligence (AI) generally, and Machine Learning (ML) specifically. Due to the huge ongoing success in machine learning, particularly in statistical learning from big data, there is rising interest of academia, industry and the public in this field. Industry is investing heavily in AI, and spin-offs and start-ups are emerging on an unprecedented rate. The European Union is allocating a lot of additional funding into AI research grants, and various institutions are calling for a joint European AI research institute. Even universities are taking AI/ML into their curricula and strategic plans. Finally, even the people on the street talk about it, and if grandma knows what her grandson is doing in his new start-up, then the time is ripe: We are reaching a new AI spring. However, as fantastic current approaches seem to be, there are still huge problems to be solved: the best performing models lack transparency, hence are considered to be black boxes. The general and worldwide trends in privacy, data protection, safety and security make such black box solutions difficult to use in practice. Specifically in Europe, where the new General Data Protection Regulation (GDPR) came into effect on May, 28, 2018 which affects everybody (right of explanation). Consequently, a previous niche field for many years, explainable AI, explodes in importance. For the future, we envision a fruitful marriage between classic logical approaches (ontologies) with statistical approaches which may lead to context-adaptive systems (stochastic ontologies) that might work similar as the human brain.",
isbn="978-3-319-99740-7"
}

@article{QUINN2022102158,
title = {The three ghosts of medical AI: Can the black-box present deliver?},
journal = {Artificial Intelligence in Medicine},
volume = {124},
pages = {102158},
year = {2022},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2021.102158},
url = {https://www.sciencedirect.com/science/article/pii/S0933365721001512},
author = {Thomas P. Quinn and Stephan Jacobs and Manisha Senadeera and Vuong Le and Simon Coghlan},
keywords = {Xai, Black-box, Ethics, Challenges, Transparency, Autonomy},
abstract = {Our title alludes to the three Christmas ghosts encountered by Ebenezer Scrooge in A Christmas Carol, who guide Ebenezer through the past, present, and future of Christmas holiday events. Similarly, our article takes readers through a journey of the past, present, and future of medical AI. In doing so, we focus on the crux of modern machine learning: the reliance on powerful but intrinsically opaque models. When applied to the healthcare domain, these models fail to meet the needs for transparency that their clinician and patient end-users require. We review the implications of this failure, and argue that opaque models (1) lack quality assurance, (2) fail to elicit trust, and (3) restrict physician-patient dialogue. We then discuss how upholding transparency in all aspects of model design and model validation can help ensure the reliability and success of medical AI.}
}

@inproceedings{10.1145/3411764.3445562,
author = {Lu, Zhuoran and Yin, Ming},
title = {Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks},
year = {2021},
isbn = {9781450380966},
publisher = {ACM},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445562},
doi = {10.1145/3411764.3445562},
abstract = { This paper addresses an under-explored problem of AI-assisted decision-making: when objective performance information of the machine learning model underlying a decision aid is absent or scarce, how do people decide their reliance on the model? Through three randomized experiments, we explore the heuristics people may use to adjust their reliance on machine learning models when performance feedback is limited. We find that the level of agreement between people and a model on decision-making tasks that people have high confidence in significantly affects reliance on the model if people receive no information about the model’s performance, but this impact will change after aggregate-level model performance information becomes available. Furthermore, the influence of high confidence human-model agreement on people’s reliance on a model is moderated by people’s confidence in cases where they disagree with the model. We discuss potential risks of these heuristics, and provide design implications on promoting appropriate reliance on AI.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {78},
numpages = {16},
pages={1--16},
keywords = {human-AI interaction, Machine learning, appropriate reliance},
location = {Yokohama, Japan},
series = {CHI '21}
}

@article{GU2020101858,
title = {A case-based ensemble learning system for explainable breast cancer recurrence prediction},
journal = {Artificial Intelligence in Medicine},
volume = {107},
pages = {101858},
year = {2020},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2020.101858},
url = {https://www.sciencedirect.com/science/article/pii/S0933365719306712},
author = {Dongxiao Gu and Kaixiang Su and Huimin Zhao},
keywords = {Ensemble learning, Case-based reasoning, Breast cancer, Recurrence prediction, Case-based interpretation},
abstract = {Significant progress has been achieved in recent years in the application of artificial intelligence (AI) for medical decision support. However, many AI-based systems often only provide a final prediction to the doctor without an explanation of its underlying decision-making process. In scenarios concerning deadly diseases, such as breast cancer, a doctor adopting an auxiliary prediction is taking big risks, as a bad decision can have very harmful consequences for the patient. We propose an auxiliary decision support system that combines ensemble learning with case-based reasoning to help doctors improve the accuracy of breast cancer recurrence prediction. The system provides a case-based interpretation of its prediction, which is easier for doctors to understand, helping them assess the reliability of the system’s prediction and make their decisions accordingly. Our application and evaluation in a case study focusing on breast cancer recurrence prediction shows that the proposed system not only provides reasonably accurate predictions but is also well-received by oncologists.}
}

@article{NASSIF2022102276,
title = {Breast cancer detection using artificial intelligence techniques: A systematic literature review},
journal = {Artificial Intelligence in Medicine},
volume = {127},
pages = {102276},
year = {2022},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2022.102276},
url = {https://www.sciencedirect.com/science/article/pii/S0933365722000410},
author = {Ali Bou Nassif and Manar Abu Talib and Qassim Nasir and Yaman Afadar and Omar Elgendy},
keywords = {Breast cancer, Machine learning, Deep learning},
abstract = {Cancer is one of the most dangerous diseases to humans, and yet no permanent cure has been developed for it. Breast cancer is one of the most common cancer types. According to the National Breast Cancer Foundation, in 2020 alone, more than 276,000 new cases of invasive breast cancer and more than 48,000 non-invasive cases were diagnosed in the US. To put these figures in perspective, 64\% of these cases are diagnosed early in the disease's cycle, giving patients a 99\% chance of survival. Artificial intelligence and machine learning have been used effectively in detection and treatment of several dangerous diseases, helping in early diagnosis and treatment, and thus increasing the patient's chance of survival. Deep learning has been designed to analyze the most important features affecting detection and treatment of serious diseases. For example, breast cancer can be detected using genes or histopathological imaging. Analysis at the genetic level is very expensive, so histopathological imaging is the most common approach used to detect breast cancer. In this research work, we systematically reviewed previous work done on detection and treatment of breast cancer using genetic sequencing or histopathological imaging with the help of deep learning and machine learning. We also provide recommendations to researchers who will work in this field.}
}

@article {DeeplearningtodiagnosepouchofDouglasobliterationwithultrasoundslidingsign,
      author = "Gabriel Maicas and Mathew Leonardi and Jodie Avery and Catrina Panuccio and Gustavo Carneiro and M Louise Hull and George Condous",
      title = "Deep learning to diagnose pouch of Douglas obliteration with ultrasound sliding sign",
      journal = "Reproduction and Fertility",
      year = "2021",
      publisher = "Bioscientifica Ltd",
      address = "Bristol, UK",
      volume = "2",
      number = "4",
      doi = "10.1530/RAF-21-0031",
      pages=      "236 - 243",
      url = "https://raf.bioscientifica.com/view/journals/raf/2/4/RAF-21-0031.xml"
}

@ARTICLE{9540298,
  author={Medley, Daniela and Santiago, Carlos and Nascimento, Jacinto C.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={CyCoSeg: A Cyclic Collaborative Framework for Automated Medical Image Segmentation}, 
  year={2021},
  volume={},
  number={},
  pages={1-1},
  abstract={Deep neural networks have been tremendously successful at segmenting objects in images. However, it has been shown they still have limitations on challenging problems such as the segmentation of medical images. The main reason behind this lower success resides in the reduced size of the object in the image. In this paper we overcome this limitation through a cyclic collaborative framework, &lt;i&gt;CyCoSeg&lt;/i&gt;. The proposed framework is based on a deep active shape model (D-ASM), which provides prior information about the shape of the object, and a semantic segmentation network (SSN). These two models collaborate to reach the desired segmentation by influencing each other: SSN helps D-ASM identify relevant keypoints in the image through an Expectation Maximization formulation, while D-ASM provides a segmentation proposal that guides the SSN. This cycle is repeated until both models converge. Extensive experimental evaluation shows CyCoSeg boosts the performance of the baseline models, including several popular SSNs, while avoiding major architectural modifications. The effectiveness of our method is demonstrated on the left ventricle segmentation on two benchmark datasets, where our approach achieves one of the most competitive results in segmentation accuracy. Furthermore, its generalization is demonstrated for lungs and kidneys segmentation in CT scans.},
  keywords={},
  doi={10.1109/TPAMI.2021.3113077},
  ISSN={1939-3539},
  month={}
}

@ARTICLE{9730804,
  author={Santiago, Carlos and Medley, Daniela O. and Marques, Jorge S. and Nascimento, Jacinto C.},
  journal={IEEE Transactions on Image Processing}, 
  title={Model-Agnostic Temporal Regularizer for Object Localization Using Motion Fields}, 
  year={2022},
  volume={31},
  number={},
  pages={2478-2487},
  abstract={Video analysis often requires locating and tracking target objects. In some applications, the localization system has access to the full video, which allows fine-grain motion information to be estimated. This paper proposes capturing this information through motion fields and using it to improve the localization results. The learned motion fields act as a model-agnostic temporal regularizer that can be used with any localization system based on keypoints. Unlike optical flow-based strategies, our motion fields are estimated from the model domain, based on the trajectories described by the object keypoints. Therefore, they are not affected by poor imaging conditions. The benefits of the proposed strategy are shown on three applications: 1) segmentation of cardiac magnetic resonance; 2) facial model alignment; and 3) vehicle tracking. In each case, combining popular localization methods with the proposed regularizer leads to improvement in overall accuracies and reduces gross errors.},
  keywords={},
  doi={10.1109/TIP.2022.3155947},
  ISSN={1941-0042},
  month={}
}

@inproceedings{10.1145/3411764.3445736,
author = {Anik, Ariful Islam and Bunt, Andrea},
title = {Data-Centric Explanations: Explaining Training Data of Machine Learning Systems to Promote Transparency},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445736},
doi = {10.1145/3411764.3445736},
abstract = {Training datasets fundamentally impact the performance of machine learning (ML) systems. Any biases introduced during training (implicit or explicit) are often reflected in the system's behaviors leading to questions about fairness and loss of trust in the system. Yet, information on training data is rarely communicated to stakeholders. In this work, we explore the concept of data-centric explanations for ML systems that describe the training data to end-users. Through a formative study, we investigate the potential utility of such an approach, including the information about training data that participants find most compelling. In a second study, we investigate reactions to our explanations across four different system scenarios. Our results suggest that data-centric explanations have the potential to impact how users judge the trustworthiness of a system and to assist users in assessing fairness. We discuss the implications of our findings for designing explanations to support users’ perceptions of ML systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {75},
numpages = {13},
pages={1--13},
keywords = {Explanations, Machine Learning Systems, User Expertise, Transparency, Training Data, Fairness, Trust},
location = {Yokohama, Japan},
series = {CHI '21}
}

@Article{Forsberg2017,
author={Forsberg, Daniel
and Rosipko, Beverly
and Sunshine, Jeffrey L.},
title={Radiologists' Variation of Time to Read Across Different Procedure Types},
journal={Journal of Digital Imaging},
year={2017},
month={Feb},
day={01},
volume={30},
number={1},
pages={86-94},
abstract={The workload of US radiologists has increased over the past two decades as measured through total annual relative value units (RVUs). This increase in RVUs generated suggests that radiologists' productivity has increased. However, true productivity (output unit per input unit; RVU per time) is at large unknown since actual time required to interpret and report a case is rarely recorded. In this study, we analyzed how the time to read a case varies between radiologists over a set of different procedure types by retrospectively extracting reading times from PACS usage logs. Specifically, we tested two hypotheses that; i) relative variation in time to read per procedure type increases as the median time to read a procedure type increases, and ii) relative rankings in terms of median reading speed for individual radiologists are consistent across different procedure types. The results that, i) a correlation of -0.25 between the coefficient of variation and median time to read and ii) that only 12 out of 46 radiologists had consistent rankings in terms of time to read across different procedure types, show both hypotheses to be without support. The results show that workload distribution will not follow any general rule for a radiologist across all procedures or a general rule for a specific procedure across many readers. Rather the findings suggest that improved overall practice efficiency can be achieved only by taking into account radiologists' individual productivity per procedure type when distributing unread cases.},
issn={1618-727X},
doi={10.1007/s10278-016-9911-z},
url={https://doi.org/10.1007/s10278-016-9911-z}
}

@Article{jpm10040211,
AUTHOR = {Suh, Yong Joon and Jung, Jaewon and Cho, Bum-Joo},
TITLE = {Automated Breast Cancer Detection in Digital Mammograms of Various Densities via Deep Learning},
JOURNAL = {Journal of Personalized Medicine},
VOLUME = {10},
YEAR = {2020},
NUMBER = {4},
ARTICLE-NUMBER = {211},
PubMedID = {33172076},
ISSN = {2075-4426},
ABSTRACT = {Mammography plays an important role in screening breast cancer among females, and artificial intelligence has enabled the automated detection of diseases on medical images. This study aimed to develop a deep learning model detecting breast cancer in digital mammograms of various densities and to evaluate the model performance compared to previous studies. From 1501 subjects who underwent digital mammography between February 2007 and May 2015, craniocaudal and mediolateral view mammograms were included and concatenated for each breast, ultimately producing 3002 merged images. Two convolutional neural networks were trained to detect any malignant lesion on the merged images. The performances were tested using 301 merged images from 284 subjects and compared to a meta-analysis including 12 previous deep learning studies. The mean area under the receiver-operating characteristic curve (AUC) for detecting breast cancer in each merged mammogram was 0.952 &plusmn; 0.005 by DenseNet-169 and 0.954 &plusmn; 0.020 by EfficientNet-B5, respectively. The performance for malignancy detection decreased as breast density increased (density A, mean AUC = 0.984 vs. density D, mean AUC = 0.902 by DenseNet-169). When patients&rsquo; age was used as a covariate for malignancy detection, the performance showed little change (mean AUC, 0.953 &plusmn; 0.005). The mean sensitivity and specificity of the DenseNet-169 (87 and 88\%, respectively) surpassed the mean values (81 and 82\%, respectively) obtained in a meta-analysis. Deep learning would work efficiently in screening breast cancer in digital mammograms of various densities, which could be maximized in breasts with lower parenchyma density.},
DOI = {10.3390/jpm10040211}
}

@INPROCEEDINGS{8633197,
  author={Cai, Qiang and Liu, Xiaoming and Guo, Zhengsheng},
  booktitle={2018 11th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={Identifying Architectural Distortion in Mammogram Images Via a SE-DenseNet Model and Twice Transfer Learning}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Breast cancer is a leading threaten of woman's health, and mammography is widely used in the early detection and diagnosis of breast cancer. Mass is a common sign observed on mammograms, and the automatic identification of benign and malignant breast mammography mass images is a challenging task. The CAD techniques have been used to improve the classification performance. Deep learning is powerful classification technique, however, it needs a lot of training data, which is not practical for mass detection or classification. In this paper, based on the observation that natural images are greatly different from medical images, we proposed a new network (SE-DenseNet) which combines the Dense convolutional neural network (DenseNet) and the “Squeeze-and-Excitation” (SE) block, and twice fine-tuning method to classify breast mass. We first use the mass and normal breast to fine-tune our model (trained on ImageNet) and then use breast mass dataset (benign and malignant) to further fine-tuning the model. The correctness of the model is verified by a large number of experiments on the BCDR dataset and quantitative comparison with other methods. The proposed model achieved better performance on the BCDR dataset(AUC is 0.984, accuracy is 0.982).},
  keywords={},
  doi={10.1109/CISP-BMEI.2018.8633197},
  ISSN={},
  month={Oct}
}

@Article{Hai2019,
author={Hai, Jinjin
and Qiao, Kai
and Chen, Jian
and Tan, Hongna
and Xu, Jingbo
and Zeng, Lei
and Shi, Dapeng
and Yan, Bin},
title={Fully Convolutional DenseNet with Multiscale Context for Automated Breast Tumor Segmentation},
journal={Journal of Healthcare Engineering},
year={2019},
month={Jan},
day={14},
publisher={Hindawi},
volume={2019},
pages={8415485},
abstract={Breast tumor segmentation plays a crucial role in subsequent disease diagnosis, and most algorithms need interactive prior to firstly locate tumors and perform segmentation based on tumor-centric candidates. In this paper, we propose a fully convolutional network to achieve automatic segmentation of breast tumor in an end-to-end manner. Considering the diversity of shape and size for malignant tumors in the digital mammograms, we introduce multiscale image information into the fully convolutional dense network architecture to improve the segmentation precision. Multiple sampling rates of atrous convolution are concatenated to acquire different field-of-views of image features without adding additional number of parameters to avoid over fitting. Weighted loss function is also employed during training according to the proportion of the tumor pixels in the entire image, in order to weaken unbalanced classes problem. Qualitative and quantitative comparisons demonstrate that the proposed algorithm can achieve automatic tumor segmentation and has high segmentation precision for various size and shapes of tumor images without preprocessing and postprocessing.},
issn={2040-2295},
doi={10.1155/2019/8415485},
url={https://doi.org/10.1155/2019/8415485}
}

@InProceedings{10.1007/978-3-030-88163-4_16,
author="Jim{\'e}nez Gaona, Yuliana
and Rodriguez-Alvarez, Mar{\'i}a Jos{\'e}
and Espino-Morato, Hector
and Castillo Malla, Darwin
and Lakshminarayanan, Vasudevan",
editor="Rojas, Ignacio
and Castillo-Secilla, Daniel
and Herrera, Luis Javier
and Pomares, H{\'e}ctor",
title="DenseNet for Breast Tumor Classification in Mammographic Images",
booktitle="Bioengineering and Biomedical Signal and Image Processing",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="166--176",
abstract="Breast cancer screening is an efficient method to detect breast lesions early. The common screening techniques are tomosynthesis and mammography images. However, the traditional manual diagnosis requires an intense workload for pathologists, and hence is prone to diagnostic errors. Thus, the aim of this study was to build a deep convolutional neural network method for automatic detection, segmentation, and classification of breast lesions in mammography images. Based on deep learning the Mask-CNN (RoIAlign) method was developed to automate RoI segmentation. Then feature extraction, selection and classification were carried out by the DenseNet architecture. Finally, the precision and accuracy of the model was evaluated by the AUC, accuracy and precision metrics. To summarize, the findings of this study show that the methodology may improve the diagnosis and efficiency in automatic tumor localization through medical image classification.",
isbn="978-3-030-88163-4",
doi={https://doi.org/10.1007/978-3-030-88163-4_16}
}

@InProceedings{10.1007/978-3-030-47679-3_23,
author="Rybia{\l}ek, Anita
and Jele{\'{n}}, {\L}ukasz",
editor="Saeed, Khalid
and Dvorsk{\'y}, Ji{\v{r}}{\'i}",
title="Application of DenseNets for Classification of Breast Cancer Mammograms",
booktitle="Computer Information Systems and Industrial Management",
year="2020",
publisher="Springer International Publishing",
address="Cham",
pages="266--277",
abstract="In this study, we focus on the problem of a breast cancer diagnosis using mammography images by classifying them as belonging either to a negative or to a malignant mass class. We explore the potential of densely connected convolutional neural network (DenseNet) architectures by comparing its three different variants that were trained to classify the abnormalities in breast tissue. The models have been tested in a series of systematic experiments. With a limited dataset (2247 images per class), it was necessary to perform tests to verify whether the amount of data used in this work is sufficient to allow for the conclusion that the experimental results are not dependent on the subset of the data. The training was conducted using stratified 10-fold cross-validation to obtain statistically reliable metrics estimates. DenseNet-201 was found to be the best model achieving: 0.96 value for area under the curve (AUC), 0.92 for precision, 0.90 for recall, and 91{\%} for accuracy.",
isbn="978-3-030-47679-3"
}

@inproceedings{10.1145/3544548.3581075,
author = {Sivaraman, Venkatesh and Bukowski, Leigh A and Levin, Joel and Kahn, Jeremy M. and Perer, Adam},
title = {Ignore, Trust, or Negotiate: Understanding Clinician Acceptance of AI-Based Treatment Recommendations in Health Care},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581075},
doi = {10.1145/3544548.3581075},
abstract = {Artificial intelligence (AI) in healthcare has the potential to improve patient outcomes, but clinician acceptance remains a critical barrier. We developed a novel decision support interface that provides interpretable treatment recommendations for sepsis, a life-threatening condition in which decisional uncertainty is common, treatment practices vary widely, and poor outcomes can occur even with optimal decisions. This system formed the basis of a mixed-methods study in which 24 intensive care clinicians made AI-assisted decisions on real patient cases. We found that explanations generally increased confidence in the AI, but concordance with specific recommendations varied beyond the binary acceptance or rejection described in prior work. Although clinicians sometimes ignored or trusted the AI, they also often prioritized aspects of the recommendations to follow, reject, or delay in a process we term “negotiation.” These results reveal novel barriers to adoption of treatment-focused AI tools and suggest ways to better support differing clinician perspectives.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {754},
numpages = {18},
keywords = {human-AI interaction, interpretability, healthcare, visualization},
location = {Hamburg, Germany},
series = {CHI '23}
}

@incollection{harrington2016affinity,
  title={Affinity Diagrams},
  author={Harrington, H James},
  booktitle={The Innovation Tools Handbook, Volume 2},
  pages={45--54},
  year={2016},
  publisher={Productivity Press}
}

@inproceedings{10.1145/3544549.3573827,
author = {Yang, Qian and Wong, Richmond Y. and Gilbert, Thomas and Hagan, Margaret D. and Jackson, Steven and Junginger, Sabine and Zimmerman, John},
title = {Designing Technology and Policy Simultaneously: Towards A Research Agenda and New Practice},
year = {2023},
isbn = {9781450394222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544549.3573827},
doi = {10.1145/3544549.3573827},
abstract = {Accounting for technologies’ unintended consequences—whether they are misinformation on social media or issues of sustainability and social justice—increasingly requires HCI to consider technology design at a societal-level scale. At this scale, public and corporate policies play a critical role in shaping technologies and user behaviors. However, the research and practices around tech and policy design have largely been held separate. How can technology design and policies better inform and coordinate with each other in generating safe new technologies? What new solutions might emerge when HCI practitioners design technology and its policies simultaneously to account for its societal impacts? This workshop addresses these questions. It will 1) identify disciplines and areas of expertise needed for a tighter, more proactive technology-and-policy-design integration, 2) launch a community of researchers, educators, and designers interested in this integration, 3) identify and publish an HCI research and education agenda towards designing technologies and technology policies simultaneously.},
booktitle = {Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {343},
numpages = {6},
location = {Hamburg, Germany},
series = {CHI EA '23}
}

@inproceedings{10.1145/3544548.3581393,
author = {Yang, Qian and Hao, Yuexing and Quan, Kexin and Yang, Stephen and Zhao, Yiran and Kuleshov, Volodymyr and Wang, Fei},
title = {Harnessing Biomedical Literature to Calibrate Clinicians’ Trust in AI Decision Support Systems},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3581393},
doi = {10.1145/3544548.3581393},
abstract = {Clinical decision support tools (DSTs), powered by Artificial Intelligence (AI), promise to improve clinicians’ diagnostic and treatment decision-making. However, no AI model is always correct. DSTs must enable clinicians to validate each AI suggestion, convincing them to take the correct suggestions while rejecting its errors. While prior work often tried to do so by explaining AI’s inner workings or performance, we chose a different approach: We investigated how clinicians validated each other’s suggestions in practice (often by referencing scientific literature) and designed a new DST that embraces these naturalistic interactions. This design uses GPT-3 to draw literature evidence that shows the AI suggestions’ robustness and applicability (or the lack thereof). A prototyping study with clinicians from three disease areas proved this approach promising. Clinicians’ interactions with the prototype also revealed new design and research opportunities around (1) harnessing the complementary strengths of literature-based and predictive decision supports; (2) mitigating risks of de-skilling clinicians; and (3) offering low-data decision support with literature.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {14},
numpages = {14},
keywords = {Clinical AI, Qualitative Method, Biomedical Literature, XAI},
location = {Hamburg, Germany},
series = {CHI '23}
}

@Article{doi:10.1148/ryai.2020190208,
  author   = {Pacilè, Serena and Lopez, January and Chone, Pauline and Bertinotti, Thomas and Grouin, Jean Marie and Fillard, Pierre},
  title    = {Improving Breast Cancer Detection Accuracy of Mammography with the Concurrent Use of an Artificial Intelligence Tool},
  doi      = {10.1148/ryai.2020190208},
  eprint   = {https://doi.org/10.1148/ryai.2020190208},
  number   = {6},
  pages    = {e190208},
  url      = {https://doi.org/10.1148/ryai.2020190208},
  volume   = {2},
  abstract = {Purpose To evaluate the benefits of an artificial intelligence (AI)–based tool for two-dimensional mammography in the breast cancer detection process. Materials and Methods In this multireader, multicase retrospective study, 14 radiologists assessed a dataset of 240 digital mammography images, acquired between 2013 and 2106, using a counterbalance design in which half of the dataset was read without AI and the other half with the help of AI during a first session and vice versa during a second session, which was separated from the first by a washout period. Area under the receiver operating characteristic curve (AUC), sensitivity, specificity, and reading time were assessed as endpoints. Results The average AUC across readers was 0.769 (95\% CI: 0.724, 0.814) without AI and 0.797 (95\% CI: 0.754, 0.840) with AI. The average difference in AUC was 0.028 (95\% CI: 0.002, 0.055, P = .035). Average sensitivity was increased by 0.033 when using AI support (P = .021). Reading time changed dependently to the AI-tool score. For low likelihood of malignancy (< 2.5\%), the time was about the same in the first reading session and slightly decreased in the second reading session. For higher likelihood of malignancy, the reading time was on average increased with the use of AI. Conclusion This clinical investigation demonstrated that the concurrent use of this AI tool improved the diagnostic performance of radiologists in the detection of breast cancer without prolonging their workflow. Supplemental material is available for this article. © RSNA, 2020},
  journal  = {Radiology: Artificial Intelligence},
  year     = {2020},
}

@article{doi:10.1148/radiol.2021210325,
author = {den                             Dekker, Bianca M. and Bakker, Marije                             F. and de                             Lange, St\'{e}phanie V. and Veldhuis, Wouter                             B. and van                             Diest, Paul J. and Duvivier, Katya                             M. and Lobbes, Marc B.                             I. and Loo, Claudette                             E. and Mann, Ritse                         M. and Monninkhof, Evelyn                             M. and Veltman, Jeroen and Pijnappel, Ruud                             M. and van                             Gils, Carla H. and  and van                         Gils, C. H. and Bakker, M.                         F. and de                         Lange, S. V. and Veenhuizen, S. G.                             A. and Veldhuis, W.                         B. and Pijnappel, R.                             M. and Emaus, M.                         J. and Peeters, P. H.                             M. and Monninkhof, E.                             M. and Fernandez-Gallardo, M.                             A. and Mali, W. P. T.                             M. and van den                             Bosch, M. A. A. J. and van                             Diest, P. J. and Mann, R.                         M. and Mus, R. and Imhof-Tas, M.                             W. and Karssemeijer, N. and Loo, C.                         E. and de                             Koekkoek-Doll, P. K. and Winter-Warnars, H. A.                             O. and Bisschops, R. H.                             C. and Kock, M. C. J.                             M. and Storm, R.                         K. and van der                             Valk, P. H. M. and Lobbes, M. B.                             I. and Gommers, S. and de                             Jong, M. D. F. and Rutten, M. J. C.                             M. and Duvivier, K.                         M. and de                         Graaf, P. and Veltman, J. and Bourez, R. L. J.                             H. and de                             Koning, H. J.},
title = {Reducing False-Positive Screening MRI Rate in Women with Extremely                     Dense Breasts Using Prediction Models Based on Data from the DENSE                     Trial},
journal = {Radiology},
volume = {301},
number = {2},
pages = {283-292},
year = {2021},
doi = {10.1148/radiol.2021210325},
    note ={PMID: 34402665},

URL = { 
    
        https://doi.org/10.1148/radiol.2021210325
    
    

},
eprint = { 
    
        https://doi.org/10.1148/radiol.2021210325
    
    

}
,
    abstract = { Background High breast density increases breast cancer risk and lowers mammographic sensitivity. Supplemental MRI screening improves cancer detection but increases the number of false-positive screenings. Thus, methods to distinguish true-positive MRI screening results from false-positive ones are needed. Purpose To build prediction models based on clinical characteristics and MRI findings to reduce the rate of false-positive screening MRI findings in women with extremely dense breasts. Materials and Methods Clinical characteristics and MRI findings in Dutch breast cancer screening participants (age range, 50–75 years) with positive first-round MRI screening results (Breast Imaging Reporting and Data System 3, 4, or 5) after a normal screening mammography with extremely dense breasts (Volpara density category 4) were prospectively collected within the randomized controlled Dense Tissue and Early Breast Neoplasm Screening (DENSE) trial from December 2011 through November 2015. In this secondary analysis, prediction models were built using multivariable logistic regression analysis to distinguish true-positive MRI screening findings from false-positive ones. Results Among 454 women (median age, 52 years; interquartile range, 50–57 years) with a positive MRI result in a first supplemental MRI screening round, 79 were diagnosed with breast cancer (true-positive findings), and 375 had false-positive MRI results. The full prediction model (area under the receiver operating characteristics curve [AUC], 0.88; 95\% CI: 0.84, 0.92), based on all collected clinical characteristics and MRI findings, could have prevented 45.5\% (95\% CI: 39.6, 51.5) of false-positive recalls and 21.3\% (95\% CI: 15.7, 28.3) of benign biopsies without missing any cancers. The model solely based on readily available MRI findings and age had a comparable performance (AUC, 0.84; 95\% CI: 0.79, 0.88; P = .15) and could have prevented 35.5\% (95\% CI: 30.4, 41.1) of false-positive MRI screening results and 13.0\% (95\% CI: 8.8, 18.6) of benign biopsies. Conclusion Prediction models based on clinical characteristics and MRI findings may be useful to reduce the false-positive first-round screening MRI rate and benign biopsy rate in women with extremely dense breasts. Clinical trial registration no. NCT01315015 © RSNA, 2021 Online supplemental material is available for this article. See also the editorial by Imbriaco in this issue. }
}

@article{10.1001/jamaoncol.2023.4519,
    author = {Mao, Xinhe and He, Wei and Humphreys, Keith and Eriksson, Mikael and Holowko, Natalie and Yang, Haomin and Tapia, José and Hall, Per and Czene, Kamila},
    title = "{Breast Cancer Incidence After a False-Positive Mammography Result}",
    journal = {JAMA Oncology},
    year = {2023},
    month = {11},
    abstract = "{False-positive mammography results are common. However, long-term outcomes after a false-positive result remain unclear.To examine long-term outcomes after a false-positive mammography result and to investigate whether the association of a false-positive mammography result with cancer differs by baseline characteristics, tumor characteristics, and time since the false-positive result.This population-based, matched cohort study was conducted in Sweden from January 1, 1991, to March 31, 2020. It included 45 213 women who received a first false-positive mammography result between 1991 and 2017 and 452 130 controls matched on age, calendar year of mammography, and screening history (no previous false-positive result). The study also included 1113 women with a false-positive result and 11 130 matched controls with information on mammographic breast density from the Karolinska Mammography Project for Risk Prediction of Breast Cancer study. Statistical analysis was performed from April 2022 to February 2023.A false-positive mammography result.Breast cancer incidence and mortality.The study cohort included 497 343 women (median age, 52 years [IQR, 42-59 years]). The 20-year cumulative incidence of breast cancer was 11.3\\% (95\\% CI, 10.7\\%-11.9\\%) among women with a false-positive result vs 7.3\\% (95\\% CI, 7.2\\%-7.5\\%) among those without, with an adjusted hazard ratio (HR) of 1.61 (95\\% CI, 1.54-1.68). The corresponding HRs were higher among women aged 60 to 75 years at the examination (HR, 2.02; 95\\% CI, 1.80-2.26) and those with lower mammographic breast density (HR, 4.65; 95\\% CI, 2.61-8.29). In addition, breast cancer risk was higher for women who underwent a biopsy at the recall (HR, 1.77; 95\\% CI, 1.63-1.92) than for those without a biopsy (HR, 1.51; 95\\% CI, 1.43-1.60). Cancers after a false-positive result were more likely to be detected on the ipsilateral side of the false-positive result (HR, 1.92; 95\\% CI, 1.81-2.04) and were more common during the first 4 years of follow-up (HR, 2.57; 95\\% CI, 2.33-2.85 during the first 2 years; HR, 1.93; 95\\% CI, 1.76-2.12 at \\&gt;2 to 4 years). No statistical difference was found for different tumor characteristics (except for larger tumor size). Furthermore, associated with the increased risk of breast cancer, women with a false-positive result had an 84\\% higher rate of breast cancer death than those without (HR, 1.84; 95\\% CI, 1.57-2.15).This study suggests that the risk of developing breast cancer after a false-positive mammography result differs by individual characteristics and follow-up. These findings can be used to develop individualized risk-based breast cancer screening after a false-positive result.}",
    issn = {2374-2437},
    doi = {10.1001/jamaoncol.2023.4519},
    url = {https://doi.org/10.1001/jamaoncol.2023.4519},
    eprint = {https://jamanetwork.com/journals/jamaoncology/articlepdf/2811409/jamaoncology\_mao\_2023\_oi\_230059\_1698334950.60362.pdf},
}

@article{doi:10.1200/JGO.19.00127,
author = {Sood, Rupali and Rositch, Anne F. and Shakoor, Delaram and Ambinder, Emily and Pool, Kara-Lee and Pollack, Erica and Mollura, Daniel J. and Mullen, Lisa A. and Harvey, Susan C.},
title = {Ultrasound for Breast Cancer Detection Globally: A Systematic Review and Meta-Analysis},
journal = {Journal of Global Oncology},
volume = {},
number = {5},
pages = {1-17},
year = {2019},
doi = {10.1200/JGO.19.00127},
    note ={PMID: 31454282},

URL = { 
    
        https://doi.org/10.1200/JGO.19.00127
    
    

},
eprint = { 
    
        https://doi.org/10.1200/JGO.19.00127
    
    

}
,
    abstract = { PURPOSEMammography is not always available or feasible. The purpose of this systematic review and meta-analysis is to assess the diagnostic performance of ultrasound as a primary tool for early detection of breast cancer.MATERIALS AND METHODSFor this systematic review and meta-analysis, we comprehensively searched PubMed and SCOPUS to identify articles from January 2000 to December 2018 that included data on the performance of ultrasound for detection of breast cancer. Studies evaluating portable, handheld ultrasound as an independent detection modality for breast cancer were included. Quality assessment and bias analysis were performed with the Quality Assessment of Diagnostic Accuracy Studies-2 tool. Sensitivity analyses and meta-regression were used to explore heterogeneity. The study protocol has been registered with the international prospective register of systematic reviews (PROSPERO identifier: CRD42019127752).RESULTSOf the 526 identified studies, 26 were eligible for inclusion. Ultrasound had an overall pooled sensitivity and specificity of 80.1\% (95\% CI, 72.2\% to 86.3\%) and 88.4\% (95\% CI, 79.8\% to 93.6\%), respectively. When only low- and middle-income country data were considered, ultrasound maintained a diagnostic sensitivity of 89.2\% and specificity of 99.1\%. Meta-analysis of the included studies revealed heterogeneity. The high sensitivity of ultrasound for the detection of breast cancer was not statistically significantly different in subgroup analyses on the basis of mean age, risk, symptoms, study design, bias level, and study setting.CONCLUSIONGiven the increasing burden of breast cancer and infeasibility of mammography in certain settings, we believe these results support the potential use of ultrasound as an effective primary detection tool for breast cancer, which may be beneficial in low-resource settings where mammography is unavailable. }
}

@article{f451f9e9-c389-3030-ad8a-847378d73154,
 ISSN = {02767783},
 URL = {http://www.jstor.org/stable/30036540},
 abstract = {Information technology (IT) acceptance research has yielded many competing models, each with different sets of acceptance determinants. In this paper, we (1) review user acceptance literature and discuss eight prominent models, (2) empirically compare the eight models and their extensions, (3) formulate a unified model that integrates elements across the eight models, and (4) empirically validate the unified model. The eight models reviewed are the theory of reasoned action, the technology acceptance model, the motivational model, the theory of planned behavior, a model combining the technology acceptance model and the theory of planned behavior, the model of PC utilization, the innovation diffusion theory, and the social cognitive theory. Using data from four organizations over a six-month period with three points of measurement, the eight models explained between 17 percent and 53 percent of the variance in user intentions to use information technology. Next, a unified model, called the Unified Theory of Acceptance and Use of Technology (UTAUT), was formulated, with four core determinants of intention and usage, and up to four moderators of key relationships. UTAUT was then tested using the original data and found to outperform the eight individual models (adjusted R of 69 percent). UTAUT was then confirmed with data from two new organizations with similar results (adjusted R of 70 percent). UTAUT thus provides a useful tool for managers needing to assess the likelihood of success for new technology introductions and helps them understand the drivers of acceptance in order to proactively design interventions (including training, marketing, etc.) targeted at populations of users that may be less inclined to adopt and use new systems. The paper also makes several recommendations for future research including developing a deeper understanding of the dynamic influences studied here, refining measurement of the core constructs used in UTAUT, and understanding the organizational outcomes associated with new technology use.},
 author = {Viswanath Venkatesh and Michael G. Morris and Gordon B. Davis and Fred D. Davis},
 journal = {MIS Quarterly},
 number = {3},
 pages = {425--478},
 publisher = {Management Information Systems Research Center, University of Minnesota},
 title = {User Acceptance of Information Technology: Toward a Unified View},
 urldate = {2024-01-14},
 volume = {27},
 year = {2003}
}

@article{doi:10.1057/ejis.2012.15,
author = {Jiming Wu and Hongwei Du},
title = {Toward a better understanding of behavioral intention and system usage constructs},
journal = {European Journal of Information Systems},
volume = {21},
number = {6},
pages = {680-698},
year = {2012},
publisher = {Taylor & Francis},
doi = {10.1057/ejis.2012.15},


URL = { 
    
        https://doi.org/10.1057/ejis.2012.15
    
    

},
eprint = { 
    
        https://doi.org/10.1057/ejis.2012.15
    
    

}

}

@Article{Venkatesh2022,
author={Venkatesh, Viswanath},
title={Adoption and use of AI tools: a research agenda grounded in UTAUT},
journal={Annals of Operations Research},
year={2022},
month={Jan},
day={01},
volume={308},
number={1},
pages={641-652},
abstract={This paper is motivated by the widespread availability of AI tools, whose adoption and consequent benefits are still not well understood. As a first step, some critical issues that relate to AI tools in general, humans in the context of AI tools, and AI tools in the context of operations management are identified. A discussion of how these issues could hinder employee adoption and use of AI tools is presented. Building on this discussion, the unified theory of acceptance and use of technology is used as a theoretical basis to propose individual characteristics, technology characteristics, environmental characteristics and interventions as viable research directions that could not only contribute to the adoption literature, particularly as it relates to AI tools, but also, if pursued, such research could help organizations positively influence the adoption of AI tools.},
issn={1572-9338},
doi={10.1007/s10479-020-03918-9},
url={https://doi.org/10.1007/s10479-020-03918-9}
}

@incollection{JURAVLE2020263,
title = {Chapter 14 - Trust in artificial intelligence for medical diagnoses},
editor = {Beth Louise Parkin},
series = {Progress in Brain Research},
publisher = {Elsevier},
volume = {253},
pages = {263-282},
year = {2020},
booktitle = {Real-World Applications in Cognitive Neuroscience},
issn = {0079-6123},
doi = {https://doi.org/10.1016/bs.pbr.2020.06.006},
url = {https://www.sciencedirect.com/science/article/pii/S0079612320300819},
author = {Georgiana Juravle and Andriana Boudouraki and Miglena Terziyska and Constantin Rezlescu},
keywords = {Trust, AI, Healthcare, Medical diagnosis, Medical decision-making},
abstract = {We present two online experiments investigating trust in artificial intelligence (AI) as a primary and secondary medical diagnosis tool and one experiment testing two methods to increase trust in AI. Participants in Experiment 1 read hypothetical scenarios of low and high-risk diseases, followed by two sequential diagnoses, and estimated their trust in the medical findings. In three between-participants groups, the first and second diagnoses were given by: human and AI, AI and human, and human and human doctors, respectively. In Experiment 2 we examined if people expected higher standards of performance from AI than human doctors, in order to trust AI treatment recommendations. In Experiment 3 we investigated the possibility to increase trust in AI diagnoses by: (i) informing our participants that the AI outperforms the human doctor, and (ii) nudging them to prefer AI diagnoses in a choice between AI and human doctors. Results indicate overall lower trust in AI, as well as for diagnoses of high-risk diseases. Participants trusted AI doctors less than humans for first diagnoses, and they were also less likely to trust a second opinion from an AI doctor for high risk diseases. Surprisingly, results highlight that people have comparable standards of performance for AI and human doctors and that trust in AI does not increase when people are told the AI outperforms the human doctor. Importantly, we find that the gap in trust between AI and human diagnoses is eliminated when people are nudged to select AI in a free-choice paradigm between human and AI diagnoses, with trust for AI diagnoses significantly increased when participants could choose their doctor. These findings isolate control over one's medical practitioner as a valid candidate for future trust-related medical diagnosis and highlight a solid potential path to smooth acceptance of AI diagnoses amongst patients.}
}

@article{CHOUDHURY2022103708,
title = {Effect of risk, expectancy, and trust on clinicians’ intent to use an artificial intelligence system -- Blood Utilization Calculator},
journal = {Applied Ergonomics},
volume = {101},
pages = {103708},
year = {2022},
issn = {0003-6870},
doi = {https://doi.org/10.1016/j.apergo.2022.103708},
url = {https://www.sciencedirect.com/science/article/pii/S000368702200031X},
author = {Avishek Choudhury and Onur Asan and Joshua E. Medow},
keywords = {Healthcare, Artificial intelligence, Behavioral intention, Clinical decision making},
abstract = {A gap exists between the capabilities of artificial intelligence (AI) technologies in healthcare and the extent to which clinicians are willing to adopt these systems. Our study addressed this gap by leveraging ‘expectancy-value theory’ and ‘modified extended unified theory of acceptance and use of technology’ to understand why clinicians may be willing or unwilling to adopt AI systems. The study looked at the ‘expectancy,’ ‘trust,’ and ‘perceptions’ of clinicians related to their intention of using an AI-based decision support system known as the Blood Utilization Calculator (BUC). The study used purposive sampling to recruit BUC users and administered a validated online survey from a large hospital system in the Midwest in 2021. The findings captured the significant effect of ‘perceived risk’ (negatively) and ‘expectancy’ (positively) on clinicians' ‘trust’ in BUC. ‘Trust’ was also found to mediate the relationship of ‘perceived risk’ and ‘expectancy’ with the ‘intent to use BUC.’ The study's findings established pathways for future research and have implications on factors influencing BUC use.}
}

@Article{Lambert2023,
author={Lambert, Sophie Isabelle
and Madi, Murielle
and Sopka, Sa{\v{s}}a
and Lenes, Andrea
and Stange, Hendrik
and Buszello, Claus-Peter
and Stephan, Astrid},
title={An integrative review on the acceptance of artificial intelligence among healthcare professionals in hospitals},
journal={npj Digital Medicine},
year={2023},
month={Jun},
day={10},
volume={6},
number={1},
pages={111},
abstract={Artificial intelligence (AI) in the domain of healthcare is increasing in prominence. Acceptance is an indispensable prerequisite for the widespread implementation of AI. The aim of this integrative review is to explore barriers and facilitators influencing healthcare professionals' acceptance of AI in the hospital setting. Forty-two articles met the inclusion criteria for this review. Pertinent elements to the study such as the type of AI, factors influencing acceptance, and the participants' profession were extracted from the included studies, and the studies were appraised for their quality. The data extraction and results were presented according to the Unified Theory of Acceptance and Use of Technology (UTAUT) model. The included studies revealed a variety of facilitating and hindering factors for AI acceptance in the hospital setting. Clinical decision support systems (CDSS) were the AI form included in most studies (n{\thinspace}={\thinspace}21). Heterogeneous results with regard to the perceptions of the effects of AI on error occurrence, alert sensitivity and timely resources were reported. In contrast, fear of a loss of (professional) autonomy and difficulties in integrating AI into clinical workflows were unanimously reported to be hindering factors. On the other hand, training for the use of AI facilitated acceptance. Heterogeneous results may be explained by differences in the application and functioning of the different AI systems as well as inter-professional and interdisciplinary disparities. To conclude, in order to facilitate acceptance of AI among healthcare professionals it is advisable to integrate end-users in the early stages of AI development as well as to offer needs-adjusted training for the use of AI in healthcare and providing adequate infrastructure.},
issn={2398-6352},
doi={10.1038/s41746-023-00852-5},
url={https://doi.org/10.1038/s41746-023-00852-5}
}

@article{KHANIJAHANI2022100602,
title = {Organizational, professional, and patient characteristics associated with artificial intelligence adoption in healthcare: A systematic review},
journal = {Health Policy and Technology},
volume = {11},
number = {1},
pages = {100602},
year = {2022},
issn = {2211-8837},
doi = {https://doi.org/10.1016/j.hlpt.2022.100602},
url = {https://www.sciencedirect.com/science/article/pii/S2211883722000089},
author = {Ahmad Khanijahani and Shabnam Iezadi and Sage Dudley and Megan Goettler and Peter Kroetsch and Jama Wise},
keywords = {Artificial intelligence, Health care sector, Procedures and techniques utilization, Systematic review},
abstract = {Objectives
This review study was aimed to identify and document organizational, professional, and patient characteristics influencing the adoption of Artificial Intelligence (AI) in healthcare.
Methods
We searched electronic databases for relevant publications and outlined the eligibility criteria based on the study Participants (healthcare professionals), Concept (AI adoption), and Context (healthcare settings). We included peer-reviewed quantitative, qualitative, and mixed-method studies published in English and implemented a qualitative data synthesis approach to categorize and interpret the results.
Results
A total of 27 studies were included in the final analysis. We organized professional characteristics associated with AI adoption in healthcare settings into three main categories: psychosocial, experiential, and background elements. We organized the organizational characteristics into structural and cultural elements. We grouped patient characteristics into three categories: psychosocial factors, background characteristics, and medical characteristics.
Conclusions
Psychosocial factors such as perceived ease of use or usefulness, performance or effort expectancy, and social influence were major influential factors among healthcare professionals and patients. However, the perceived threat to autonomy was negatively associated with AI adoption. Structural factors such as the organization's size, workflow, training, and security play a crucial role in adopting AI technologies. A limited number of studies cited patient's demographic (e.g., age, sex, and race) and medical (e.g., the severity of illness and historical procedures) characteristics as factors associated with AI adoption. Further studies are needed to better understand the mechanisms of AI adoption in healthcare organizations and settings.}
}

@article{HSIEH2023107868,
title = {Determinants of physicians’ intention to use AI-assisted diagnosis: An integrated readiness perspective},
journal = {Computers in Human Behavior},
volume = {147},
pages = {107868},
year = {2023},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107868},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223002194},
author = {Pi-Jung Hsieh},
keywords = {Artificial intelligence-assisted diagnosis, Involvement, Technology readiness, Consumer value},
abstract = {Artificial intelligence (AI) in medical imaging applications improves the effectiveness and efficiency of disease diagnosis in medical image analysis through neural networks, machine learning tools, and big data. However, previous studies have only explained the impact of AI medical applications on the healthcare process, providing clinical diagnoses, and recommending treatments; therefore, they are insufficient to explain physician AI-assisted diagnosis adoption behavior. The present study has proposed a theoretical model to explain physicians' AI-assisted diagnosis adoption behavior. The resulting 237 valid questionnaires constituted a response rate of 72.48%. The results indicated that functional value, social value, emotional value, and epistemic value had positive effects on personal involvement. The results also showed that functional value, emotional value, personal involvement, optimism, and innovativeness had a positive influence on physicians’ intentions to adopt AI-assisted diagnosis. The results also found that perceived unregulated standards and perceived mistrust have negative effects on behavior intentions. The results provide unique insights that will not only assist hospital administrators in developing an appropriate AI-assisted diagnosis implementation strategy but also enable software developers, medical imaging manufacturers, and government agencies to develop and appropriate their own marketing and administrative strategies for the future.}
}

@article{SHIN2021102551,
title = {The effects of explainability and causability on perception, trust, and acceptance: Implications for explainable AI},
journal = {International Journal of Human-Computer Studies},
volume = {146},
pages = {102551},
year = {2021},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2020.102551},
url = {https://www.sciencedirect.com/science/article/pii/S1071581920301531},
author = {Donghee Shin},
keywords = {Explainable Ai, Causability, Human-ai interaction, Explanatorycues, Interpretability, Understandability, Trust, Glassbox, Human-centeredAI},
abstract = {Artificial intelligence and algorithmic decision-making processes are increasingly criticized for their black-box nature. Explainable AI approaches to trace human-interpretable decision processes from algorithms have been explored. Yet, little is known about algorithmic explainability from a human factors’ perspective. From the perspective of user interpretability and understandability, this study examines the effect of explainability in AI on user trust and attitudes toward AI. It conceptualizes causability as an antecedent of explainability and as a key cue of an algorithm and examines them in relation to trust by testing how they affect user perceived performance of AI-driven services. The results show the dual roles of causability and explainability in terms of its underlying links to trust and subsequent user behaviors. Explanations of why certain news articles are recommended generate users trust whereas causability of to what extent they can understand the explanations affords users emotional confidence. Causability lends the justification for what and how should be explained as it determines the relative importance of the properties of explainability. The results have implications for the inclusion of causability and explanatory cues in AI systems, which help to increase trust and help users to assess the quality of explanations. Causable explainable AI will help people understand the decision-making process of AI algorithms by bringing transparency and accountability into AI systems.}
}

@Article{Amann2020,
author={Amann, Julia
and Blasimme, Alessandro
and Vayena, Effy
and Frey, Dietmar
and Madai, Vince I.
and consortium, the Precise4Q},
title={Explainability for artificial intelligence in healthcare: a multidisciplinary perspective},
journal={BMC Medical Informatics and Decision Making},
year={2020},
month={Nov},
day={30},
volume={20},
number={1},
pages={310},
abstract={Explainability is one of the most heavily debated topics when it comes to the application of artificial intelligence (AI) in healthcare. Even though AI-driven systems have been shown to outperform humans in certain analytical tasks, the lack of explainability continues to spark criticism. Yet, explainability is not a purely technological issue, instead it invokes a host of medical, legal, ethical, and societal questions that require thorough exploration. This paper provides a comprehensive assessment of the role of explainability in medical AI and makes an ethical evaluation of what explainability means for the adoption of AI-driven tools into clinical practice.},
issn={1472-6947},
doi={10.1186/s12911-020-01332-6},
url={https://doi.org/10.1186/s12911-020-01332-6}
}

@article{SOLAIMANI2023101760,
title = {Critical Success Factors in a multi-stage adoption of Artificial Intelligence: A Necessary Condition Analysis},
journal = {Journal of Engineering and Technology Management},
volume = {69},
pages = {101760},
year = {2023},
issn = {0923-4748},
doi = {https://doi.org/10.1016/j.jengtecman.2023.101760},
url = {https://www.sciencedirect.com/science/article/pii/S0923474823000309},
author = {Sam Solaimani and Lucas Swaak},
keywords = {Artificial Intelligence, Technology adoption, Critical Success Factors, Necessary Condition Analysis},
abstract = {Notwithstanding the widespread publicity, Artificial Intelligence (AI) adoption has remained relatively limited. One important reason is a lack of insight into critical factors in the adoption process. This study reviews the literature on AI and several similar technologies to identify success factors and employs Necessary Condition Analysis (NCA) to empirically assess the criticality of the identified factors across various stages of adoption. The findings evidence the necessity of performance expectancy, top management support, technical competencies and resources, perceived ease of use, organizational compatibility, and trading partner leverage with varying levels of criticality across various stages of AI adoption.}
}

@incollection{HLAVKA2020235,
title = {Chapter 10 - Security, privacy, and information-sharing aspects of healthcare artificial intelligence},
editor = {Adam Bohr and Kaveh Memarzadeh},
booktitle = {Artificial Intelligence in Healthcare},
publisher = {Academic Press},
pages = {235-270},
year = {2020},
isbn = {978-0-12-818438-7},
doi = {https://doi.org/10.1016/B978-0-12-818438-7.00010-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128184387000101},
author = {Jakub P. Hlávka},
keywords = {Security, privacy, artificial intelligence, healthcare, information sharing},
abstract = {This chapter addresses key topics in security, privacy, and information sharing related to the emergence of artificial intelligence (AI)-based solutions in healthcare. It addresses security and privacy concerns, including the risks and opportunities associated with emerging AI-based technologies in healthcare and potential challenges to its adoption due to regulatory interventions. It also discusses potential benefits and challenges associated with information sharing in an era of AI in healthcare, describing its value, technological, and other constraints, and shows how it can improve patient experience throughout the disease cycle. The chapter concludes with a discussion of desirable policy responses to security, privacy, and information-sharing challenges in healthcare AI applications around the world, as countries continue to introduce AI-based technologies to their healthcare systems.}
}

@article{MALAMATENIOU20211192,
title = {Artificial Intelligence: Guidance for clinical imaging and therapeutic radiography professionals, a summary by the Society of Radiographers AI working group},
journal = {Radiography},
volume = {27},
number = {4},
pages = {1192-1202},
year = {2021},
issn = {1078-8174},
doi = {https://doi.org/10.1016/j.radi.2021.07.028},
url = {https://www.sciencedirect.com/science/article/pii/S1078817421001085},
author = {C. Malamateniou and S. McFadden and Y. McQuinlan and A. England and N. Woznitza and S. Goldsworthy and C. Currie and E. Skelton and K.-Y. Chu and N. Alware and P. Matthews and R. Hawkesford and R. Tucker and W. Town and J. Matthew and C. Kalinka and T. O'Regan},
keywords = {Artificial intelligence, Machine learning, Radiographer, Guidance, Recommendations},
abstract = {Introduction
Artificial intelligence (AI) has started to be increasingly adopted in medical imaging and radiotherapy clinical practice, however research, education and partnerships have not really caught up yet to facilitate a safe and effective transition. The aim of the document is to provide baseline guidance for radiographers working in the field of AI in education, research, clinical practice and stakeholder partnerships. The guideline is intended for use by the multi-professional clinical imaging and radiotherapy teams, including all staff, volunteers, students and learners.
Methods
The format mirrored similar publications from other SCoR working groups in the past. The recommendations have been subject to a rapid period of peer, professional and patient assessment and review. Feedback was sought from a range of SoR members and advisory groups, as well as from the SoR director of professional policy, as well as from external experts. Amendments were then made in line with feedback received and a final consensus was reached.
Results
AI is an innovative tool radiographers will need to engage with to ensure a safe and efficient clinical service in imaging and radiotherapy. Educational provisions will need to be proportionately adjusted by Higher Education Institutions (HEIs) to offer the necessary knowledge, skills and competences for diagnostic and therapeutic radiographers, to enable them to navigate a future where AI will be central to patient diagnosis and treatment pathways. Radiography-led research in AI should address key clinical challenges and enable radiographers co-design, implement and validate AI solutions. Partnerships are key in ensuring the contribution of radiographers is integrated into healthcare AI ecosystems for the benefit of the patients and service users.
Conclusion
Radiography is starting to work towards a future with AI-enabled healthcare. This guidance offers some recommendations for different areas of radiography practice. There is a need to update our educational curricula, rethink our research priorities, forge new strong clinical-academic-industry partnerships to optimise clinical practice. Specific recommendations in relation to clinical practice, education, research and the forging of partnerships with key stakeholders are discussed, with potential impact on policy and practice in all these domains. These recommendations aim to serve as baseline guidance for UK radiographers.
Implications for practice
This review offers the most up-to-date recommendations for clinical practitioners, researchers, academics and service users of clinical imaging and therapeutic radiography services. Radiography practice, education and research must gradually adjust to AI-enabled healthcare systems to ensure gains of AI technologies are maximised and challenges and risks are minimised. This guidance will need to be updated regularly given the fast-changing pace of AI development and innovation.}
}

@Article{Alowais2023,
author={Alowais, Shuroug A.
and Alghamdi, Sahar S.
and Alsuhebany, Nada
and Alqahtani, Tariq
and Alshaya, Abdulrahman I.
and Almohareb, Sumaya N.
and Aldairem, Atheer
and Alrashed, Mohammed
and Bin Saleh, Khalid
and Badreldin, Hisham A.
and Al Yami, Majed S.
and Al Harbi, Shmeylan
and Albekairy, Abdulkareem M.},
title={Revolutionizing healthcare: the role of artificial intelligence in clinical practice},
journal={BMC Medical Education},
year={2023},
month={Sep},
day={22},
volume={23},
number={1},
pages={689},
abstract={Healthcare systems are complex and challenging for all stakeholders, but artificial intelligence (AI) has transformed various fields, including healthcare, with the potential to improve patient care and quality of life. Rapid AI advancements can revolutionize healthcare by integrating it into clinical practice. Reporting AI's role in clinical practice is crucial for successful implementation by equipping healthcare providers with essential knowledge and tools.},
issn={1472-6920},
doi={10.1186/s12909-023-04698-z},
url={https://doi.org/10.1186/s12909-023-04698-z}
}

@article{OPRESCU202253,
title = {Towards a data collection methodology for Responsible Artificial Intelligence in health: A prospective and qualitative study in pregnancy},
journal = {Information Fusion},
volume = {83-84},
pages = {53-78},
year = {2022},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2022.03.011},
url = {https://www.sciencedirect.com/science/article/pii/S1566253522000355},
author = {A.M. Oprescu and G. Miró-Amarante and L. García-Díaz and V.E. Rey and A. Chimenea-Toscano and R. Martínez-Martínez and M.C. Romero-Ternero},
keywords = {Responsible Artificial Intelligence (RAI), Explainable Artificial Intelligence (XAI), Emotional computing, Affective computing, User-centered design, Human-Centered Design, Privacy, Security, Pregnancy},
abstract = {A medical field that is increasingly benefiting from Artificial Intelligence applications is Gyne- cology and Obstetrics. In previous work, we exposed that Artificial Intelligence (AI) technology and obstetric control by physicians can enhance pregnancy health, leading to better pregnancy outcomes and overall better experience, also reducing any possible long-term effects that can be produced by complications. This work presents a data collection methodology for responsible AI in Health and a case study in the pregnancy domain. It is a qualitative descriptive study on the preferences and expectations expressed by pregnant women regarding responsible AI and affective computing. A 41-items structured interview was distributed among 150 pregnant pa- tients attending prenatal care at Hospital Virgen del Rocío and the Clinic Victoria Rey (Seville, Spain) during the months of October and November 2020. A substantial interest in intelligent pregnancy solutions among pregnant women has been revealed in this study. Participants with a lower level of interest reported privacy concerns and lack of trust towards AI solutions. Re- garding affective computing based intelligent solutions specifically, most participants reported positively and no significant difference was found between women having a healthy or a high risk pregnancy on this matter. Our findings also suggest that a high demand of personalized intelligent solutions exists among participants. On the topic of sharing pregnancy data with the healthcare provider in favor of scientific research, pregnant women assisting public health- care services were found to be more likely to share their data when the provider was a public healthcare system rather than a private entity. Pregnant women who are interested in using an AI pregnancy application share a strong idea that it needs to be responsible, trustworthy, useful, and safe. Likewise, we found that pregnant women would change their mind about their concerns and they would feel more confident if the intelligent solution gives explanations about the system decisions and recommendations, as XAI approach promotes.}
}

@Article{Knisely2021,
author={Knisely, Benjamin M.
and Vaughn-Cooke, Monifa
and Wagner, Lee-Ann
and Fink, Jeffrey C.},
title={Device personalization for heterogeneous populations: leveraging physician expertise and national population data to identify medical device patient user groups},
journal={User Modeling and User-Adapted Interaction},
year={2021},
month={Nov},
day={01},
volume={31},
number={5},
pages={979-1025},
abstract={Interaction with patient-facing medical devices requires integrated performance of both physical and cognitive tasks that are highly dependent on many user characteristics. Quantifying product use variability early in the design process is useful for device designers seeking to personalize medical device features to maximize performance and improve health outcomes, but three barriers make this difficult. First, patient populations often differ from the general population and can be difficult to recruit and access for human performance evaluations. Second, users of patient-facing devices are highly heterogeneous, leading to highly varied and complicated use-cases. Finally, there are numerous unique tasks for each medical device that make it resource prohibitive to perform comprehensive device use evaluations, particularly in the early stages of design. To address these challenges, a method for modeling highly prevalent patient user sub-populations to be used in targeted device personalization is proposed. In this study, Internal Medicine domain-expert input is used to identify patient characteristics critical to the performance of generic physical and cognitive tasks required for commonly prescribed medical devices. Then, a novel approach to quantify those characteristics is proposed, utilizing variables from the US National Health and Nutrition Examination Survey (NHANES) dataset, demonstrating a means to characterize specific patient populations. The data are statistically clustered to identify meaningful, task-specific device user sub-populations. The approach is demonstrated on the diabetes population for tasks related to hand-held self-management glucometer device use. The cluster results are then discussed, including their practical application to design personalization.},
issn={1573-1391},
doi={10.1007/s11257-021-09305-8},
url={https://doi.org/10.1007/s11257-021-09305-8}
}

@inproceedings{10.1145/3411764.3445385,
author = {Jacobs, Maia and He, Jeffrey and F. Pradier, Melanie and Lam, Barbara and Ahn, Andrew C. and McCoy, Thomas H. and Perlis, Roy H. and Doshi-Velez, Finale and Gajos, Krzysztof Z.},
title = {Designing AI for Trust and Collaboration in Time-Constrained Medical Decisions: A Sociotechnical Lens},
year = {2021},
isbn = {9781450380966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3411764.3445385},
doi = {10.1145/3411764.3445385},
abstract = {Major depressive disorder is a debilitating disease affecting 264 million people worldwide. While many antidepressant medications are available, few clinical guidelines support choosing among them. Decision support tools (DSTs) embodying machine learning models may help improve the treatment selection process, but often fail in clinical practice due to poor system integration. We use an iterative, co-design process to investigate clinicians’ perceptions of using DSTs in antidepressant treatment decisions. We identify ways in which DSTs need to engage with the healthcare sociotechnical system, including clinical processes, patient preferences, resource constraints, and domain knowledge. Our results suggest that clinical DSTs should be designed as multi-user systems that support patient-provider collaboration and offer on-demand explanations that address discrepancies between predictions and current standards of care. Through this work, we demonstrate how current trends in explainable AI may be inappropriate for clinical environments and consider paths towards designing these tools for real-world medical systems.},
booktitle = {Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems},
articleno = {659},
numpages = {14},
keywords = {major depressive disorder, decision support tools, healthcare},
location = {, Yokohama, Japan, },
series = {CHI '21}
}

@article{10.1145/3449199,
author = {Abou Amsha, Khuloud and Bossen, Claus and Gr\"{o}nvall, Erik and Lewkowicz, Myriam},
title = {Computer-Supported Knotworking: Design Guidelines Based on Two Case Studies from the Healthcare Domain in Europe},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449199},
doi = {10.1145/3449199},
abstract = {In this paper, we compare two cases of collaboration within healthcare in two European countries, Denmark and France respectively. In each of these two cases, we conducted a design case study, and we found that collaboration is ad hoc, temporary, and shifting with regards to collaborators, aims, and processes. We argue for the relevance of knotworking and its analytic potential for investigating the kind of collaborative work we observed. We also argue that our two cases present a higher complexity level than how knotworking has previously been described in the literature. We describe complex knotworking as having three characteristics: 1) collaboration happens between a dynamic number of actors (who are usually loosely connected), 2) collaboration happens in episodes, and 3) cooperative work arrangements are constantly negotiated. Using the concept of complex knotworking for a comparative analysis of our two design solutions, we outline generic design guidelines for developing computer support to manage complex knotworking situations.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {125},
numpages = {26},
keywords = {ad-hoc collaboration, design guidelines, healthcare, knotworking}
}

@inproceedings{10.1145/3544548.3580945,
author = {Yuan, Chien Wen (Tina) and Bi, Nanyi and Lin, Ya-Fang and Tseng, Yuen-Hsien},
title = {Contextualizing User Perceptions about Biases for Human-Centered Explainable Artificial Intelligence},
year = {2023},
isbn = {9781450394215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3544548.3580945},
doi = {10.1145/3544548.3580945},
abstract = {Biases in Artificial Intelligence (AI) systems or their results are one important issue that demands AI explainability. Despite the prevalence of AI applications, the general public are not necessarily equipped with the ability to understand how the black-box algorithms work and how to deal with biases. To inform designs for explainable AI (XAI), we conducted in-depth interviews with major stakeholders, both end-users (n = 24) and engineers (n = 15), to investigate how they made sense of AI applications and the associated biases according to situations of high and low stakes. We discussed users’ perceptions and attributions about AI biases and their desired levels and types of explainability. We found that personal relevance and boundaries as well as the level of stake are two major dimensions for developing user trust especially during biased situations and informing XAI designs.},
booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
articleno = {248},
numpages = {15},
keywords = {Transparency, Human-Computer Interaction (HCI), Human-Centered Computing, Explainable AI (XAI), Explainability, Artificial Intelligence, AI bias},
location = {, Hamburg, Germany, },
series = {CHI '23}
}

@article{RASMY201811,
title = {A study of generalizability of recurrent neural network-based predictive models for heart failure onset risk using a large and heterogeneous EHR data set},
journal = {Journal of Biomedical Informatics},
volume = {84},
pages = {11-16},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S1532046418301175},
author = {Laila Rasmy and Yonghui Wu and Ningtao Wang and Xin Geng and W. Jim Zheng and Fei Wang and Hulin Wu and Hua Xu and Degui Zhi},
keywords = {EHR, Deep learning, Predictive modeling, RNN},
abstract = {Recently, recurrent neural networks (RNNs) have been applied in predicting disease onset risks with Electronic Health Record (EHR) data. While these models demonstrated promising results on relatively small data sets, the generalizability and transferability of those models and its applicability to different patient populations across hospitals have not been evaluated. In this study, we evaluated an RNN model, RETAIN, over Cerner Health Facts® EMR data, for heart failure onset risk prediction. Our data set included over 150,000 heart failure patients and over 1,000,000 controls from nearly 400 hospitals. Convincingly, RETAIN achieved an AUC of 82% in comparison to an AUC of 79% for logistic regression, demonstrating the power of more expressive deep learning models for EHR predictive modeling. The prediction performance fluctuated across different patient groups and varied from hospital to hospital. Also, we trained RETAIN models on individual hospitals and found that the model can be applied to other hospitals with only about 3.6% of reduction of AUC. Our results demonstrated the capability of RNN for predictive modeling with large and heterogeneous EHR data, and pave the road for future improvements.}
}

@article{doi:10.1148/radiol.210948,
author = {Lauritzen, Andreas D. and Rodr\'{\i}guez-Ruiz, Alejandro and von Euler-Chelpin, My Catarina and Lynge, Elsebeth and Vejborg, Ilse and Nielsen, Mads and Karssemeijer, Nico and Lillholm, Martin},
title = {An Artificial Intelligence–based Mammography Screening                     Protocol for Breast Cancer: Outcome and Radiologist Workload},
journal = {Radiology},
volume = {304},
number = {1},
pages = {41-49},
year = {2022},
doi = {10.1148/radiol.210948},
    note ={PMID: 35438561},

URL = { 
    
        https://doi.org/10.1148/radiol.210948
    
    

},
eprint = { 
    
        https://doi.org/10.1148/radiol.210948
    
    

}
,
    abstract = { Background Developments in artificial intelligence (AI) systems to assist radiologists in reading mammograms could improve breast cancer screening efficiency. Purpose To investigate whether an AI system could detect normal, moderate-risk, and suspicious mammograms in a screening sample to safely reduce radiologist workload and evaluate across Breast Imaging Reporting and Data System (BI-RADS) densities. Materials and Methods This retrospective simulation study analyzed mammographic examination data consecutively collected from January 2014 to December 2015 in the Danish Capital Region breast cancer screening program. All mammograms were scored from 0 to 10, representing the risk of malignancy, using an AI tool. During simulation, normal mammograms (score < 5) would be excluded from radiologist reading and suspicious mammograms (score > recall threshold [RT]) would be recalled. Two radiologists read the remaining mammograms. The RT was fitted using another independent cohort (same institution) by matching to the radiologist sensitivity. This protocol was further applied to each BI-RADS density. Screening outcomes were measured using the sensitivity, specificity, workload, and false-positive rate. The AI-based screening was tested for noninferiority sensitivity compared with radiologist screening using the Farrington-Manning test. Specificities were compared using the McNemar test. Results The study sample comprised 114 421 screenings for breast cancer in 114 421 women, resulting in 791 screen-detected, 327 interval, and 1473 long-term cancers and 2107 false-positive screenings. The mean age of the women was 59 years ± 6 (SD). The AI-based screening sensitivity was 69.7\% (779 of 1118; 95\% CI: 66.9, 72.4) and was noninferior (P = .02) to the radiologist screening sensitivity of 70.8\% (791 of 1118; 95\% CI: 68.0, 73.5). The AI-based screening specificity was 98.6\% (111 725 of 113 303; 95\% CI: 98.5, 98.7), which was higher (P < .001) than the radiologist specificity of 98.1\% (111 196 of 113 303; 95\% CI: 98.1, 98.2). The radiologist workload was reduced by 62.6\% (71 585 of 114 421), and 25.1\% (529 of 2107) of false-positive screenings were avoided. Screening results were consistent across BI-RADS densities, although not significantly so for sensitivity. Conclusion Artificial intelligence (AI)–based screening could detect normal, moderate-risk, and suspicious mammograms in a breast cancer screening program, which may reduce the radiologist workload. AI-based screening performed consistently across breast densities. © RSNA, 2022 Online supplemental material is available for this article. }
}

@article{HUA2024102698,
title = {Understanding the factors influencing acceptability of AI in medical imaging domains among healthcare professionals: A scoping review},
journal = {Artificial Intelligence in Medicine},
volume = {147},
pages = {102698},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2023.102698},
url = {https://www.sciencedirect.com/science/article/pii/S0933365723002129},
author = {David Hua and Neysa Petrina and Noel Young and Jin-Gun Cho and Simon K. Poon},
keywords = {Artificial intelligence, Diagnostic imaging, Acceptability, Healthcare professionals, Healthcare intervention},
abstract = {Background
Artificial intelligence (AI) technology has the potential to transform medical practice within the medical imaging industry and materially improve productivity and patient outcomes. However, low acceptability of AI as a digital healthcare intervention among medical professionals threatens to undermine user uptake levels, hinder meaningful and optimal value-added engagement, and ultimately prevent these promising benefits from being realised. Understanding the factors underpinning AI acceptability will be vital for medical institutions to pinpoint areas of deficiency and improvement within their AI implementation strategies. This scoping review aims to survey the literature to provide a comprehensive summary of the key factors influencing AI acceptability among healthcare professionals in medical imaging domains and the different approaches which have been taken to investigate them.
Methods
A systematic literature search was performed across five academic databases including Medline, Cochrane Library, Web of Science, Compendex, and Scopus from January 2013 to September 2023. This was done in adherence to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping Reviews (PRISMA-ScR) guidelines. Overall, 31 articles were deemed appropriate for inclusion in the scoping review.
Results
The literature has converged towards three overarching categories of factors underpinning AI acceptability including: user factors involving trust, system understanding, AI literacy, and technology receptiveness; system usage factors entailing value proposition, self-efficacy, burden, and workflow integration; and socio-organisational-cultural factors encompassing social influence, organisational readiness, ethicality, and perceived threat to professional identity. Yet, numerous studies have overlooked a meaningful subset of these factors that are integral to the use of medical AI systems such as the impact on clinical workflow practices, trust based on perceived risk and safety, and compatibility with the norms of medical professions. This is attributable to reliance on theoretical frameworks or ad-hoc approaches which do not explicitly account for healthcare-specific factors, the novelties of AI as software as a medical device (SaMD), and the nuances of human-AI interaction from the perspective of medical professionals rather than lay consumer or business end users.
Conclusion
This is the first scoping review to survey the health informatics literature around the key factors influencing the acceptability of AI as a digital healthcare intervention in medical imaging contexts. The factors identified in this review suggest that existing theoretical frameworks used to study AI acceptability need to be modified to better capture the nuances of AI deployment in healthcare contexts where the user is a healthcare professional influenced by expert knowledge and disciplinary norms. Increasing AI acceptability among medical professionals will critically require designing human-centred AI systems which go beyond high algorithmic performance to consider accessibility to users with varying degrees of AI literacy, clinical workflow practices, the institutional and deployment context, and the cultural, ethical, and safety norms of healthcare professions. As investment into AI for healthcare increases, it would be valuable to conduct a systematic review and meta-analysis of the causal contribution of these factors to achieving high levels of AI acceptability among medical professionals.}
}

@inproceedings{10.1145/3563657.3596058,
author = {Yildirim, Nur and Oh, Changhoon and Sayar, Deniz and Brand, Kayla and Challa, Supritha and Turri, Violet and Crosby Walton, Nina and Wong, Anna Elise and Forlizzi, Jodi and McCann, James and Zimmerman, John},
title = {Creating Design Resources to Scaffold the Ideation of AI Concepts},
year = {2023},
isbn = {9781450398930},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3563657.3596058},
doi = {10.1145/3563657.3596058},
abstract = {Advances in artificial intelligence have enabled unprecedented technical capabilities, yet making these advances useful in the real world remains challenging. We engaged in a Research through Design process to improve the ideation of AI products and services. We developed a design resource capturing AI capabilities based on 40 AI features commonly used across various domains. To probe its usefulness, we created a set of slides illustrating AI capabilities and asked designers to ideate AI-enabled user experiences. We also incorporated capabilities into our own design process to brainstorm concepts with domain experts and data scientists. Our research revealed that designers should focus on innovations where moderate AI performance creates value. We reflect on our process and discuss research implications for creating and assessing resources to systematically explore AI’s problem-solution space.},
booktitle = {Proceedings of the 2023 ACM Designing Interactive Systems Conference},
pages = {2326–2346},
numpages = {21},
keywords = {User experience, artificial intelligence, human-centered AI, ideation},
location = {, Pittsburgh, PA, USA, },
series = {DIS '23}
}

@ARTICLE{8884671,
  author={Medley, Daniela O. and Santiago, Carlos and Nascimento, Jacinto C.},
  journal={IEEE Transactions on Image Processing}, 
  title={Deep Active Shape Model for Robust Object Fitting}, 
  year={2020},
  volume={29},
  number={},
  pages={2380-2394},
  keywords={Feature extraction;Shape;Probabilistic logic;Active appearance model;Image segmentation;Image edge detection;Active shape model;Image segmentation;convolutional neural networks;generalized expectation-maximization;HOG;SIFT;active shape model},
  doi={10.1109/TIP.2019.2948728}
}

@article{10.1145/3274463,
author = {Zhu, Haiyi and Yu, Bowen and Halfaker, Aaron and Terveen, Loren},
title = {Value-Sensitive Algorithm Design: Method, Case Study, and Lessons},
year = {2018},
issue_date = {November 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CSCW},
url = {https://doi.org/10.1145/3274463},
doi = {10.1145/3274463},
abstract = {Most commonly used approaches to developing automated or artificially intelligent algorithmic systems are Big Data-driven and machine learning-based. However, these approaches can fail, for two notable reasons: (1) they may lack critical engagement with users and other stakeholders; (2) they rely largely on historical human judgments, which do not capture and incorporate human insights into how the world can be improved in the future. We propose and describe a novel method for the design of such algorithms, which we call Value Sensitive Algorithm Design. Value Sensitive Algorithm Design incorporates stakeholders' tacit knowledge and explicit feedback in the early stages of algorithm creation. This increases the chance to avoid biases in design choices or to compromise key stakeholder values. Generally, we believe that algorithms should be designed to balance multiple stakeholders' needs, motivations, and interests, and to help achieve important collective goals. We also describe a specific project "Designing Intelligent Socialization Algorithms for WikiProjects in Wikipedia" to illustrate our method. We intend this paper to contribute to the rich ongoing conversation concerning the use of algorithms in supporting critical decision-making in society.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {194},
numpages = {23},
keywords = {wikiprojects, wikipedia, value-sensitive algorithm design, system buildings, peer production, online recruitment, online communities, algorithmic intervention}
}

@article{10.1145/3555171,
author = {Zhang, Peng and Guan, Zhengqing and Liu, Baoxi and Ding, Xianghua (Sharon) and Lu, Tun and Gu, Hansu and Gu, Ning},
title = {Building User-oriented Personalized Machine Translator based on User-Generated Textual Content},
year = {2022},
issue_date = {November 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {CSCW2},
url = {https://doi.org/10.1145/3555171},
doi = {10.1145/3555171},
abstract = {Machine Translation (MT) has been a very useful tool to assist multilingual communication and collaboration. In recent years, by taking advantage of the exciting developments of neural networks and deep learning, the accuracy and speed of machine translation have been continuously improved. However, most machine translation methods and systems are data-driven. They tend to select a consensus response represented in training data, while a user's preferred linguistic style, which is important for translation comprehension and user experience, is ignored. For this problem, we aim to build a user-oriented personalized machine translation model in this paper. The model aims to learn each user's linguistic style from the textual content that is generated by her/him (User-Generated Textual Content, UGTC) in social media context and generate personalized translation results utilizing several state-of-the-art deep learning techniques like Transformer and pre-training. We also implemented a user-oriented personalized machine translator using Weibo as a case of the source of UGTC to provide a systematical implementation scheme of a user-oriented personalized machine translation system based on our model. The translator was evaluated by automatic evaluation in combination with human evaluation. The results suggest that our model can generate more personalized, natural and lively translation results and enhance the comprehensibility of translation results, which makes its generations more preferred by users versus general translation results.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {nov},
articleno = {280},
numpages = {26},
keywords = {user-generated textual content, personalized, machine translation, linguistic style, Weibo}
}

@article{10.1145/3449190,
author = {Zhu, Jichen and Dallal, Diane H. and Gray, Robert C. and Villareale, Jennifer and Onta\~{n}\'{o}n, Santiago and Forman, Evan M. and Arigo, Danielle},
title = {Personalization Paradox in Behavior Change Apps: Lessons from a Social Comparison-Based Personalized App for Physical Activity},
year = {2021},
issue_date = {April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {CSCW1},
url = {https://doi.org/10.1145/3449190},
doi = {10.1145/3449190},
abstract = {Social comparison-based features are widely used in social computing apps. However, most existing apps are not grounded in social comparison theories and do not consider individual differences in social comparison preferences and reactions. This paper is among the first to automatically personalize social comparison targets. In the context of an m-health app for physical activity, we use artificial intelligence (AI) techniques of multi-armed bandits. Results from our user study (n=53) indicate that there is some evidence that motivation can be increased using the AI-based personalization of social comparison. The detected effects achieved small-to-moderate effect sizes, illustrating the real-world implications of the intervention for enhancing motivation and physical activity. In addition to design implications for social comparison features in social apps, this paper identified the personalization paradox, the conflict between user modeling and adaptation, as a key design challenge of personalized applications for behavior change. Additionally, we propose research directions to mitigate this Personalization Paradox.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = {apr},
articleno = {116},
numpages = {21},
keywords = {m-health, personalization, physical activity, social comparison}
}